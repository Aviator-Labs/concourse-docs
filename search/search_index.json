{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"blog/","title":"Blog","text":""},{"location":"blog/2017-09-29-the-concourse-crew-2017/","title":"The Concourse Crew (2017)","text":"<p>{{&lt; image src=\"/images/downloaded_images/The-Concourse-Crew--2017-/1-Q5Wx-Lltp5MDzh1rE2Yw0g.png\" alt=\"Concourse logo\" position=\"center\" &gt;}}</p> <p>In 2014 the Concourse CI project started with just two engineers; Alex Suraci and Chris Brown. At the time, both Alex and Chris were working on the Pivotal Cloud Foundry team. Over time, they became increasingly frustrated by existing CI/CD solutions. In response, Alex and Chris worked on designing a new CI/CD system in their spare time; imagining a new type of CI/CD system that would treat pipelines as first class citizens. After building some early prototypes and seeing early success internally within Pivotal, Concourse as released as an open source project with sponsorship from Pivotal.</p> <p>Fast forward to 2017 and the Concourse team has grown considerably. We now have 6 full time engineers (soon to be 8), a product manager (that\u2019s me!) and a product designer. The Concourse team is distributed across two countries (US and Canada); with a majority of the team working out of the Pivotal office in Toronto. Alex is still around and remains a key contributor to the project.</p> <p>The Concourse open source community has grown considerably as well. We do our best to to keep engaged with everyone through GitHub issues, Slack and StackOverflow. And now, using Medium we are going to try to do a better job at covering the bigger topics like: the Concourse roadmap, the Concourse philosophy, and more generally \u201chow things work\u201d.</p> <p>If you have any specific comments that you\u2019d like us to cover, comment below, hit me up on Twitter (@pioverpi) or reach out on the Concourse Slack (@jma)</p>"},{"location":"blog/2017-10-03-how-the-concourse-team-organize-issues/","title":"How the Concourse Team Organize Issues","text":"<p>{{&lt; image src=\"/images/downloaded_images/How-the-Concourse-Team-Organize-Issues/1--19t4s8wuBf9tUCiluO_mQ.png\" alt=\"\" width=\"20%\" &gt;}}</p> <p>As the Concourse team continues to grow in size and in the # of incoming issues, the team has been experimenting with new ways of managing our backlog. So far we have tried three different setups:</p> <ol> <li>GitHub    issues + Customs/Tracksuit + Pivotal Tracker</li> <li>GitHub issues + aggressive labelling + CodeTree</li> <li>GitHub issues + GitHub Projects</li> </ol> <p>We\u2019ve been using the third setup, GitHub issues + GitHub Projects, for the past few months and we\u2019ve been mildly happy with the experience.</p>"},{"location":"blog/2017-10-03-how-the-concourse-team-organize-issues/#github-issues","title":"GitHub Issues","text":"<p>All issues are reported in through the concourse/concourse repo. Issues can include community-reported bugs, feature requests, technical chores, features, etc. If you want something done against the Concourse codebase, it gets reported there.</p> <p>Relying on a single location for all issues has the benefit of consolidating our backlogs; making it easier for the community to submit issues and track its progress. However with over 400 open issues against Concourse, the question becomes: how does the team decide what to work on first?</p> <p>Our first approach was to simply prioritize issues that were slated for the next release and burn through the list top-down. This naive approach became problematic for our growing team because of the incredible breadth of problems that Concourse covers. One day an engineer could be working on Elm and the next they would be working on our garbage collector. Even with pairing, new engineers found it very frustrating to master the codebase as they were constantly context-switching through thematically different issues.</p> <p>To address this, Alex Suraci bucketed our issues into five \u201cprojects\u201d:</p> <ul> <li>Operations</li> <li>Runtime</li> <li>Integrations</li> <li>Core</li> <li>UX</li> </ul> <p>By bucketing our issues into projects, engineers can now spend more time in thematically similar problem spaces in the Concourse codebase.</p>"},{"location":"blog/2017-10-03-how-the-concourse-team-organize-issues/#github-projects","title":"GitHub Projects","text":"<p>{{&lt; image src=\"/images/downloaded_images/How-the-Concourse-Team-Organize-Issues/1-5wA-RflsG_zFAyYMw0O95w.png\" alt=\"A snapshot of the Concourse UX project\" width=\"100%\"&gt;}}</p> <p>Our Concourse Projects manifest themselves as GitHub Projects in the Concourse GitHub organization. Annoyingly, GitHub doesn\u2019t (yet?) allow us to share these projects publicly.</p> <p>Each project has an engineering \u201canchor\u201d assigned to it. The anchor responsible for deeply understanding the issues under that project and usually sticks on the project for a long period of time. Each project also has its own roadmap and short-term goals.</p> <p>Every week we have an Iteration Planning Meeting (IPM) where we discuss the backlog for each project team. This is where our team discusses what\u2019s been done, what\u2019s in-flight, and what the upcoming issues are for the week ahead.</p> <p>I hope this post gives everyone in the community a bit of insight into how the Concourse team manages incoming issues and incoming work. We\u2019re hoping that Github announces improvements to the GitHub Projects system in their upcoming conference, GitHub Universe. If we aren\u2019t able to make our projects public in the near future, the Concourse team is committed to looking into alternative tools to publicly share our roadmap.</p> <p>For those who are interested, I\u2019ve also listed the specifics of our Five Concourse Project below:</p>"},{"location":"blog/2017-10-03-how-the-concourse-team-organize-issues/#the-five-concourse-projects","title":"The Five Concourse Projects","text":""},{"location":"blog/2017-10-03-how-the-concourse-team-organize-issues/#operations","title":"Operations","text":"<p>Ensuring Concourse is deployable and manageable in various environments, and able to meet organizations' authorization requirements.</p> <p>Subject matter:</p> <ul> <li>Various deployment scenarios (BOSH, binaries, Docker, Kubernetes, Windows, Darwin)</li> <li>Understanding resource demands of Concourse, both minimum requirements and \"at scale\"</li> <li>Systems knowledge to support and improve all of the above</li> <li>Multi-tenant operator demands (auth, inspectability)</li> </ul>"},{"location":"blog/2017-10-03-how-the-concourse-team-organize-issues/#runtime","title":"Runtime","text":"<p>Bring the theory to life. How do we go from a declarative configuration to efficiently running things across a pool of VMs?</p> <p>Subject matter:</p> <ul> <li>Containers: what &amp; why, what is their \u201ccost\u201d</li> <li>Copy-on-write volume management</li> <li>Scheduling to most efficiently utilize a pool of VMs</li> <li>Safely managing containers/volumes/etc. across VMs without leaking resources</li> </ul>"},{"location":"blog/2017-10-03-how-the-concourse-team-organize-issues/#integration","title":"Integration","text":"<p>Defining interfaces and patterns for how Concourse interacts with the real world.</p> <p>Subject matter:</p> <ul> <li>Supporting the core set of resources</li> <li>Establishing and documenting patterns for resources, watching out for anti-patterns</li> <li>Defining the best interfaces for extending Concourse; recognizing resources alone may not be enough</li> </ul>"},{"location":"blog/2017-10-03-how-the-concourse-team-organize-issues/#concourse-core","title":"Concourse Core","text":"<p>Pushing Concourse concepts forward by distilling customer needs into abstract primitives.</p> <p>Subject matter:</p> <ul> <li>Recognize that most feature requests are valid, but should not be implemented \u201cas-is\u201d</li> <li>Networking and pattern-matching; peel back the layers of the GitHub onion to identify common ground between various   issues</li> <li>Leave space for innovation and re-framing our existing concepts</li> <li>Define the REST API, and how pipelines/tasks are configured</li> </ul>"},{"location":"blog/2017-10-03-how-the-concourse-team-organize-issues/#ux","title":"UX","text":"<p>The face of Concourse \u2014 web UI, fly, and user research to find the best representations of what Concourse does and how users want to interact with it.</p> <p>Subject matter:</p> <ul> <li>Tie Concourse\u2019s pretentious high-level super-abstract concepts to users\u2019 needs around automation.</li> <li>Consume Concourse\u2019s API and ensure it doesn\u2019t get too bogged down in specific user flows.</li> <li>Drive feedback into the rest of the project through user research.</li> </ul>"},{"location":"blog/2017-10-26-build-page-improvements/","title":"Build Page Improvements","text":"<p>{{&lt; image src=\"/images/downloaded_images/Build-Page-Improvements/1-vjvvVZAw9nO4yRrveU0Ojg.gif\" alt=\"GIF demoing build page changes\" width=\"50%\" &gt;}}</p> <p>Concourse v3.6.0 comes with two new features on the build output page: timestamps and keyboard shortcuts.</p>"},{"location":"blog/2017-10-26-build-page-improvements/#timestamps-and-output-sharing","title":"Timestamps and Output\u00a0Sharing","text":"<p>When looking at the build page, you will now see timestamps reported against each line of output using your browser\u2019s reported timezone. As you hover over the timestamp, you can select single line of output or you can SHIFT select multiple lines of output. You\u2019ll also notice that the build page URL is updated to reflect the lines you have selected. You can use this URL to share specific build outputs with your team members.</p> <p>This feature addresses issue #361, #838 and #1423. Thank you for your patience!</p>"},{"location":"blog/2017-10-26-build-page-improvements/#keyboard-shortcuts","title":"Keyboard Shortcuts","text":"<p>{{&lt; image src=\"/images/downloaded_images/Build-Page-Improvements/1-8-_eZ3qsDLB8Sqq5I-9vTw.png\" alt=\"\" width=\"50%\" &gt;}}</p> <p>The build page also supports basic vim-style keyboard shortcuts as well. You can bring up a handy reference menu using <code>?</code> or <code>SHIFT + /</code> if you\u2019re really having trouble finding it.</p> <p>The supported keyboard shortcuts are:</p> <ul> <li><code>h</code> and <code>l</code> for previous / next build</li> <li><code>j</code> and <code>k</code> for scrolling up and down</li> <li><code>T</code> to trigger a new build</li> <li><code>A</code> to abort the build</li> <li><code>gg</code> to scroll back to the top of the page</li> <li><code>G</code> to scroll to the bottom of the page</li> <li><code>?</code> to toggle the keyboard hint on and off</li> </ul> <p>This feature closes out issue #439</p>"},{"location":"blog/2017-11-01-sneak-peek-spatial-resources/","title":"Sneak Peek: Spatial Resources","text":"<p>{{&lt; image src=\"/images/downloaded_images/Sneak-Peek--Spatial-Resources/1-agN3JPhVv4Fyfvp-2VQsRQ.png\" alt=\"An early visualization of Spatial Resources\" width=\"100%\" &gt;}}</p> <p>If you\u2019ve been paying close attention to our issues on GitHub you may have noticed a small flurry of activity around one specific issue: #1707 Spike: spatial resource flows.</p>"},{"location":"blog/2017-11-01-sneak-peek-spatial-resources/#what-are-spatial-resources-flows-aka-space","title":"What are Spatial Resources Flows (aka Space)?","text":"<p>The first reference to \u201cspatial\u201d resources came up in a proposal between Alex Suraci and Christopher Hendrix for Multi-branch workflows ( #1172). In that issue we focused specifically on one recurring problem: it\u2019s a real pain to deal with the Git resource when you have multiple branches representing different streams of work.</p> <p>Over time we researched similar build paradigms and thought deeply about generalized solutions that would fit nicely with the Concourse philosophy\u2122:</p> <p>Concourse makes it very easy to model changes over time. Resources do this for you; you point them at a given source of truth, and it\u2019ll let you know everything that happened.Some workflows, however, can\u2019t just be modeled as change over time. Multiple branches of a repo, or pull requests to a repository, are over space, not time. They are parallel pipelines, which today are hard to manage, and impossible to correlate (you cannot fan-in). Build matrixes are another example of wanting to run over many spaces (i.e. versions of a product). This can be done today, within a pipeline, but results in a massive pipeline with every combination explicitly configured... \u2026(a spatial resource) introduces the ability to have arbitrary build matrixes within one pipeline, which should dramatically improve the experience for people testing many variations/combinations.</p>"},{"location":"blog/2017-11-01-sneak-peek-spatial-resources/#would-you-like-to-know-more","title":"Would you like to know more?","text":"<p>{{&lt; image src=\"/images/downloaded_images/Sneak-Peek--Spatial-Resources/1-9vFBBZBYtFvCxsDnoMZszw.jpeg\" alt=\"\" width=\" 100%\" &gt;}}</p> <p>There\u2019s a few ways you can get involved as the Concourse team continues to build out spaces:</p> <ol> <li>Read the proposal for spatial resources on GitHub here. Join in    on the discussion and \u2764\ufe0f the proposal if you\u2019re excited to see this happen!</li> <li>We\u2019re building out some common pipeline use cases to test out spaces. You can see our current list of proposals in    issue #1766. If you\u2019d like to add your own personal experiences    and pipeline use case, I\u2019d encourage you to add your notes on the issue.</li> <li>Spaces will introduce a lot of new abstractions into the pipeline visualization. We\u2019re still experimenting with the    visualization of spaces in the pipeline view; and are looking for fresh new ideas on how to visualize this. If you    have a sketch, a doodle, or even a simple recommendation; drop us a line on    the proposalor on our Slack.</li> </ol>"},{"location":"blog/2017-12-01-concourse-at-springone-2017/","title":"Concourse at SpringOne 2017","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-at-SpringOne-2017/1-JzJoM_Man8MYThde2qy7Zg.png\" alt=\"\" width=\" 100%\" &gt;}}</p> <p>Topher Bullock, Lindsay Auchinachie, Alex Suraci and I will be travelling to San Francisco next week to attend the SpringOne Platform 2017 Conference. Not only are there a lot of exciting Spring talks this year, but there will be a lot of CI/CD talks from some amazing speakers.</p> <p>Unfortunately none of the Concourse core contribution team will be speaking at SpringOne this year; but that doesn\u2019t mean there\u2019s a shortage of Concourse-related talks. Here\u2019s a short list of talks from people who will be sharing their real-world Concourse knowledge and experiences at SpringOne:</p> <ul> <li>Automated PCF Upgrades with Concourse   with Rich Ruedin from Express Scripts</li> <li>Building Developer Pipelines with PKS, Harbor, Clair and Concourse   with Thomas Kraus and Merlin Glynn from VMWare</li> <li>Concourse in the Real World: A Case Study in CI/CD and DevOp   s with Bryan Kelly and Greg Meyer from Cerner Corp</li> <li>Ensuring Platform Security with Windows BOSH Add-ons and Runtime Config at Boeing   with Sheryl Maris, Brad Schaefbauer and James Coppock from Boeing</li> <li>Enterprise CI/CD\u200a\u2014\u200aScaling the Build Pipeline at Home Depot   with Matt MacKenny from The Home Depot</li> <li>How to Continuously Delivery Your Platform with Concourse   with Brian Kirland from Verizon and Ryan Pei from Pivotal</li> </ul> <p>You can find a full list of sessions on the SpringOne sessions page here. Be sure to check out the DevOps, CI, CD</p> <p>Looking forward to seeing ya\u2019ll there!</p>"},{"location":"blog/2018-02-02-concourse-updates-jan-29--feb-2-2018/","title":"Concourse Updates (Jan 29 \u2014 Feb 2, 2018)","text":"<p>As a Product Manager at Pivotal, one of my responsibilities is to write weekly updates to let Pivots know what the Concourse team has been up to for the past week. When the Concourse team got together earlier this month for our 2018 planning, we decided that we should be sharing these updates with our community as a whole. So, without further ado, here\u2019s our first update of 2018!</p>"},{"location":"blog/2018-02-02-concourse-updates-jan-29--feb-2-2018/#features","title":"Features","text":"<p>UX</p> <ul> <li>Fixed https://github.com/concourse/concourse/issues/1978</li> <li>We gave a shot at doing lazy-loading and pagination of builds, but it didn\u2019t work very well. Reverting in lieu of some   more UX research on that   page https://github.com/concourse/concourse/issues/1855</li> </ul> <p>Core</p> <ul> <li>Currently looking for additional feedback on use-cases for Spatial Resources. If you have an opinion on this, **PLEASE   ** jump on this issue and   comment: https://github.com/concourse/concourse/issues/1766</li> <li>Continued work on refactoring auth providers model in preparation for Users in Concourse.   See https://github.com/concourse/concourse/issues/1991   and https://github.com/concourse/concourse/issues/1888</li> </ul> <p>Runtime</p> <ul> <li>Wrapped up work on \u201cBind-mount certs to resource containers at   <code>/etc/ssl/certs</code>\"https://github.com/concourse/concourse/issues/1938.   This was a tough one. Look forward to a post from Topher Bullock explaining some   of the nuances behind this implementation</li> </ul>"},{"location":"blog/2018-02-02-concourse-updates-jan-29--feb-2-2018/#design-research","title":"Design Research","text":"<ul> <li>Lindsay Auchinachie and Sam Peinado mocked   up a new \u201cHigh Density\u201d view of the Concourse   dashboard (https://github.com/concourse/concourse/issues/1899).   This new design would be an add-on to the current beta dashboard, and would be activated using a toggle in the status   bar.</li> <li>The design team is also beginning to research new designs to support adding comments to the current build page</li> <li>We\u2019re also beginning to work on new designs for the http://concourse.ci/ homepage! New year,   new look!</li> </ul>"},{"location":"blog/2018-02-02-concourse-updates-jan-29--feb-2-2018/#feedback","title":"Feedback","text":"<p>This is our first time posting updates publicly like this, so please let us know if they\u2019re helpful by giving us a \u201cclap\u201d or by responding to the story below! We also plan to announce a new portal where community members can follow along with our progress in the coming weeks, so look forward to more information coming your way!</p>"},{"location":"blog/2018-02-09-concourse-updates-feb-5--feb9/","title":"Concourse Updates (Feb 5 \u2014 Feb9)","text":"<p>We spent some time this week wrapping up additional testing on our certs management across workers. We also put down some of work on Spaces this week to play around with something fun: a high density dashboard view. A lot of you have been asking us when Concourse v3.9.0 will be available, and the answer is: very soon!</p> <p>On to the update:</p>"},{"location":"blog/2018-02-09-concourse-updates-feb-5--feb9/#features","title":"Features","text":"<p>UX</p> <ul> <li>High Density View! Original Git issue #1899 and a demo version   of it up and running can be found in our production environment</li> <li>Merged PR #227, thanks for the   contribution SwamWithTurtles!</li> </ul> <p>Runtime</p> <ul> <li>Picked up #2016 Move TSA beacon operations to \u2018worker\u2019. We need   to do this to fix some nasty behaviour we\u2019ve observed in our large scale Concourse   installation Pivotal</li> </ul> <p>Core</p> <ul> <li>Continued breaking out our backend auth systems to use   Dex #1888, (   see #1886for additional background)</li> </ul>"},{"location":"blog/2018-02-09-concourse-updates-feb-5--feb9/#design-research","title":"Design Research","text":"<ul> <li>Did some research and prototypes to see what build page commenting would look like and how it would behave in   Concourse</li> <li>Continuing some design prototyping for Concourse brand assets</li> </ul>"},{"location":"blog/2018-02-16-concourse-update-feb-1216/","title":"Concourse Update (Feb 12\u201316)","text":"<p>If you haven\u2019t heard the news by now, we released Concourse v3.9.0 this week \ud83c\udf89\ud83c\udf89\ud83c\udf89! Two of the top-line features in this release are:</p> <ul> <li>Concourse will now automatically propagate certificates from the worker machine into resource containers (GH   issue #1027)</li> <li>Improved btrfs volume driver stability. So if you\u2019re getting hit hard by overlay weirdness, I\u2019d suggest you give the   btrfs driver another shot!</li> </ul> <p>To find out what else we\u2019ve packed into this release, I\u2019d encourage you to read the full release notes on the concourse.ci/downloads page!</p> <p>On to the update...</p>"},{"location":"blog/2018-02-16-concourse-update-feb-1216/#features","title":"Features","text":"<p>UX</p> <ul> <li>Started to look at slow page-load times on the web-ui. The team identified that a large source of the pain came when   we introduced timestamps last year. We\u2019ve since been able to drastically improve the load times on that   page GH issue 1912</li> </ul> <p>Runtime</p> <ul> <li>As I mentioned last week, the Concourse team runs a relatively large installation of Concourse that is used by Pivotal   employees for internal projects. As a result of running this giant Concourse, we\u2019ve discovered that our Garbage   Collector needs significant improvement in order to keep up with the workloads that we\u2019ve been observing. GH   issue #2016 has been consuming a lot of our thoughts and   feelings this week.</li> </ul> <p>Core</p> <ul> <li>Same as last week: continued breaking out our backend auth systems to use   Dex #1888, (   see #1886for additional background)</li> <li>^^ Refactoring our complex backend to support individual auth is going to take some time, and we recognize that :)</li> </ul>"},{"location":"blog/2018-02-16-concourse-update-feb-1216/#design-research","title":"Design Research","text":"<p>We\u2019ve picked up design research work on Spatial Resources again. Lindsay Auchinachie and Sam Peinado are currently exploring different ways to visualize the (potentially) dense permutations and combinations of work.</p>"},{"location":"blog/2018-02-23-concourse-update-feb-2023/","title":"Concourse Update (Feb 20\u201323)","text":"<p>Monday, Feb 19 was Family Day for us here in Canada, so its been a relatively short work week for the Concourse team. With the release of v3.9.0 last week, we\u2019ve gotten some reports of new bugs and issues, so thanks to everyone who reported them in via our GitHub issues and Slack. Please make sure to check the updated release notes (here) for the full details! We\u2019re planning to cut a new patch release early next week with some of the fixes to the reported issues.</p> <p>On to the update:</p>"},{"location":"blog/2018-02-23-concourse-update-feb-2023/#features","title":"Features","text":"<p>UX</p> <ul> <li>We fixed issue #1912(slow build page due to timestamps)! The fix   for this should be rolled into the next patch release as well</li> <li>Started working on search hint and autocomplete on the Concourse   Dashboard #1713</li> <li>Tried adding buffering to fly outputs, it didn\u2019t help #1912</li> </ul> <p>Core</p> <ul> <li>Fixed an issue with noisy logging from skymarshall by lowering the the log   level #2044</li> <li>SURPRISE: we\u2019re still refactoring our backend to support users</li> </ul> <p>Operations</p> <ul> <li>Pulled in PR #2030so we could fix the BOSH deployment issue where   the ATC will fail due to function esc not being defined #2029</li> <li>Fixed a CredHub integration bug #2034</li> </ul>"},{"location":"blog/2018-03-02-concourse-update-feb-26--mar2/","title":"Concourse Update (Feb 26 \u2014 Mar2)","text":"<p>After some wrestling with our production pipelines last week we managed to release a patch update in the form of Concourse v3.9.1. We\u2019ve fixed some of the reported bugs from the previous release (3.9.0) so definitely go and check it out!</p> <p>I don\u2019t have much else regarding updates this week so here\u2019s a fun fact for you to chew on: did you know that Concourse uses Concourse to deploy Concourse? Its true! You can check out our publishing pipelines here: https://ci.concourse-ci.org/teams/main/pipelines/main?groups=publish</p>"},{"location":"blog/2018-03-08-were-switchin-domains/","title":"We\u2019re switchin\u2019 domains.","text":"<p>(UPDATE March 9 @ ~10 AM: The old domain appears to now be hosting a very old snapshot of our website. This is either targeted or part of a phishing scam. Do not go to it.)</p> <p>Well, that sucked.</p> <p>Wednesday morning I woke up to a ton messages because Concourse\u2019s site was gone, and in its place was a blank domain registrar placeholder.</p> <p>Before you say anything, I totally remembered to renew the domain. It was due to expire in August. Not even close to expiring.</p> <p>As far as I can tell, our registrar just didn\u2019t do the one thing it\u2019s supposed to do: renew the damned domain. They took the money, bumped the expiry date on the website, and\u2026apparently stopped there. They had literally one job and they didn\u2019t do it.</p> <p>{{&lt; youtube src=\"https://www.youtube.com/embed/4T2GmGSNvaM?start=39\" &gt;}}</p> <p>So some Joe Schmoe out of Macedonia went ahead and registered it somewhere else, presumeably to act as part of some spam network (the only thing set up were MX records). We contacted the new registrar\u2019s abuse email and they basically told us that the domain was registered normally, not transferred, and must have been available. And that there is nothing they can do.</p> <p>I contacted our registrar, and the latest word is this:</p> <p>We are contacting Domain Authorities in Ivory Coast to know more about this. I will contact you back as soon as possible.</p> <p>Soooo at this point I\u2019m calling the domain a loss. I\u2019m giving up pretty easily here for a reason: the .ci TLD is under the authority of the Ivory Coast and has next to zero legitimate registrars willing to reserve domains for it. I could tell from day one that my registrar was hot garbage, but didn\u2019t find any other choices.</p> <p>It seems like the registrar messed up so badly that there\u2019s not much leverage for getting it back. Even if I could get it back, I don\u2019t really want to deal with something like this again in the future. Luckily, before we got too big I went ahead and registered concourse-ci.org, .net, and .com in case something like this happened.</p> <p>So here\u2018s our new home: https://concourse-ci.org</p> <p>I\u2019d already been considering this switch for a while (anticipating trouble with .ci), but a more graceful transition would have been nice. Unfortunately there is a ton of material pointing to the old website, and it\u2019ll probably take time for the new location to bubble up in Google search results.</p> <p>I want to highlight that this doesn\u2019t seem to have been a targeted attack, but that you should be careful to not accidentally go to the old domain or send any traffic or emails there. It may not be a targeted attack, but the new owner still has full control over it, and they\u2019re receiving a bunch of free traffic. I wouldn\u2019t be surprised if they wisened up and pulled something nefarious.</p> <p>We really appreciate the support y\u2019all have shown us, and all the folks who offered to help. Sorry for the trouble.</p>"},{"location":"blog/2018-03-09-concourse-update-mar-59/","title":"Concourse Update (Mar 5\u20139)","text":"<p>Whelp, that felt like a long week. If you haven\u2019t heard the news by now you should definitely read Alex Suraci\u2019s post regarding our domain.</p> <p>I want to take this time to thank the Concourse fans out there who offered their help, support, and positive vibes throughout the whole ordeal. The team here really appreciates it \ud83d\ude4f</p> <p>Luckily for us this event didn\u2019t consume our entire engineering team. We WERE able to get some issues resolved this week and are planning for an imminent release of Concourse 3.9.2</p> <p>On to the update:</p> <p>UX:</p> <ul> <li>Resolved #1841 \u201cANSI cursor escapees wreak havoc with Concourse   build output\u201d</li> <li>Resolved #1999 where buttons weren\u2019t working on the build page   when using Firefox</li> <li>Experimented with adding scroll effects to pipeline names in the   Dashboard #2026. It was hilarious and many \\&lt;marquee&gt; jokes   were made.</li> <li>Brought back the/dashboard route to app #2051, which should make   you be able to login again #1801</li> </ul> <p>Docker Image Resource</p> <ul> <li>Fixed #170. According to GitHub, I\u2019m the original   author of that, but I honestly can\u2019t remember writing it. I do remember that it was supposed to help a Concourse   user, so hurrah!</li> </ul> <p>Runtime</p> <ul> <li>Resolved #2031 \u201ccannot_invalidate_during_initialization   constraint bubbles up to the user\u201d</li> <li>Resolved #2059   and#2058, two similar issues that influenced our decision to   make a 3.9.2 patch release</li> <li>Resolved #1499, tasks occasionally failing when interacting with   Vault</li> </ul>"},{"location":"blog/2018-03-16-concourse-update-mar-1216/","title":"Concourse Update (Mar 12\u201316)","text":"<p>Its been a first week in a long time where we were back to full strength and fully co-located. It was nice!</p> <p>Oh, and Concourse v3.9.2 was released this week as well,check it out!</p> <p>On to our update:</p> <p>UX</p> <ul> <li>Started to make our dashboard a bit more mobile friendly #1712</li> <li>Started to tackle the problem where our dashboard holds too many open   connections #1806</li> </ul> <p>Core</p> <ul> <li>Removed a dependancy to provide an external URL for fly   execute #2069. To   quote Alex Suraci:</li> </ul> <p>\u201cIt also makes the \u2018getting started with Docker\u2019 flow a bit complicated on platforms like Darwin where Docker is actually run via a Linux VM, in a separate namespace. fly execute can't be made to automatically work; the container IP would probably work for fly execute but isn't really what they should be setting as the external URL (as they can't reach it from their own machine).\u201d</p> <ul> <li>Continued our refactoring of Concourse APIs to support multiple teams</li> </ul> <p>Runtime</p> <ul> <li>Completed work on #2070, making it so that workers can retry   against multiple TSAs</li> <li>Picked up a reported issue around custom resources on tagged   workers #1371. We\u2019re not quite sure how it got so bad</li> </ul> <p>Docs</p> <p>We\u2019ve been working on a new website! The focus of it is to make it less flashy, less marketing, and more content driven. The design of it is still in progress but we want to start sharing it out very soon \ud83d\udc4d</p>"},{"location":"blog/2018-03-23-concourse-update-april-1923/","title":"Concourse Update (April 19\u201323)","text":"<p>Hi folks,</p> <p>Had an interesting week talking to customers about how we might improve their Concourse operations and deployments. More info on that soon!</p> <p>On to the update:</p> <p>UX</p> <ul> <li>Fixed an issue with timestamps #2088</li> </ul> <p>Core</p> <ul> <li>Continued our refactoring of the API to support dex and   users #1888</li> </ul> <p>Runtime</p> <ul> <li>Finished the issue around custom resources on tagged workers, it should work   now #1371</li> <li>Restricted the list of allowed TLS ciphers for more security   checkboxing #1997</li> </ul> <p>Design</p> <p>And now, some words from our Product Design team:</p> <p>Lindsay Auchinachie and Sam Peinado are continuing work on the Space and Causality features in Concourse.The Space features give users the ability to have arbitrary build matrixes within one pipeline and of a resource to solve for the pain around people testing many variations/combinations. Causality allows users a view into what is going through the pipeline, and how far it has made it through the pipeline. Read the proposals for Spatial Resource Flows and Resource Causality Flow on GitHub. This week we shared out our Space framing and talked through feasibility and technical constraints of this with the engineering team. Started work on a small Invision with the current Ruby and Git use case. Pairing with engineering next week to define additional more complex uses cases for coding a prototype with real pipeline.</p>"},{"location":"blog/2018-03-29-a-renewed-focus--community-changes/","title":"A renewed focus & community changes","text":"<p>Phew, we\u2019ve been busy for the past couple of months! There\u2019s a lot to give y\u2019all an update on.</p>"},{"location":"blog/2018-03-29-a-renewed-focus--community-changes/#new-website","title":"New website","text":"<p>First off, check out our new website! We\u2019ve completely redesigned it and redone how we organize the documentation, in hopes that it\u2019ll be much easier to find what you\u2019re looking for.</p> <p>We also hope that the new style, language, and tone will feel a bit more inclusive and humble. For example, we got rid of the \u201cConcourse vs.\u201d section \u2014 the effort it took to keep that up-to-date is better spent elsewhere. Use whatever dang tool you want! Our old site, as pretty as it was, felt a bit too much like we were trying to sell a finished product.</p> <p>We\u2019ve added an \u201cAbout\u201d page which provides all the background and motivation you should need to get a good idea of who we are and what we\u2019re about. There\u2019s also a \u201cContribute\u201d section which contains reference material for developers as well as general guidance. We\u2019re also fleshing out an \u201cOperation\u201d section which should help out those who are deploying Concourse for the first time or managing it at scale.</p> <p>In addition to these new sections, we\u2019ve also consolidated many pages and simplified the organization. There are now top-level sections for all the \u201cthings\u201d you\u2019ll be working with (Pipelines, Tasks, etc.), and each section contains the schema right up-front with examples to the side. This should make the docs much more effective when used as a reference.</p> <p>Search is back, and we\u2019ve made a lot better than it was before its unceremonious removal. Try searching \u201cimgrespar\u201d and you\u2019ll find image_resource.params. It\u2019s not full-text, but there\u2019s always Google for that. I tried but it\u2019s pretty slow and janky.</p>"},{"location":"blog/2018-03-29-a-renewed-focus--community-changes/#community-platform-changes","title":"Community platform changes","text":"<p>Along with the new site, we\u2019re changing a few things in an effort to foster a healthier, more collaborative community:</p> <ul> <li>There\u2019s a new community forum! This will   be a much better format for support, long-form discussion, announcing cool new resource types, and whatever else y\u2019all   want to talk about.</li> <li>We\u2019re switching from Slack to Discord! We hope to have   this new chat platform be an organized place for contributors to have meaningful discussions, rather than a firehose   of help requests. There\u2019s still a #need-help channel, but we\u2019d prefer if most support went through the forums instead,   as persistent threads are much easier to keep tabs on and are much easier to find in Google search results.</li> <li>We\u2019ve got a publicly visible roadmap! This is thanks to a tool   called Cadet, which provides visibility into each of our GitHub projects (which are   normally hidden on GitHub). It also provides a networked view of issues and PRs that helps us identify the \u201cboulders\u201d   vs. the \u201cpebbles\u201d when it comes to understanding problem spaces to tackle.</li> </ul>"},{"location":"blog/2018-03-29-a-renewed-focus--community-changes/#simpler-deployment","title":"Simpler deployment","text":"<p>We\u2019ve coordinated all this with the launch of 3.10.0, which simplifies how Concourse is deployed. We\u2019ve made it easier to spin up a single-instance Concourse via the quickstart command, which we\u2019re in turn using for the quick intro on the front page, via Docker Compose. We also no longer require you to configure an external URL (which was the main obstacle in the way of a single-command intro).</p> <p>Instead of documenting four different deployment methods (and scaring away people in the process), we\u2019re focusing on the concourse binary distribution as the lingua franca on the main site. It\u2019s the most general and assumes the least about how you want to deploy it. For platform-specific documentation, each GitHub repo will be the source of truth:</p> <ul> <li>Concourse BOSH Deployment</li> <li>Concourse Docker</li> <li>Concourse Helm Chart (official soon)</li> </ul> <p>These repos are linked to by the \u201cDownload\u201d page as their own platform alongside the binaries, so they should feel just as official, while not feeling like a necessary mental hurdle for beginners.</p>"},{"location":"blog/2018-03-29-a-renewed-focus--community-changes/#halp","title":"HALP","text":"<p>Lastly, I want to apologize for the recent slowdown in processing pull requests. I\u2019ve been pretty focused on getting all this out there, and it\u2019s definitely taken away from my other duties.</p> <p>I hope that with our continued focus on community building in 2018, more of these responsibilities can be shared among a broader, stronger network of contributors. If you\u2019re interested in stepping up and helping out in a meaningful way, let us know early and we can help! That\u2019s part of the reason for introducing Discord and the forums.</p> <p>We\u2019re still figuring things out, and hope to provide more structure to the contribution process for those who need it, but a conversation is a great start.</p> <p>As always, thanks everyone for your patience and support.</p> <p>Alex</p>"},{"location":"blog/2018-04-06-concourse-updates-april-26/","title":"Concourse Updates (April 2\u20136)","text":"<p>If you haven\u2019t done so already please check out Alex Suraci\u2019s recent update post on \u201cA renewed focus &amp; community changes\u201d. It covers all the recent changes that we\u2019ve been making; starting with the new styling of the website, our new discussion forum, and our migration to Discord chat.</p> <p>Specifically, we\u2019ve been getting some mixed feedback on the new format of the site. Some folks love it, other folks miss the highly visual styling of the old site. As always, the Concourse team is always open to hearing your feedback in the usual channels. If you\u2019d like, you can even open issues against the docs repo itself here.</p> <p>And now, on to the update:</p> <p>UX:</p> <ul> <li>Finished up #1806 where our dashboard keeps spamming the ATC and   the db with connection requests.</li> </ul> <p>Core</p> <ul> <li>Started to spike on the spatial resource visualization, you can follow along   at #2131</li> </ul> <p>Runtime</p> <ul> <li>Tackling the large story on adding batch volume &amp; container deletion to a worker #2109</li> </ul> <p>PRs</p> <p>Apologies to everyone who\u2019s been waiting for feedback on their PRs. Alex Suraci has been working down the list this week; so we\u2019re slowly making our way down the list and merging them in.</p>"},{"location":"blog/2018-04-13-concourse-update-april-913/","title":"Concourse Update (April 9\u201313)","text":"<p>Concourse v3.11.0 came out today! Go get it: https://concourse-ci.org/download.html#v3110</p> <p>On another note: I\u2019ve noticed some interesting articles and guides come out on writing custom resources for Concourse. There\u2019s one on the Pivotal blog https://content.pivotal.io/blog/developing-a-custom-concourse-resource and another from fellow Medium writer Shin Myung Yoon (https://itnext.io/writing-a-custom-resource-for-concourse-detecting-pull-request-close-merge-events-e40468eb2a81)!</p> <p>Topher Bullock and I will also be travelling to Boston next week for CF Summit 2018. We\u2019ll be around to meet some Pivotal PCF customers and answer questions about Concourse. Make sure you visit some of the awesome talks on Concourse as well. You can find some articles about it on the Cloud Foundry blog:</p> <ul> <li>https://www.cloudfoundry.org/blog/5-cloud-foundry-summit-sessions-developers-build-cicd-practice/</li> <li>https://content.pivotal.io/blog/dialing-platform-ops-to-eleven-5-cloud-foundry-summit-sessions-that-operators-shouldnt-miss?_lrsc=96881456-a782-4c9e-999a-3be986b65b16&amp;utm_source=employee-social&amp;utm_medium=twitter&amp;utm_campaign=employee_advocacy</li> </ul> <p>Fun fact: we got some new stickers printed up and we\u2019ll be handing some out at Summit:</p> <p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--April-9-13-/1-cS-JeBD00f0h7vhlpYTE7w.png\" alt=\"\" width=\" 20%\" &gt;}}</p> <p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--April-9-13-/1-thrSlXnAzYewzqirHjukWA.png\" alt=\"Whee!\" width=\" 20%\" &gt;}}</p>"},{"location":"blog/2018-04-27-concourse-update-april-2327/","title":"Concourse Update (April 23\u201327)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--April-23-27-/1-1T4dM1zWpCx5NvHFnhK2Lw.jpeg\" alt=\"\" width=\" 100%\" &gt;}}</p> <p>Well, that was fun! Topher Bullock absolutely killed it last week on the CF Summit 2018 main stage with his demo of the experimental Concourse \u2764 \ufe0fK8s runtime project. We also had a great time talking to companies who were using Concourse to continuously do things in the cloud. One of my favorite talks was from Jason Immerman and Derek Van Assche from Zipcar (Concourse All the Things, All the Time); really inspirational stuff!</p> <p>Now, on to the update.</p> <p>We released Concourse v3.12.0 earlier this week. As usual it contains a lot of new improvements; but notably this release fixes the earlier memory leak reported in v3.11.0. A few things to highlight:</p> <ul> <li>We\u2019ve been doing some work behind the scenes to improve our GC behaviour on workers. To do this we\u2019ve started work on   distributing container/volume garbage-collection across   workers (#1959). This release has the early signs of this work,   and we expect it to be done in just a few more weeks (tm). However, this DOES mean that you\u2019ll need to open up port   7799 on the worker in order to have workers behave properly with v3.12.0 (please see release notes for more details!)</li> <li>We also pulled in a change that made the git tag fetch behavior toggle-able\u2026a lot of folks were hit by that so thanks   to GH user mdomke for the quick change!</li> <li>We think we finally hunted down some weird UI issues where certain versions of Chrome / Safari didn\u2019t let you click   into jobs. Let us know how that goes for ya\u2019ll when you upgrade!</li> </ul> <p>This week we\u2019ve been cranking away at three key areas:</p> <ul> <li>Working on the visualization to spatial   resources https://github.com/concourse/concourse/issues/2131</li> <li>Building out Users in Concourse with   dex https://github.com/concourse/concourse/issues/1888</li> <li>Distributing GC across   workers: https://github.com/concourse/concourse/issues/1959</li> </ul> <p>On the design front, our team has been working on something that we call \u201cdesign snacks\u201d; minor changes to the UI that could make big improvements to the overall experience with the app. Given our current tracks of work, we may not be able to pick them up right away, but at least the designs are attached to issues for contributors to pick up; if they felt so inclined :D</p> <p>A few examples:</p> <ul> <li>Concourse pipeline groups should be   responsive https://github.com/concourse/concourse/issues/2130</li> <li>Breadcrumb on Nav   Bar https://github.com/concourse/concourse/issues/2139</li> <li>Paused jobs should indicate they\u2019re paused on the build page(scroll to the bottom for that   one https://github.com/concourse/concourse/issues/1915</li> <li>Build-level   commenting https://github.com/concourse/concourse/issues/2025</li> </ul> <p>As always, feel free to jump into the discussion on our forum (https://discuss.concourse-ci.org/) or on Discord (https://discord.gg/MeRxXKW)</p>"},{"location":"blog/2018-05-04-concourse-update-april-30--may-4/","title":"Concourse Update (April 30 \u2014 May 4)","text":"<p>I\u2019ve gotten some questions about Freedom Friday from some readers after last week\u2019s update. Well it turns out thatTopher Bullock wrote a great article about it this week; you read up on it here: https://medium.com/concourse-ci/freedom-fridays-319204dea834</p> <p>We also release Concourse v3.13.0 earlier this week. Make sure you check it out if you were hit by the accumulating logs issue introduced in v3.12.0.</p> <p>On to the update:</p>"},{"location":"blog/2018-05-04-concourse-update-april-30--may-4/#space","title":"Space","text":"<p>We\u2019ve been building out some of the frontend code for representing Spaces as part of #2131. You can see some of the early visualizations below:</p> <p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--April-30---May-4-/1-K13pFduQtcsPeX3VH6crQQ.png\" alt=\"\" width=\"100%\" &gt;}} {{&lt; image src=\"/images/downloaded_images/Concourse-Update--April-30---May-4-/1-_ndF5rSNwVlKJWTj2_vxUQ.png\" alt=\"\" width=\"100%\" &gt;}} {{&lt; image src=\"/images/downloaded_images/Concourse-Update--April-30---May-4-/1-kBELwDyhYQwPchw7J-O0eQ.png\" alt=\"\" width=\"100%\" &gt;}}</p> <p>We now have the capability of testing Space end-to-end i.e. write the yml -&gt; fly sp -&gt; check out the web visualization.</p> <p>EXCITING</p>"},{"location":"blog/2018-05-04-concourse-update-april-30--may-4/#distributed-gc-on-workers","title":"Distributed GC on Workers","text":"<p>We\u2019ve been hacking away on master issue #1959 for distributed GC. If you\u2019ve been following along closely you\u2019ll notice that the number of boxes that we\u2019ve checked has increased\u2026and that\u2019s a good thing! We\u2019re in the final stretches of this work and will be prepping to test them in our internal Concourse \u201cWings\u201d very soon</p>"},{"location":"blog/2018-05-04-concourse-update-april-30--may-4/#user-auth","title":"User Auth","text":"<p>As always, we continue to work on our User Auth master issue #1888. We\u2019ve now transitioned into building out specific auth connectors using the dex library. We\u2019ve completed the GitHub and CF connectors, and are currently working on the generic OAuth provider</p>"},{"location":"blog/2018-05-11-concourse-update-may-711/","title":"Concourse Update (May 7\u201311)","text":"<p>Hi folks,</p> <p>Joshua Winters has spent a lot of time refactoring Concourse so that it can finally support Users. We\u2019re finally at a point where we can share some our work with you, so I\u2019d really encourage you to check out his recent blog post Oh, Auth</p> <p>Outside of that, we\u2019ve got a bunch of vacations going on this week, so it\u2019s been more of the same three tracks of work:</p> <ul> <li>Users</li> <li>Distributed GC on workers</li> <li>Spatial Resource flows</li> </ul> <p>See you next week!</p>"},{"location":"blog/2018-05-18-concourse-update-may-1418/","title":"Concourse Update (May 14\u201318)","text":"<p>In case you missed it, I\u2019d encourage you to check out some of the recent posts from Shashwathi Reddy on \u201cMy first month on Concourse\u201d and Joshua Winters regarding upcoming changes to our authentication; \u201cOh, Auth\u201d. We\u2019d love to hear your feedback!</p> <p>Heads up: the Concourse team will be taking Monday May 21st off for Victoria Dayholiday.</p> <p>And now, on to the update:</p> <p>Core</p> <ul> <li>Continued banging our heads against new auth connectors with Dex. Note: We\u2019ve started to centralize backwards-(in)   compatibilities with user auth in issue #2218</li> <li>We\u2019ve stood up a new Concourse with our experimental Spaces work. We\u2019re looking for volunteers who are interested in   trying out their pipelines before and after \u201cspace\u201d. Tweet at me if you\u2019re   interested https://twitter.com/pioverpi!</li> </ul> <p>Runtime</p> <ul> <li>Completed all the volume collection work for distributed GC   in #1959. We\u2019re currently deploying this change to our internal   environments to see how it works at scale \ud83e\udd1e</li> <li>Fixed issue #2168, wherein \u201cDuplicate resource type volumes   created over time\u201d</li> </ul>"},{"location":"blog/2018-05-25-concourse-update-may-2225/","title":"Concourse Update (May 22\u201325)","text":"<p>It was a short week for us here in Canada, but we had a few interesting updates:</p> <ul> <li>We attempted to deploy our distributed GC changes to our   internal environment \u201cWings\u201d last Friday. Turns out that was an incredibly bad idea. The deployment failed   horrifically and we had to roll back all our changes. We\u2019re still investigating why our code worked in   our \u201cprod\u201d environment but failed when deployed onto Wings. We\u2019re tracking this work   in issue #2202.</li> <li>Our team conducted our first round of interviews on Spatial resources with Pivots in the Toronto office. We\u2019re getting   a lot of interesting feedback and are making tweaks for next week\u2019s batch of interviews</li> <li>In the mean time, we managed to work through some design snacks, addressing the lack   of breadcrumbs   and responsive design on groups.</li> <li>Investigated migration paths forward with the new dex auth. Keep an eye on   issue #2218 for more information on future incompatibilities   with this upgrade!</li> </ul>"},{"location":"blog/2018-06-01-concourse-update-may-28--june-1/","title":"Concourse Update (May 28 \u2014 June 1)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--May-28---June-1-/1-kJxF-3MOSqElyItFT2ec-A.png\" alt=\"\" width=\" 100%\" &gt;}}</p> <p>If you\u2019ve been experiencing \u201cAw Snap\u201d errors on Chrome with Concourse 3.13.0 or 3.12.0 we traced the root case to two lines of CSS. This seems to happen only on Chrome 67; so a temporary workaround is to switch over to Chrome canary or use Firefox/Safari/Edge. You can follow along in our discussion at GitHub issue #2236</p> <p>Now, on to the update</p> <p>Runtime</p> <p>We were able to successfully test our distributed volume GC collection code on our Wings environment this week. Overall we\u2019ve seen a significant drop in Database Queries and a ~10% decrease in Web CPU usage.</p> <p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--May-28---June-1-/1-GfBC0PNc6p2DOiGAbcxKnA.png\" alt=\"\" width=\" 100%\" &gt;}} {{&lt; image src=\"/images/downloaded_images/Concourse-Update--May-28---June-1-/1-n8Ea93MfUmDIGaPLtdU37Q.png\" alt=\"\" width=\" 100%\" &gt;}}</p> <p>Notice how the Database Queries now look like a sawtooth; this is a result of our new \u201cmark and sweep\u201d GC strategy on workers.</p> <p>Core</p> <p>In an effort to make our new Users work backwards compatible and downgrade-able, we spent a good chunk of this week figuring out down-migrations. The conversation around this, and the compromises we\u2019ve had to make can be found in Josh\u2019s follow up comment here</p> <p>UX</p> <p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--May-28---June-1-/1-VzHW0teV3e1DfrqcYWc_-w.png\" alt=\"\" width=\" 100%\" &gt;}}</p> <p>Check out the new breadcrumbs and responsive groups on our prod environment!</p> <p>We\u2019re still looking for users who would be interested in testing out our new spatial resources view! Please reach out to me over Twitter or @jma on Discord if you\u2019re interested!</p>"},{"location":"blog/2018-06-06-how-we-build-concourse/","title":"How We Build Concourse","text":"<p>Building on some of our previous posts on the Concourse team mechanics\u00b9, I wanted to spend some time going over how we actually build Concourse.</p>"},{"location":"blog/2018-06-06-how-we-build-concourse/#tracking-features-and-bugs","title":"Tracking Features and Bugs","text":"<p>Concourse tracks all of its bugs, features and epics through GitHub Issues.</p> <p>For items regarding the core functionality of Concourse itself, you can find the master issues list here: https://github.com/concourse/concourse/issues</p> <p>For issues regarding the Concourse website and documentation, you can find the backlog here: https://github.com/concourse/docs</p> <p>Concourse resources, both the ones included with Concourse and the ones that arecommunity made, live in their own repositories. Issues, bugs and features should be reported against the resource\u2019s GitHub issues repo.</p>"},{"location":"blog/2018-06-06-how-we-build-concourse/#triage-review-and-prioritization","title":"Triage, Review and Prioritization","text":"<p>We do our best to review and triage new issues that come into the Concourse repository on a daily basis. Triaging an issue requires us to:</p> <ul> <li>Identify whether the issue is a bug or new feature (aka enhancement)</li> <li>Identify whether the issue requires more investigation</li> <li>Apply relevant labels for easier search down-the road (e.g. web-ui, fly, security, etc.)</li> <li>Follow up with any questions or comments if issue was unclear</li> <li>Connect issues to related issues already entered previously</li> <li>If applicable, assign to one of the Concourse GitHub Projects</li> </ul> <p>Issues assigned to a GitHub Project are automatically assigned into the project\u2019s Icebox. The Concourse team follows a very similar development approach to XP and Pivotal workflow where only active and prioritized items are assigned to the Backlog, and all finished stories are required to be \u201cAccepted\u201d or \u201cRejected\u201d by a Product Manager or some other knowledgeable subject matter expert.</p>"},{"location":"blog/2018-06-06-how-we-build-concourse/#design-research","title":"Design &amp; Research","text":"<p>Issues that require design and UX feedback are labeled with needs-design. These are usually picked up by our product design team.</p> <p>We also use the label design-snack on bite-sized UX/UI issues that are ready to be picked up by an engineer. design-snacks aren\u2019t highly prioritized issues but are nonetheless very useful for Concourse users!</p> <p>Sometimes we work on big issues that require more research and testing before we can actually write issues. This work is often tracked separately through various tools (both online and offline). We do our best to post updates in blog posts and GitHub issues along the way.</p>"},{"location":"blog/2018-06-06-how-we-build-concourse/#iteration-planning-meeting-ipm","title":"Iteration Planning Meeting (IPM)","text":"<p>The Concourse team conducts IPM every week on Monday afternoon. During this time we review each GitHub Project\u2019s backlog. This includes discussions on stories that were recently complete, are currently in flight, new stories added to the backlog and any change in Backlog priorities. The Concourse team uses this custom-build project view (https://project.concourse-ci.org/) as a way to quickly access the backlogs of all our projects.</p>"},{"location":"blog/2018-06-06-how-we-build-concourse/#acceptance","title":"Acceptance","text":"<p>Issues that are resolved are moved into the \u201cDone\u201d column of each project. This means that the issue is ready to be reviewed for Acceptance. Typically, work that is ready for acceptance is reviewed on our \u201cprod\u201d instance, that is, https://ci.concourse-ci.org/ The issue is typically reviewed by a product manager or a subject matter expert who can determine whether the completed issue is acceptable for general distribution. Some changes require additional load and/or \u201creal-world\u201d testing; in that case we deploy to Pivotal\u2019s internal large-scale Concourse \u201cWings\u201d; which currently runs 3 ATCs, 38 workers and has &gt; 70 teams.</p> <p>Rejected issues are returned to the top of the GitHub Project Backlog and commented on for revision.</p>"},{"location":"blog/2018-06-06-how-we-build-concourse/#prcommunity","title":"PR/Community","text":"<p>PRs and \u201cCommunity\u201d work (e.g. answering questions on Discord, our Forum, in GitHub issues) is usually handled by a dedicated person. Currently this person is Alex Suraci (Product Manager). In addition to helping the community, he is building out new proposals for long-term changes to Concourse in the RFCs repo.</p>"},{"location":"blog/2018-06-06-how-we-build-concourse/#what-do-we-build","title":"What do we build?","text":"<p>In my next blog post, I plan on covering what the core team is working on, how we make those decisions, and how we are working to make those plans more obvious</p> <p>\u00b9 see The Concourse Crew andHow the Concourse Team Organizes Issues</p>"},{"location":"blog/2018-06-08-concourse-update-june-48/","title":"Concourse Update (June 4\u20138)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--June-4-8-/1-XZfbfSSmYOJi2Ujc1uDP7Q.png\" alt=\"\" width=\" 100%\" &gt;}}</p> <p>Big release this week! After lots internal load testing on Wings we finally felt comfortable releasing Concourse 3.14.0. In addition to the new Distributed Garbage Collection, breadcrumbs, responsive groups, and Windows worker, we have 14 new features a whole bunch of bug fixes. But wait! Don\u2019t download that one; get Concourse v3.14.1 instead.</p> <p>A few other updates. First, be sure to check out my write up on How We Build Concourse. I plan on writing more posts like this in hopes of giving you more insight into the internals of the Concourse team. Hope you like it!</p> <p>And now, on to the update; starting with a note on RFCs:</p> <p>RFCs</p> <ul> <li>We\u2019re looking for feedback on how to improve our existing implementation of credential management. You can read more   about it in issue #5.</li> <li>The RFC around Resources v2is moving along with some new changes. Thanks   to all the reviewers (itsdalmo, cwlbraa   and dprotaso). I\u2019d REALLY encourage ya\u2019ll to read   the full proposaland provide your   inputs; since we\u2019ll be relying on these changes for new features like Spatial Resources.</li> </ul> <p>UX</p> <ul> <li>We\u2019re seriously, absolutely, most definitely tacking the slow performance on the build   page #1543</li> <li>Spatial Resource testing continues! Here\u2019s a peek at our most recent iteration:   {{&lt; image src=\"/images/downloaded_images/Concourse-Update--June-4-8-/1-C8RdmEmjBxrG5pzamGDMSg.png\" alt=\"\" width=\"   100%\" &gt;}}</li> </ul> <p>Core</p> <ul> <li>Now that 3.14.1 is out, we\u2019re now ready to rebase and merge in our Users change and prime that for release in 3.15.0.   Testing begins next week after we finish getting everything merged in</li> </ul>"},{"location":"blog/2018-06-15-concourse-update-jun-1115/","title":"Concourse Update (Jun 11\u201315)","text":"<p>This was a post-release week, so we spent a lot of time merging in new code from the Users track, fixing our pipelines, and working on some neglected issues. All in all a solid week\u2019s worth of work! On to the update</p> <p>UX</p> <ul> <li>Changed the behaviour of the breadcrumb so that clicking on the pipeline name resets the pipeline view and group   settings (#2258)</li> <li>Fixed a bug with the breadcrumb where it wouldn\u2019t render whitespace   correctly (#2267)</li> <li>Fixed a bug with team name overflowing on breadcrumbs (#2241)</li> <li>Fixed a UI bug on the navigation arrows (#2276)</li> <li>Added JSON stdout to Fly CLI (#952)</li> </ul> <p>We haven\u2019t done work on this yet, but based on our observations and feedback from the community, we\u2019re planning to push the dashboard up to / level. This will require a few items of polish first; but you can refer to issue #2282 for details</p> <p>Core</p> <ul> <li>Spent most of the week trying to rebase and merge in changes from the Users track. Our pipelines are finally green so   we\u2019re ready to push some of that work into our local environments for broad testing. Be sure to check up   on #2218 for any gotchas that might affect you!</li> </ul> <p>Space</p> <ul> <li>Conducted two user interviews this week. We have only have one or two more interviews left next week. After that we\u2019ll   be figuring out what our MVP might look light so we can start exposing that feature to adventurous Concourse users.</li> </ul> <p>RFCs</p> <p>As with last week, we\u2019re looking for feedback on how to improve our existing implementation of credential management. You can read more about it in issue #5.</p> <p>The RFC around Resources v2is moving along with some new changes. Thanks to all the reviewers (itsdalmo, cwlbraa and dprotaso). I\u2019d REALLY encourage ya\u2019ll to read the full proposaland provide your inputs; since we\u2019ll be relying on these changes for new features like Spatial Resources.</p>"},{"location":"blog/2018-06-22-concourse-update-jun-1822/","title":"Concourse Update (Jun 18\u201322)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Jun-18-22-/0-iPsCYY5ob7h-bSKD.jpg\" alt=\"\" width=\"100%\" &gt;}}</p> <p>It\u2019s been a busy week for myself and Topher Bullock. We spent some time in Boston meeting with some users operating large-scale Concourses. We learned a lot about the issues they were running into operating Concourse a scale\u2026and we ate a lot of Lobster!</p> <p>On to the update:</p> <p>UX:</p> <ul> <li>Made some improvements to the build page in issue #1543 that   we\u2019re hoping to test soon on our internal Concourse. You can read into some more of the details in   our comments.</li> <li>Expanded our PR pipelines in #2305 to run web tests as a part of   pulling in the PR for Shareable Search on dashboard #2265.</li> <li>Started the move of the dashboard/ view to be the root level page (   issue #2282) by adding Logout to the dashboard page   in #1663</li> </ul> <p>Core</p> <ul> <li>Continued our struggle to finish off Users work with some fixes to migrations and breakages to our own testing   pipeline</li> <li>Continued with our user testing on Spatial Resources. We\u2019re getting more confident with the designs, so we added a   story to bring those designs into beta/ in issue #2292</li> </ul>"},{"location":"blog/2018-06-29-concourse-update-jun-2529/","title":"Concourse Update (Jun 25\u201329)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Jun-25-29-/1-eGvw-f2AjgJvsWN9pdikBg.gif\" alt=\"\" width=\" 25%\" &gt;}}</p> <p>If you\u2019ve been following along with our Auth changes, you\u2019ll know that we\u2019ve been doing a lot of work behind the scenes to make the upgrade into this new world as seamless as possible. This week, we were able to do our first large-scale upgrade test against our Wings instance. The upgrade went well and we were able to find a few more areas of polish before we push this feature. You can find our updated list of future incompatibilities in GitHub issue #2218. Having considered the nature of the breaking changes, the next update of Concourse with Users will push us into4.0.0!!!</p> <p>I also wanted to take this time to give a big thank you to all of the participants in our spatial resource interview. If you\u2019re curious to see the results of our research please read up on Lindsay Auchinachie\u2019s post here:Designing for Space in Concourse</p> <p>If you\u2019d like to get your hands on Space as soon as possible, then I\u2019d encourage you to also read and comment on our Resources v2 RFC. Alex Suraci made some recent updates to the proposal so definitely check it out, or read the fully rendered proposal.</p> <p>We\u2019d like to get the Resources v2 RFC closed out soon so we can implement the resource changes necessary to tap into the full potential of spatial resources!</p> <p>Some other updates:</p> <ul> <li>We fixed a known issue #2300 with the 3.14.x series whereby users noticed a significant   increase in CPU usage when connecting with CredHub. This has now been fixed</li> <li>Increased pipeline stability and fixed some flakes with our UI tests in topgun</li> <li>Fixed an issue where the auth token is shown in the address bar</li> <li>Picked up additional pipeline work by adding integration   for web PRs</li> </ul> <p>Edit</p> <p>I ALMOST FORGOT! We also improved build page performance #1543! In some instances we reduced the page load time from 25s to only 5s:</p> <p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Jun-25-29-/1-KEWandpQWRWRFcBvLRwbog.jpeg\" alt=\"\" width=\" 100%\" &gt;}}</p>"},{"location":"blog/2018-07-06-concourse-updates-july-36/","title":"Concourse Updates (July 3\u20136)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Updates--July-3-6-/0-BrjbFvtgpagi0Ag3.png\" alt=\"Concourse, beavers, poutine and maple syrup\" width=\"100%\" &gt;}}</p> <p>Since July 1st was the official day of Canada\u2019s birth, the Concourse team enjoyed a long weekend with no work on Monday. We were, however, able to get quite a bit done during this short week.</p> <p>A big win is that we added a k8s-testflight job to our official ci pipeline (check it out here); this will let us know in advance when we have broken the Concourse Kubernetes Helm Chart. Shout out to Divya Dadlani, Jamie Klassen and Rui Yang for working on that in the Concourse team!</p> <p>Here\u2019s also a few interesting reminders:</p> <ul> <li>For Pivotal-supported releases of Concourse (aka Concourse for PCF) you can find a compatibility matrix of common   dependencies   here: http://docs.pivotal.io/p-concourse/#Compatibility</li> <li>I realized this week that not a lot of people know about this; but Alex Suraci   wrote up a series of Concourse Anti-Patterns a while   back. Its definitely worth the read</li> <li>PLEASE take a second to review the upcoming Resource v2 RFC or its   rendered version here</li> <li>Concourse team is going to OSCON! Come by the Pivotal booth 406 and say \u201chi\u201d!</li> </ul> <p>Anyways, on to the update:</p> <p>UX</p> <ul> <li>Fixed some minor UI issues across the   board: #2333, #2313, #2291,   and #2310</li> <li>Continued our work in routing Dashboard page to the Home page   in #2282. This, however, has turned into a bit of a scope creep   and we are now upgrading the entire UI to use the new dark theme:   {{&lt; image src=\"/images/downloaded_images/Concourse-Updates--July-3-6-/1-Xp51wHexBz5wx1GcqaCvwA.png\" alt=\"\" width=\"   50%\" &gt;}}</li> </ul> <p>Core</p> <ul> <li>Discovered some additional backward incompatibilities with the new user-based auth that would be super annoying to   deal with; so we have addressed some of them   in#2326, #2299   and #1810. As always, you can read about future   incompatibilities with our new auth in issue #2218</li> <li>Alex Suraci had some time to pick up some low-hanging performance-improving fruit   in #285</li> </ul>"},{"location":"blog/2018-07-13-concourse-update-jul-913/","title":"Concourse Update (Jul 9\u201313)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Jul-9-13-/1-AuH8VYkniNetbpZtRBjTuA.png\" alt=\"DARK\" width=\" 100%\" &gt;}}</p> <p>We\u2019re going dark themed for Concourse 4.0.0! In addition to the users work, we\u2019re promoting the Dashboard to the / level to take over the home page. You\u2019ll also notice that we added pipeline play/pause capabilities to the dashboard, NEAT!</p> <p>To keep things consistent, we\u2019re also propagating our new design to the existing pipeline views. You can play around with this new nav structure on our own CI: https://ci.concourse-ci.org/</p> <p>The team here is also planning to attend OSCON in Portland next week (July 18 &amp; 19). Drop by the Pivotal booth to say hi and grab a Concourse sticker!</p> <p>On to the update:</p> <p>UX</p> <ul> <li>Fixed some resource alerting errors on the pipeline #2333</li> <li>Moved dashboard to home #2282</li> <li>Added Pause/Play pipeline buttons on homepage #2365</li> <li>Worked on dragging to re-order pipelines on the dashboard #2364</li> <li>Updated and propagated the new colours across the app #2370</li> </ul> <p>Core</p> <ul> <li>Added health check APIs to verify credential managers are properly   configured #2216</li> <li>Even more db optimizations! yay!</li> </ul> <p>Runtime</p> <ul> <li>Picked up an oldie but a goodie: Concourse should support imposing limits on container   resources #787</li> </ul> <p>Operations</p> <ul> <li>Started to move our stemcells onto the   new Xenial stemcells</li> <li>Switch upgrade/downgrade testing jobs to the binaries #2371</li> </ul>"},{"location":"blog/2018-07-20-concourse-update-jul-1620/","title":"Concourse Update (Jul 16\u201320)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Jul-16-20-/1-CIxNgJ_FKbnacEpUI588nw.jpeg\" alt=\"\" width=\" 100%\" &gt;}}</p> <p>This week, the Concourse team went out to Portland to attend OSCON 2018. Topher Bullock gave a great intro to Concourse in the Open Source track. We even met some of the Concourse fans in person!</p> <p>In other news, we\u2019ve begun to sketch out what RBAC might look like in Concourse. Please check out #2389 when you have some time!</p> <p>On to the update:</p> <p>UX</p> <ul> <li>Team has been working on adding drag and drop re-arranging for the dashboard   in #2364</li> <li>We also found a weird quirk with the new team creation flow, where you won\u2019t see your team if it was just created and   has no pipelines. We will be addressing this in #2382</li> <li>Play/pause pipeline on the dashboard is mostly completed but was missing functionality when a search filter was   applied; so I had to reject that story for review in #2365</li> <li>Lindsay Auchinachie has also been entering some new UI polish issues to co-incide   with our new dark   theme: #2370, #2385, #2387, #2361</li> </ul> <p>Core</p> <ul> <li>Picked up some stories related our migrations, see #2380   and #2074</li> <li>Keen watchers of our repo will notice that we\u2019ve added a note in   our core backlog   to start sketching out what additional work we need to get space moving along.</li> <li>Reminder to check out and comment on   the Resources v2 proposal!</li> </ul> <p>Integrations</p> <ul> <li>We closed #215 in the docker-image-resource recently   after we discovered a regression with a newer version of Docker. This seems to only affect large-scale Concourse   installations that have reliability issues accessing and connecting to their local registries. A short-term fix is to   target older versions of the docker-image-resource</li> </ul> <p>Runtime</p> <ul> <li>Addressed #1516, wherein Concourse doesn\u2019t run any jobs if Vault   misconfigured</li> <li>Did some work to begin imposing limits on containers in #787.   Please review this issue carefully if this affects you; since our initial resolution is very specific and requires you   to understand the nature of your worker vms</li> <li>Worked on #2375 \u201cListing destroying volumes should not perform   any database write operations\u201d :D</li> </ul>"},{"location":"blog/2018-07-27-concourse-update-jul-2327/","title":"Concourse Update (Jul 23\u201327)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Jul-23-27-/1-tfhJwBRSLe9wrc2-a7MwpQ.png\" alt=\"Concourse v4 Dashboard\" width=\"100%\" &gt;}}</p> <p>I\u2019m happy to announce that we released Concourse 4.0.0 this week! This was a HUGE release with over 28 new features and fixes. I\u2019d encourage you to read through the full list of changes on our Downloads page.</p> <p>Why did this release warrant a bump in the major version? Well, if you\u2019ve been following along closely you\u2019ll know that we had just finished our new auth work in 4.0.0. Users are now central to the authentication flows, not teams. Practically speaking, the user-centric auth flow means that you won\u2019t need to re-login to see pipelines in other teams that you already have access to! Underneath the hood though, \u201cWe\u2019re leveraging CoreOS\u2019s Dex project for all the moving parts, which already supports a ton of providers (Dex calls them \u201cconnectors\u201d). The only delta required for Concourse to support a Dex connector is a tiny bit of glue code in our new Skymarshal component to provide higher-level flags for our CLI.\u201d</p> <p>We spent a lot of time near the end of this cycle trying to make these changes backwards compatible, but ultimately decided that the changes were significant enough to warrant a bump in the major version. PLEASE PLEASE PLEASE refer to our release notes for all the breaking changes before executing your upgrade!</p> <p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Jul-23-27-/1-A7zDAYYisJzHjZldrxqneg.gif\" alt=\"\" width=\" 50%\" &gt;}}</p> <p>The second big change you\u2019ll notice in 4.0.0 is that the home (/) route now takes you to the dashboard. We\u2019ve also propagated the new colour scheme to the rest of the app and tightened up the fonts throughout the app.</p> <p>We hope you like it!</p> <p>So, what\u2019s next? We\u2019re focusing on three key areas:</p> <ul> <li>Resources v2 and Spatial resources.   Please review and comment on the RFC!</li> <li>Runtime efficiency &amp; Operational observability   into Concourse</li> <li>Role based access control. That\u2019s right, we\u2019re finally doing it. Please   read the RFC for this change. You can also find a copy of our initial permission   matrixhere</li> </ul>"},{"location":"blog/2018-08-03-concourse-update-july-30--aug-3/","title":"Concourse Update (July 30 \u2014 Aug 3)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--July-30---Aug-3-/1--syJtPB3nj0x2z8AVEh7zA.png\" alt=\"\" width=\" 45%\" &gt;}}</p> <p>With the launch of Concourse 4.0.0, we\u2019ve been monitoring our typical communication channelscarefully to watch out for any glaring new bugs. So far we seem to be safe from any crazy issues, but we have noticed that there has been some confusion in how to set the basic auth users in the new deployment method (see #2421 for details). Thanks everyone for your patience and working through these issues with us!</p> <p>The Concourse team will also be taking Monday, Aug 6 off for Canada\u2019s Civic Holiday. We\u2019ll be back at it on Tuesday, Aug 7.</p> <p>On to the update:</p> <p>UX</p> <ul> <li>You\u2019ll notice that our UX backlog is filled to the brim with clean-up and polish stories. Now that we\u2019ve release   4.0.0, we\u2019re taking some additional time to slow down to perform some additional polish and refactors</li> <li>Of note we have one regression which is prioritized highly \u201cNew resources are no longer highlighted in   UI\u201d #2423</li> <li>A lot of folks have noticed that the sidebar has been removed, and a bid to bring it back has started with   issue #2440</li> </ul> <p>Core</p> <ul> <li>We\u2019ve been working on a track of stories around \u201cpinning\u201d a version of a resource across the   pipeline #2439   and #2386</li> <li>Database migrations have always been a headache for us and we\u2019ve been looking at   issues #2074   and #2452</li> </ul> <p>Runtime</p> <ul> <li>We finally got rid of Yeller support #1819. I have no idea what   that did, or why it was there; but good riddance</li> <li>The much requested feature to stream build logs out is being worked   on #2104</li> </ul>"},{"location":"blog/2018-08-10-concourse-update-aug-710/","title":"Concourse Update (Aug 7\u201310)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Aug-7-10-/1-QBeLayNVacbJGgBW-BhGSw.jpeg\" alt=\"\" width=\" 35%\" &gt;}}</p> <p>As I mentioned last week, this was a short week for us in Canada due to the Civic Holiday. We did, however, manage to work on some pretty cool stuff!</p> <p>With the release of 4.0.0, we\u2019ve been shifting our new feature focus towards Operations and Runtime. We\u2019re intentionally slowing down on UX to focus on regressions and UI polish for existing screens.</p> <p>On to the update:</p> <p>Core</p> <ul> <li>Continued our work on \u201cpinning\u201d a version of a resource across the pipeline.   Completed #2439 but still   have #2386 in flight</li> </ul> <p>Runtime</p> <ul> <li>Wrapping up work around streaming build logs to an external   target #2104</li> <li>Investigated the issue around External Worker affinity on ATCs when using external   workers #2312</li> <li>Picked up the issue for adding a configurable timeout for resource and resource type   checks #2352</li> </ul> <p>Operations</p> <ul> <li>In our continued exploration of k8s Helm Chart for Concourse, we\u2019re looking into how we might auto-magically generate   helm chart parameters #2472</li> </ul>"},{"location":"blog/2018-08-10-suspicious-volume-usage-on-workers/","title":"Suspicious Volume Usage on Workers","text":"<p>As a Product Manger at Pivotal I\u2019m often called on to help with our customer\u2019s Concourse-related issues. I recently spent some time hunting down an issue around suspiciously high volume usage on Concourse workers. It was an interesting problem that I wanted to share with the broader Concourse community.</p>"},{"location":"blog/2018-08-10-suspicious-volume-usage-on-workers/#platform-management-pipelines","title":"Platform Management Pipelines","text":"<p>One of the primary use case for Concourse within the Pivotal Cloud Foundry (PCF) ecosystem is to automate the toil of manual maintenance against the platform; specifically PAS and PKS. For the purposes of this issue, the specific details of the pipeline doesn\u2019t matter but an understanding the general flow of the pipeline will help frame problem:</p> <p>{{&lt; image src=\"/images/downloaded_images/Suspicious-Volume-Usage-on-Workers/1-afxjY-fNHqW6BPik1xdGVQ.png\" alt=\"A simplified version of a pipeline used to pull updates from the Pivotal Network and apply the changes onto Ops Manager\" width=\"100%\" &gt;}}</p> <p>In these pipelines the pivnet-resource is responsible for monitoring new product versions on network.pivotal.io (aka PivNet). When a new product version is released on PivNet, the pivnet-resource picks it up and initiates a download. These files are relatively large, from 500mb to over 1 GB</p> <p>Recreate all the workers?</p> <p>Over the course of the past year or so we would get sporadic reports of customers who used Concourse for PCF management running out of space on their workers. The typical manifestation of it comes from a failed to stream in volume error. It would appear that workers were running out of space; but it wasn\u2019t clear why. To mitigate the issue Concourse operators would be forced to periodically re-create their workers to get a \u201cclean slate\u201d.</p> <p>But why?</p> <p>Having to periodically recreate workers is a huge pain and it doesn\u2019t give operators a lot of confidence in Concourse itself. The team decided to take a look into the root cause of this issue. We wanted to understand whether this was a bug in the system and whether we could do something to address it.</p> <p>After some poking and prodding, I think we figured out what was happening in this specific scenario. Using the same simplified pipeline above, consider the following scenario:</p> <p>{{&lt; image src=\"/images/downloaded_images/Suspicious-Volume-Usage-on-Workers/1-m-1ouUbMQEVv9gPJ3wggug.png\" alt=\"\" width=\" 100%\" &gt;}}</p> <ul> <li>At t=0 the pipeline is configured and idling; monitoring the external system for a new version.</li> <li>At t=1 a new version of the \u201cMetrics\u201d product is released on PivNet, picked up by Concourse, downloaded and begins to   flow through your pipeline</li> <li>At t=2 the Upload to OM (OM == Ops Manager) job kicks off and does its thing</li> <li>At t=3 the artifact is used for some long running process like Apply Changes on OM. Concourse will hold on to that   downloaded data since its still running</li> </ul> <p>But wait, what\u2019s that new Metrics 1.0 box in deep blue at t=3? Well, its not uncommon for the metadata of a release to be modified just-after release. This could be a tweak to metadata (e.g. support dates, dependencies, supported stemcells, etc.), which causes PivNet to report a new version. Semantically, its still reported as Metrics v1.0 but Concourse will pick it up nonetheless. Because of this change we have effectively doubled the amount of storage used!</p> <p>I think we learned a valuable lesson today\u2026</p> <p>The problem I described was a specific to the usage of the pivnet-resource, but there are a lot of common takeaways:</p> <ul> <li>Spend some time to understand your resources! The specific implementation of check can drastically affect your   pipeline</li> <li>Be wary of using large files with long running jobs. I could see how someone could easily re-create a similar scenario   with other resources</li> <li>Consider separating out the act of downloading an artifact from the act of operating on the artifact. For example, I   found that other teams in Pivotal worked around this by landing their PivNet artifacts in an s3 bucket and picking it   up in the next job via the s3-resource</li> <li>Set up some monitoring! You can catch errors and creeping disk use this   in metrics dashboards</li> </ul> <p>No seriously, why does this happen?!</p> <p>In this blog post I covered a lot of the symptoms of the problem and touched on some abstract reasoning on why this happens. In the next blog post we (and by \u201cwe\u201d I mostly mean Topher Bullock) will cover the specific technical details of Resource Caching on Concourse so you can have a better understanding of exactly why this happens.</p>"},{"location":"blog/2018-08-17-concourse-update-august-1317/","title":"Concourse Update (August 13\u201317)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--August-13-17-/1-tElpiP87T2Ee3rXKJP88QQ.gif\" alt=\"Combining repos for great justice\" width=\"45%\" &gt;}}</p> <p>Going to switch things up this week and start with some interesting community news:</p> <ul> <li>We\u2019ve decided to restructure our repositories to make things more understandable and less scary for   contributors. Alex Suraci has laid out a good explainer on why and how we\u2019re   going to start in   our PSA: the Great Code Restructing of 2018</li> <li>Lindsay Auchinachie wrote up a blog post describing some of the visual elements   of the Concourse pipeline view in a blog post   titled Concourse Pipeline UI Explained</li> <li>marco-m has been updating a \u201cconcourse-in-a-box\u201d formula that comes with a s3-compatible-store and a Vault. Check it   out here: https://github.com/marco-m/concourse-ci-formula</li> <li>concourse-up is a Concourse quick-start tool created created by our   friends at EngineerBetter. The team there is looking for feedback on how to support the 4.0.0 authentication scheme   moving forwards. If you use their tool, please take some time to give them some love on their GitHub   issue https://github.com/EngineerBetter/concourse-up/issues/62</li> <li>Is our efforts to have Concourse un-flaky a myth? Find out on this forum post   by eedwards-sk, you won\u2019t believe   post #4!!</li> </ul> <p>On to some development news:</p> <ul> <li>We\u2019re still hacking away at   issue #2425 \u201cLogin session expired\u201d error with multiple ATCs.   Please check in on the story to follow along with our plans for a fix (it involves some migrations)</li> <li>Praise be, we fixed the UX regression on the resources page where new resources weren\u2019t being   highlighted #2423</li> <li>Still refactoring away to make way for #2386 in preparation for   spaces</li> <li>Finished #2352on Configurable timeout for resource checks. Turns   out that by fixing that issue we also fixed #2431. We did end up   making #2494 though in order to break out the specific ability   to configure a timeout for resource type checks.</li> <li>Paused work on #2104 on emitting build logs to an external   system this week, hoping to pick it back up next week!</li> </ul>"},{"location":"blog/2018-08-24-concourse-update-august-2024/","title":"Concourse Update (August 20\u201324)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--August-20-24-/0-9tKyl-ikt-ttbS_z.jpg\" alt=\"Logs and resources\" width=\"25%\" &gt;}}</p>"},{"location":"blog/2018-08-24-concourse-update-august-2024/#kubernetes","title":"Kubernetes","text":"<p>As we continue our sporadic work on Kubernetes and its Helm chart, we\u2019re also starting to expand our thinking to cover the runtime aspects of Concourse + Kubernetes. We\u2019ve already prioritized the need to have Kubernetes as a supporting backend in addition to Garden, but what about the spiffy new developments in the Kubernetes world? We\u2019re hearing a lot about knative and knative services like build and eventing. Are there any kubernetes users who\u2019d like to weigh in on the topic? Let us know on ourforums!</p>"},{"location":"blog/2018-08-24-concourse-update-august-2024/#request-for-comment","title":"Request for Comment","text":"<p>We\u2019ve written a new RFC titled: Mergeresourceandresource_type s. This RFC came about as a result of the work in pinning resources and #2386. You can comment on the RFC PR here</p> <p>We are also stuck on #2104 Streaming of Build Logs to Additional Target. We\u2019re specifically looking on feedback on the following questions before moving forward:</p> <ul> <li>Our test for syslog is flakey: failing/hanging sometimes</li> <li>Need to backfill a test for updating the drained column</li> <li>What metadata do we want to send with the build log? team/pipeline/job/build names?</li> <li>Is there a possibility for the build logs to be reaped before they are drained?</li> <li>What kind of database locks do we need for the operation?</li> </ul> <p>If you have an insight to shed on these questions, please hop on over to the issue #2104</p> <p>Here are the rest of the updates for this week:</p> <p>UX</p> <ul> <li>Long pipeline names in the dashboards will now have a tooltip to let you read the full pipeline   name #2411</li> <li>Login button alignment on mobile views is pushed up #2433</li> </ul> <p>API</p> <ul> <li>Finished up the work on the multiple ATC login issue #2425. The   fix for this will require a db migration in the next version of Concourse!</li> <li>Added the ability to do a fly check-resource-type #2507 in order   to support #2494resource type check_timeout</li> </ul> <p>Core</p> <ul> <li>Continued work on issue #2386 Equivalent resources defined   across pipelines and teams should only correspond to a single version history. The work here has led to the creation   of the new RFC mentioned   above: Mergeresourceandresource_types</li> </ul> <p>Operations</p> <ul> <li>We\u2019ve picked up an issue that aims to be better at inferring defaults for peer/external   URLS #2519. This should help with some of the 4.0.0 upgrade and   installation issues.</li> </ul>"},{"location":"blog/2018-08-30-concourse-update-aug-2731/","title":"Concourse Update (Aug 27\u201331)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Aug-27-31-/0-39sBwa4rlBwJYlH4.jpg\" alt=\"Photo courtesy of the CNE\" width=\"100%\" &gt;}}</p> <p>Apologies for the break from the usual update schedule; I wanted to get one last update out before I take some personal time, starting Fri. Aug 31 and coming back Sept 10. In my absence Scott Foerster and Alex Suraci will be writing the product update next week. The Concourse team will also be taking Monday, Sept 3rd off in observance of Labour day as well.</p> <p>On to the updates:</p> <ul> <li>Concourse 4.1.0 will be out\u2026soon! We\u2019ve begun the process of accepting all stories and deploying our pre-release   version onto the internal test environments. If you\u2019re curious as to what new features/bug fixes are coming out in   this release, you can get an at-a-glace view in our Milestones page.You   can expect the official release to come out very soon :D</li> <li>Lindsay Auchinachie wrote another entry in her Concourse UI Explained series;   this time covering the Concourse Build page.</li> <li>The Concourse mono-repo is coming! You can read more about the change in   issue #2534. Work on this will continue the moment we release   4.1.0</li> </ul> <p>UX</p> <ul> <li>Worked on some UI improvements to help users distinguish between teams they belong to vs exposed   pipelines #2427</li> </ul> <p>Core</p> <ul> <li>Continued refactoring work on #2386</li> <li>Worked on discussion regarding a PR from GitHub user edtan to resolve   issue #2511</li> </ul> <p>Runtime</p> <ul> <li>Since there didn\u2019t seem to be any strong opinions on how we managed log outputting   in #2104, we\u2019ve decided to move forward with some reasonable   assumptions.</li> </ul>"},{"location":"blog/2018-09-14-concourse-update-sept-10--sept-14/","title":"Concourse Update (Sept 10 \u2014 Sept 14)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Sept-10---Sept-14-/1-oJ9JKLsPYwX6YtLNEibR0w.png\" alt=\"Let us know if you\u2019d be interested in Concourse swag\" width=\"100%\" &gt;}}</p> <p>Following up from a discussion on our forums Scott Foerster has been looking at different options for selling Concourse swag online. Do you want Concourse leggings? or maybe a limited edition @vito pls pillow! Let us know in the thread Concourse merchandising.</p> <p>Please also take some time to fill out our **2018 Concourse Community survey **. Your feedback is really valuable to us and the information you provide will help us plan the future of Concourse. We only have a handful of responses so far and we\u2019d like to get more before we publish the results!</p> <p>On to the update:</p> <p>API</p> <ul> <li>As a welcome back to Joshua Winters, we took a look   at #2463 and the possibility of doing an internal redirect for   all auth components. Unfortunately, that didn\u2019t work quite well. Check out the full issue thread for details</li> <li>Remember thatRBAC RFC? Well, we\u2019re going to buckle down and start working   on that now</li> </ul> <p>UX</p> <ul> <li>Following up on issue #2427, we\u2019re applying the same labelling   principals to the HD dashboard view in #2572</li> </ul> <p>Core</p> <ul> <li>Kept hacking away on good ol\u2019#2386</li> </ul> <p>Runtime</p> <ul> <li>Spiking on #2581, where we ask ourselves \u201cCan we determine when   a build step fails because the worker is unusable?\u201d</li> </ul> <p>Operations</p> <ul> <li>Continuing on #2312. This issue has exploded a bit to lots of   edge cases and race conditions; but our determination to finish this issue is strong</li> <li>Looked into why   our k8s-testflight job keeps   breaking.</li> </ul>"},{"location":"blog/2018-09-21-concourse-update-sept-1721/","title":"Concourse Update (Sept 17\u201321)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Sept-17-21-/1-7EmboSXNrRcSwtYmV9WSLQ.jpeg\" alt=\" wiltshirespotter\" width=\"50%\" &gt;}}</p> <p>Concourse 4.2.0 and Concourse 4.2.1 were released earlier this week. There\u2019s a lot of great fixes and features in this new release, so please upgrade now!</p> <p>Reminder that The Great Project Restructuring of 2018 is now underway. You\u2019ll notice that all our submodules (e.g. ATC, TSA fly)are now all under the root level of the concourse/concourse repo. Its cleaner.</p> <p>You\u2019ll also notice that the BOSH spec has moved from its usual place. We\u2019ve separated out the BOSH release code into its own repo under concourse-bosh-release. As always, you can find examples of how to use the BOSH release under concourse-bosh-deployment.</p> <p>Edit: I forgot to mention that Concourse user danhigham wrote an awesome Atom plugin for Concourse. Give the concourse-vis plugin a spin and show him some love!</p> <p>Finally, please take some time to fill out the 2018 Concourse community survey. We\u2019re at 80 responses right now and hoping to hit 100 before we publish the results!</p> <p>On to the update:</p> <p>API</p> <ul> <li>RBAC IS COMING! Team is working away at implementing our first iteration of fine grained role based access control.   You can read the details about this work in the   RFC here.</li> </ul> <p>UX</p> <ul> <li>More UX polish and refactoring, specifically we\u2019re trying to merge the HD dashboard logic with the normal dashboard   logic. A lot of that work is hidden in #2572</li> </ul> <p>Core</p> <ul> <li>#2386is close to completion! Hurray. Applying some final   polishes before shipping it. You\u2019re gonna love it.</li> </ul> <p>Runtime</p> <ul> <li>Finished #2586, which should make things more efficient</li> <li>Made progress on #2588. Completed the GC container portion and   will re-apply the same logic on the volumes portion</li> </ul> <p>Operations</p> <ul> <li>Issued PR #7804 against the Concourse Helm Chart, which refactors the   values.yml to better map Concourse binary commands in the Helm Chart</li> </ul>"},{"location":"blog/2018-09-28-concourse-update-sept-2428/","title":"Concourse Update (Sept 24\u201328)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Sept-24-28-/1-hrYofU4YBkZ9SWkt4fUPZA.jpeg\" alt=\"Reppin\u2019 Concourse at Spring One Platform\" width=\"60%\" &gt;}}</p> <p>The Concourse team went out to Washington D.C. this week to attend Spring One Platform 2018. Thanks to all the Concourse fans who stopped by to say hi, we really enjoyed meeting ya\u2019ll. All of the talks were recorded and should be uploaded to the SpringDeveloper YouTube channel in the coming weeks. Some of the interesting talks to check out are:</p> <ul> <li>Extreme Pipelines</li> <li>Zero to Multicloud   and Spinnaker and the Distributed Monorepo</li> <li>...and of   course Draupnir: A story about Managing Concourse in the Enterprise   {{&lt; image src=\"/images/downloaded_images/Concourse-Update--Sept-24-28-/1-syqGOwSEdWFE5CvrkZT-Kg.jpeg\" alt=\"Concourse \u2764   Spring &amp; PCF\" width=\"60%\" &gt;}}</li> </ul> <p>And now, on to the update:</p> <p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Sept-24-28-/1-kTNsddsROpolUBj1oiJ6Mg.png\" alt=\"\" width=\" 50%\" &gt;}}</p> <p>You\u2019ll notice that our main pipelines are paused. This is because Alex Suraci is working away on #2534, refactoring our main pipeline to support our new mono-repo structure. This new pipeline is simply called the concoursepipeline.</p> <p>In addition to refactoring the pipeline, Alex Suraci has been fleshing out the new developer/contributor workflows under our new mono-repo. You can find the new updated information in CONTRIBUTING.md.</p> <p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Sept-24-28-/1-f2DIMOJRMC4Cm8YG-iWGXw.png\" alt=\"Bugs\u2026or features?!\" width=\"100%\" &gt;}}</p> <p>You\u2019ll also notice that we ask whether you are reporting a bug or a new feature when creating issues. This will ( hopefully) help get our backlog more organized and reduce the up-front triaging!</p> <p>Fly</p> <ul> <li>Completed #2221 \u201cAdd fly command to land worker\u201d</li> <li>Added new fly flag to \u201cSupport manual token entry during login when running <code>fly</code> from a remote shell\u201d   in #2464</li> <li>Fixed #2539, where a login through fly may be \u201csuccessful\u201d if   you do not belong to a specific team</li> <li>Fixed #2598</li> </ul> <p>Core</p> <ul> <li>#2386 is done!</li> </ul> <p>Runtime</p> <ul> <li>Continuing on #2588</li> </ul> <p>Operations</p> <ul> <li>Tackling #2312, which is still giving us a run for our money</li> </ul>"},{"location":"blog/2018-10-05-concourse-update-oct-15/","title":"Concourse Update (Oct 1\u20135)","text":"<p>Alex Suraci is still tackling the chores on our One Big Repo issue #2534. Specifically, Alex is re-writing a new pipeline ( aka concourse) for our mono-repo structure so we can unblock ourselves from releasing updates.</p> <p>In other news, Concourse engineer Saman Alvi wrote up a short article on her experience pairing with a product designer during a discovery into the PivNet resource; check it out: Design &amp; Dev Pairing: What we learned during a one week technical discovery.</p> <p>Finally, the Concourse team will be taking Monday, Oct 5 off to celebrate Thanksgiving. We\u2019ll see you all next week!</p> <p>On to the update:</p> <p>RBAC</p> <p>We continue to work on the proposal for Role Based Access Control (RBAC). In the past few weeks we\u2019ve been focusing more on the experience of assigning roles to new users. Our early attempts at this was to require operators to supply those changes through the fly CLI:</p> <pre><code>fly -t mytarget set-team -n myteam --role viewer --allow-all-users\n\nfly -t mytarget set-team -n myteam --role member --github-user pivotal-jwinters --github-team myorg:myteam\n</code></pre> <p>This raises some questions though: how do you go about removing a role from a user on a team? should the role parameters be additive, or overriding like the other flags? Also, that\u2019s a lot of flags to supply through the set-team command, maybe this belongs in a configuration file.</p> <p>So with that we decided to move all of the user role configurations into a config file. We think that\u2019ll be much cleaner. Hop on over to the updated RFCfor the update details.</p> <p>UX</p> <ul> <li>We\u2019ve been doing some much needed refactoring on the Elm frontend code. That\u2019s also let us pick up some design polish   stories like #2434   and #2430</li> <li>The team has also had the opportunity to pick up a lot of issues around the fly   CLI: #2532, #963, #1062</li> </ul> <p>Core</p> <ul> <li>Space is back\u2026but really it never left! With the hard work of resource pinning and global caching, we\u2019re now ready to   resume the work around Spatial resources #2651</li> </ul> <p>Runtime</p> <ul> <li>Finished #1799 \u201cPermit overlapping inputs, outputs and task   caches</li> </ul> <p>Operations</p> <ul> <li>We finished #2312!!!\u00a0\u2026.except we DO need to do some   acceptance testing to make sure we\u2019ve covered all our bases.</li> </ul>"},{"location":"blog/2018-10-12-concourse-update-oct-912/","title":"Concourse Update (Oct 9\u201312)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Oct-9-12-/1-beC36nbzVbF57aHcM2jEyQ.jpeg\" alt=\"From the Smithsonian National Air and Space Museum in Washington D.C.\" width=\"100%\" &gt;}}</p> <p>The results of the Concourse 2018 Community survey is out! Thanks to everyone who took the time to fill it out; and to Scott Foerster and Lindsay Auchinachie for sifting through the data.</p> <p>It was a relatively short week for us due to Thanksgiving celebrations, but here\u2019s our update:</p> <p>UX</p> <ul> <li>Continued our rampage in fixing fly   issues: #259, #267, #1038, #1062, #248</li> </ul> <p>I also wanted to add that we\u2019re trying to keep all issues under concourse/concourse. We\u2019re planning on migrating the issues under concourse/fly and closing off that repo in order to centralize everything under concourse/concourse.</p> <p>Core</p> <ul> <li>SPATIAL RESOURCES ARE BACK #2651</li> </ul> <p>Runtime</p> <ul> <li>Picked up #1954(The ATC holds a lock on a resource type scan)   and #1796 (Task fails with \u201cconfig file not found\u201d after   restarting Docker service)</li> <li>Finished #1799 Permit overlapping inputs, outputs, and task   caches</li> </ul> <p>Operations</p> <ul> <li>Picked up #2674 Emit metrics for locks held in the DB</li> </ul>"},{"location":"blog/2018-10-19-concourse-update-oct-1519/","title":"Concourse Update (Oct 15\u201319)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Oct-15-19-/1-Y05yilBhjLQKwCftw39ZVw.jpeg\" alt=\"Torontonians typically overreact when they get their first snowfall of the year. Its just a bit of frost ya\u2019ll\" width=\"50%\" &gt;}}</p> <p>We finished our first implementation of Role Based Access Control (RBAC) this week! You can look forward to this change in our next release of Concourse.</p> <p>Speaking of which, the next release of Concourse is currently blocked while we try to re-build our new release pipelines. Along with our move to the mono-repo, we\u2019re focusing even more on making the binary distribution of Concourse the first-class distribution of Concourse. This means that you\u2019ll get everything you need for Concourse packaged into one nifty tgz! We\u2019re still working on finalizing the pipelines, so look forward to hearing more details about these changes in the coming weeks.</p> <p>This week, I\u2019ve also been doing some analysis on our internal Concourse instance Wings. Wings currently runs on GCP and has</p> <ul> <li>4 web instances</li> <li>31 workers @ 4 vCPUs, 16 GB memory, 1000 GB SSD</li> <li>Google CloudSQL as the db</li> <li>99 internal teams</li> </ul> <p>Since inception last year, we\u2019ve processed 238957900.6 build seconds, or 7 years of build activities for Pivotal. Our peak month was in July, 2018, where we processed 48978695.88 build seconds, or 1.5 build years.</p> <p>Neat.</p> <p>On to the update:</p> <p>API</p> <p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Oct-15-19-/1-I0qcGZPL9DOugmQ6eC_xVQ.png\" alt=\"\" width=\" 40%\" &gt;}}</p> <ul> <li>We finished RBAC!</li> <li>Fixed an issue where Users who are not assigned to teams aren\u2019t able to   login #2670</li> </ul> <p>UX</p> <ul> <li>Working on finalizing the fix to #2414, which we thought was   implemented but found that it didn\u2019t work on Linux and Windows machines</li> <li>Continuing our UI cleanup work   with #2434, #2430, #2435</li> <li>Picked up the corresponding UI story for pinning resources in the Web   UI #2508</li> </ul> <p>Core</p> <ul> <li>SPACE (#1202   and #2651)</li> </ul> <p>Runtime</p> <ul> <li>Picked up some work on improving volume streaming #2676</li> </ul> <p>Operations</p> <ul> <li>Working on emitting more metrics for locks held in DB #2674</li> </ul>"},{"location":"blog/2018-10-26-concourse-update-oct-2226/","title":"Concourse Update (Oct 22\u201326)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Oct-22-26-/1-MnGUtwM_fDCZBeKhYrlwqA.jpeg\" alt=\"MGI Construction Corp\" width=\"50%\" &gt;}}</p> <p>This week the team got together to discuss the initial groundwork and investigations required to publish and maintain a supported API. If you\u2019ve built any tools against our API and have feedback for us, please let us know by commenting on the original issue #1122.</p> <p>In another interesting update, the PivNet team has published an update to the pivnet-resource so \u201cyou no longer need to specify the access key, secret access key, bucket and region for creating releases.\u201d If you use that resource, you should definitely check it out!</p> <p>On to the update:</p> <p>UX</p> <ul> <li>Picked up the story for pinning versions of resources in the web   UI #2508</li> </ul> <p>Core</p> <ul> <li>Continued our work on resources v2 and spatial resources   with #2651</li> </ul> <p>Runtime</p> <ul> <li>Picked up failing tests in Testflight/Watsjs #2719</li> <li>Started work on retry / read deadline for Volume Streaming #2676</li> </ul> <p>Operations</p> <p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Oct-22-26-/1-yxHddOEl3sz5TqCy7M0q_A.png\" width=\"50%\" &gt;}}</p> <p>We\u2019ve added descriptions to our metrics graphs! You can check out the descriptions on our prod metrics here: https://metrics.concourse-ci.org/dashboard/db/concourse?refresh=1m&amp;orgId=1</p> <p>In other news we\u2019re also working on #2674, emit metrics for locks held in the database</p>"},{"location":"blog/2018-11-02-concourse-update-oct-29-nov-2/","title":"Concourse Update (Oct 29\u2014 Nov 2)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Oct-29--Nov-2-/1-7C_nS91OafAnN5DWBtN4SA.jpeg\" alt=\"The Concourse team\u2019s big yoga ball has returned to its rightful home\" width=\"50%\" &gt;}}</p> <p>As a part of our refactor of the prod pipeline, Alex Suraci cleaned up and refactored parts of the TSA to better support draining and rebalancing #2748. The numbers are looking really good!</p> <p>On to the update:</p>"},{"location":"blog/2018-11-02-concourse-update-oct-29-nov-2/#api","title":"API","text":"<ul> <li>We\u2019re deep into investigations around our API documentation and management strategy. Our current investigation work is   captured in #2739 but the original request comes   from #1122</li> </ul>"},{"location":"blog/2018-11-02-concourse-update-oct-29-nov-2/#core","title":"Core","text":"<ul> <li>SPACCEEEE #2651</li> </ul>"},{"location":"blog/2018-11-02-concourse-update-oct-29-nov-2/#ux","title":"UX","text":"<ul> <li>Continuing our work on supporting pinning of versions on resources from the UI. You can see some of our progress   on #2508</li> </ul>"},{"location":"blog/2018-11-02-concourse-update-oct-29-nov-2/#runtime","title":"Runtime","text":"<ul> <li>Continuing our work on #2676   and #1266</li> </ul>"},{"location":"blog/2018-11-02-concourse-update-oct-29-nov-2/#operations","title":"Operations","text":"<ul> <li>Adding jobs to our pipeline to better support the Concourse Helm   Chart #2743</li> <li>And in general Topher Bullock has been helping out with PRs and issues on the   Concourse Helm Chart.</li> </ul>"},{"location":"blog/2018-11-09-concourse-update-nov-59/","title":"Concourse Update (Nov 5\u20139)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Nov-5-9-/1-JcXgBDqfq8Lwc4WNwyJgQg.jpeg\" alt=\"\" width=\" 50%\" &gt;}}</p> <p>Right off the bat I\u2019d like to give a shoutout to Jamie Klassen and his new post about the upcoming feature for pinning resources. You can check it out the new post here:https://medium.com/concourse-ci/resource-page-explained-eb99cf256fb5</p> <p>I also wanted to mention that the Github Pull Request that was maintained by JT Archie (https://github.com/jtarchie/github-pullrequest-resource) has been officially deprecated.</p> <ol> <li>The official docs for the resource types no longer point to jtarchie/pr for the PR resource. They are pointing    to https://github.com/telia-oss/github-pr-resource now.</li> <li>There will no longer be any maintenance, issues or PRs accepted on the resource.</li> </ol> <p>We also spent some time this week finalizing our plans for the Concourse 2019 roadmap. We\u2019ll be writing it up in a wiki to share with everyone next week, so keep an eye out for another followup announcement!</p> <p>On to the update:</p> <p>Pipeline</p> <ul> <li>We finally got a deploy going onto our prod environment. Everything broke but hey, its   the attempt that matters</li> </ul> <p>API</p> <ul> <li>We\u2019re still investigating various options for refactoring and documenting our   API. Joshua Winters is on it!</li> </ul> <p>UX</p> <ul> <li>Pinning versions on resources. Make sure you read our write-up on   it here!</li> </ul> <p>Core</p> <ul> <li>Resource v2 and Spatial resource design! Most of that work is currently being done in   a feature branch.</li> </ul> <p>Runtime</p> <ul> <li>Picked up #2529</li> </ul> <p>Operations / K8s</p> <ul> <li>In addition to picking up some issues reported by users around helm-deployed concourse in   4.2.1, Topher Bullock is going to try spending his Fridays making / looking at   Concourse Helm chart PRs.</li> </ul>"},{"location":"blog/2018-11-23-concourse-rbac-preview/","title":"Concourse RBAC Preview","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-RBAC-Preview/0-oy1M_w9ksoAje2LR.jpg\" width=\"50%\" &gt;}}</p> <p>One of the big themes for Concourse in 2018 has been Users, multiple auth connectors, and role-based access control ( aka RBAC). With RBAC in the final phases of development, I wanted to give you a preview of some of the functionality that you can expect in our upcoming release; Concourse 5.0</p>"},{"location":"blog/2018-11-23-concourse-rbac-preview/#admins-owners-members-and-viewers","title":"Admins, Owners, Members and Viewers","text":"<p>Concourse 5.0 will come with 4 roles: Concourse Admin, Team Owner, Team Member, and Team Viewer.</p>"},{"location":"blog/2018-11-23-concourse-rbac-preview/#concourse-admin","title":"Concourse Admin","text":"<p>A Concourse Admin is the same as today\u2019s admin user. Members of main team will automatically be Concourse Admins* and have the ability to administrate teams with fly: set-team, destroy-team, rename-team, and teams. Given that all Concourse Admins must be a member of the main team, all Concourse Admins must have at least one other role; and that should typically be the Team Owner role.</p> <p>* There\u2019s an open issue to restrict this grant to Team Owners on main in #2846</p>"},{"location":"blog/2018-11-23-concourse-rbac-preview/#team-owner","title":"Team Owner","text":"<p>Team Owners have read, write and auth management capabilities within the scope of their team. For those familiar with Concourse today, the scope of allowed actions for a Team Owner is very closely aligned to today\u2019s Concourse team member. The new change is that you can no longer rename your own team or destroy your own team as an owner.</p>"},{"location":"blog/2018-11-23-concourse-rbac-preview/#team-member","title":"Team Member","text":"<p>Team Member is a new role that lets users operate within their teams in a read &amp; write fashion; but prevents them from changing the auth configurations of their team.</p>"},{"location":"blog/2018-11-23-concourse-rbac-preview/#team-viewer","title":"Team Viewer","text":"<p>Team Viewer is also a new role that gives users \u201cread-only\u201d access to a team. This locks everything down, preventing users from doing a set-pipeline or hijack.</p>"},{"location":"blog/2018-11-23-concourse-rbac-preview/#other-roles","title":"Other Roles","text":"<p>We considered other role types while developing this feature; including roles that would specifically prevent intercept and abort. We ultimately decided that our current configuration made more sense for the first release of RBAC. Ultimately every organization will have different needs for their access control, so we are also planning for a future where users can supply their own customized roles &amp; permissions matrix.</p>"},{"location":"blog/2018-11-23-concourse-rbac-preview/#full-roles-breakdown","title":"Full Roles Breakdown","text":"<p>For a full list of each role\u2019s allowed actions you can reference our handy permission matrix on Google Sheets here.</p>"},{"location":"blog/2018-11-23-concourse-rbac-preview/#configuring-roles-with-fly","title":"Configuring Roles with fly","text":"<p>Now that we\u2019ve gone over the new roles, we can do a quick overview of how we can go about setting users &amp; roles on teams.</p>"},{"location":"blog/2018-11-23-concourse-rbac-preview/#default-behaviour","title":"Default Behaviour","text":"<p>By default, if no configuration is provided the user is given theTeam Owner role:</p> <pre><code>fly -t dev set-team -n PowerRangers --local-user=Zordon\n</code></pre> <p>This behaviour also applies to groups as well, so be careful!</p> <pre><code>fly -t dev set-team -n A-Team \\\n  --github-team=MightyMorphin:PowerRangers\n</code></pre>"},{"location":"blog/2018-11-23-concourse-rbac-preview/#specifying-roles-with-c","title":"Specifying Roles with <code>-c</code>","text":"<p>Roles must be specified in a separate configuration file using the -c</p> <pre><code>    fly -t dev set-team -n PowerTeam -c ./team.yml\n</code></pre> <p><code>team.yml</code>:</p> <pre><code>roles:\n  - name: owner\n    local:\n      users: [ \"Zordon\" ]\n  - name: member\n    local:\n      users: [ \"RedRanger\", \"BlueRanger\", \"GreenRanger\" ]\n  - name: viewer\n    local:\n      users: [ \"Alpha\" ]\n</code></pre>"},{"location":"blog/2018-11-23-concourse-rbac-preview/#inspecting-roles-configuration","title":"Inspecting Roles Configuration","text":"<p>Once you\u2019ve set the team configuration you can verify it using the details flag on fly teams:</p> <pre><code>fly -t dev teams -d\n\nname users groups\nA-Team/member local:RedRanger, BlueRanger, GreenRanger none  \nA-Team/owner local:Zordon none  \nA-Team/viewer local:Alpha none\n</code></pre> <p>...where you\u2019ll find the output is now updated to list each team/role combination and its associated users/groups.</p>"},{"location":"blog/2018-11-23-concourse-rbac-preview/#whats-left","title":"What\u2019s left?","text":"<p>And that\u2019s RBAC in a nutshell! We\u2019re really excited to get this in your hands in our upcoming release of Concourse. There\u2019s only a few more issues that we want to finish off before releasing this feature, specifically:</p> <ul> <li>#2846 Admin users should be restricted to members of the main   team with the owner role. This is so you don\u2019t get weird cases of a Team Viewer on main getting Admin access</li> <li>#2843 Dashboard team labels updated to display User Role. We   need this otherwise users on the Web UI have no idea what they can / can\u2019t do</li> </ul>"},{"location":"blog/2018-11-23-concourse-update-nov-1923/","title":"Concourse Update (Nov 19\u201323)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Nov-19-23-/1-fBOnArsQyRfYMLYGB4Uk_w.jpeg\" width=\"50%\" &gt;}}</p> <p>It was a relatively light week this week due to some vacations. I did, however, get a chance to do some acceptance work on our upcoming feature for role-based access control in Concourse. You can read more about how that\u2019ll work in our feature preview post.</p> <p>On to the update:</p> <p>API</p> <ul> <li>Our investigation into the API continues and branches out into more areas of the codebase. If you haven\u2019t already,   make sure to check out the two related   RFCS: https://github.com/concourse/rfcs/pull/14   and https://github.com/concourse/rfcs/pull/15</li> </ul> <p>UX</p> <ul> <li>We\u2019ve decided to commit to completing our refactor the Web NavBar before picking up new stories. This\u2019ll hopefully   prevent regressions when we pick up new stories down the road. We now have over 300 unit tests for our web-ui!</li> </ul> <p>Runtime</p> <ul> <li>Picked up #2577. We\u2019re having conversations internally around   specific strategies that would help with this. On the one hand, we could try computing resource utilization on the   first run to inform our future allocations; or we could go with naive container/volume balancing.</li> </ul> <p>Core</p> <ul> <li>Continuing our planning for Spatial resources</li> </ul>"},{"location":"blog/2018-11-30-concourse-updates-nov-2630/","title":"Concourse Updates (Nov 26\u201330)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Updates--Nov-26-30-/1-BFgbR-J5U389pc0g9nDi_Q.jpeg\" width=\"100%\" &gt;}}</p> <p>As I mentioned last week I\u2019ve been doing story acceptance in our dev environments for the upcoming RBAC feature. The team\u2019s been working through some of the new issues that come out of that to give some final polish on to the release.</p> <p>Something that I haven\u2019t talked too much about in the past weeks is our work on the Concourse k8s Helm chart. If you pull up some of the PRs under stable/concourse, you\u2019ll see that we\u2019ve been proposing some changes to the chart. This all falls under our goals for helping the community stabilize the Concourse Helm Chart and to increase the scope of automated tests using the Helm chart. You can follow along some of our work in GH issues #2753 and #2876.</p> <p>On to the update</p> <p>API</p> <ul> <li>Removed \u201callow all users\u201d in #2721</li> <li>Added the restriction that only owners of main can be   admins #2846</li> </ul> <p>Fly</p> <ul> <li>Fixed #2780</li> <li>Fixed #2414</li> <li>Fixed #2819</li> </ul> <p>UX</p> <ul> <li>Implemented #2843 to help users understand what roles they have   on each team</li> <li>Finished #2795, which added the \u201cpin\u201d colors to the legend</li> <li>Completed an issue that lets users unpin from the top bar #2870</li> <li>Moved the Exposed state on a pipeline off the team and onto the   pipeline #2844</li> <li>Fixed an old issue where users of new teams can\u2019t un-pause their first   pipelines #2882</li> </ul> <p>Core</p> <ul> <li>Began building up large scale test environments for Global Resource   caching #2874</li> </ul> <p>Runtime</p> <p>Continued with #2577:</p> <p>\u201c..as a first effort solution, we have decided to go with using the existing number of active containers on the workers to determine container placement. This means that we are adding a placement strategy that adds the new task on to a worker with the least existing active containers.\u201d</p>"},{"location":"blog/2018-12-07-concourse-update-dec-37/","title":"Concourse Update (Dec 3\u20137)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Dec-3-7-/1-9QGCZafW4o8rGIVxN4QvYA.jpeg\" alt=\"Stephen A. Wolfe\" width=\"75%\" &gt;}}</p> <p>We\u2019re nearing the end on some UX refactoring work and finished off the issue regarding container scheduling. Between those improvements and the global resource caching, we\u2019re hoping to see a lot of efficiency improvements in 5.0</p> <p>That said, we\u2019ve decided that we need to perform some additional performance and load testing on Concourse 5.0 before we cut the release. And with the holidays coming up, its increasingly unlikely that we\u2019ll be able to push Concourse 5.0 before the end of this year. In the meantime, we\u2019re planning to make a big update post describing the new deployment pipeline, contribution structure, major features in Concourse 5.0, and much more; so keep an eye out for that in the coming days!</p> <p>If you\u2019re attending KubeCon next week I\u2019d encourage you to check out the talk on Using Concourse as a CI/CD Tool for Your Knative Ap p. Concourse engineer Divya Dadlani will be co-speaker on this talk and if you ask nicely; she might give you one of our fancy Concourse stickers. You should also check out Fairfax Media\u2019s talk on Cloud Native Transformation too, I hear they use a lot of Concourse!</p> <p>And finally, I\u2019ll be taking some time off for the holidays starting Dec 13, and won\u2019t be returning to work until the new year. I\u2019ve got a few posts scheduled to come out until then, but for now happy holidays, happy new year, and thanks for another awesome year of Concourse.</p> <p>On to the update:</p> <p>API</p> <ul> <li>Resolved #2887</li> </ul> <p>UX</p> <ul> <li>Fixed a bug that happens when you try to log out from   Concourse #2884</li> <li>Fixed an issue with Fly where using -c on set-team with RBAC will fail silently if you use a badly-formed   file#2904</li> <li>Fixed an issue regarding the output of fly teams -d #2880</li> </ul> <p>Runtime</p> <ul> <li>Slightly better scheduling #2577</li> </ul>"},{"location":"blog/2018-12-12-concourse-2018-year-in-review/","title":"Concourse 2018 Year in Review","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-2018-Year-in-Review/1-pzx9yhOYi-XyEFUgqnxBfw.jpeg\" alt=\"Bernal Saborio\" width=\"100%\" &gt;}}</p> <p>2018 has been an action-packed year for us. We saw a major release (Concourse 4.0.0) with a lot of new features: new auth connectors and users, dashboard, distributed GC and other runtime improvements. At the same time our team grew from 3 engineering pairs at the start of 2018 to 8 engineering pairs and an additional PM (\ud83d\udc4b Scott Foerster) working on Concourse OSS and supporting Concourse for PCF.</p>"},{"location":"blog/2018-12-12-concourse-2018-year-in-review/#by-the-numbers","title":"By the Numbers","text":"<ul> <li>13 releases of Concourse</li> <li>1 TLD snafu leading toour domain change</li> <li>1 new website design</li> <li>2 new ways to contact us (Discord, Discuss)</li> <li>1,070 members on Concourse Discord, 45 members in #contributors</li> <li>937 new GitHub issues created in 2018. Given th at only 1,694 issues were opened prior to 2018, I\u2019d say that\u2019s a   pretty big jump in activity!</li> <li>417 PRs, up by 15% from last year</li> <li>3,300 stars, up by 38% from last year</li> </ul>"},{"location":"blog/2018-12-12-concourse-2018-year-in-review/#most-popular-posts","title":"Most Popular Posts","text":"<p>We started this blog in Sept of last year. Since then we\u2019ve had thousands of readers over 70 posts. The top 5 most popular posts are:</p> <ul> <li>Designing a Dashboard for Concourse</li> <li>Getting Started with Concourse on macOS</li> <li>Earning our Wings</li> <li>Concourse Pipeline UI Explained</li> <li>Sneak Peek: Spatial Resources</li> </ul>"},{"location":"blog/2018-12-12-concourse-2018-year-in-review/#thanks-to-our-contributors","title":"Thanks to our Contributors","text":"<p>Finally, Thanks to all our contributors across all our repos:</p> <p>**concourse/concourse ** **: ** edtan, ralekseenkov, SHyz0rmZ, databus23, pivotal-kahin-ng, jmcarp, tkellen, aeijdenberg, rosenhouse, andrewedstrom, baptiste-bonnaudet, PavelTishkin, timchavez, JamesClonk, rfliam, ArthurHlt, christophermancini</p> <p>**concourse/concourse-docker: ** danielrs, scottbri, dbbaskette, ElfoLiNk, jmcduffie32, SergueiFedorov</p> <p>**concourse/concourse-bosh-release: ** JamesClonk, ramonskie, avanier, rkoster, SHyz0rmZ, aeijdenberg, jmcarp, ArthurHlt</p> <p>**concourse/docs: ** vlad-ro, charlieoleary, AnianZ, berlin-ab, a114m, ukabu, arbourd, baptiste-bonnaudet, marco-m, rosenhouse, patrickcrocker, crstamps2, JohannesRuolph, dbp587, headc4sh, aequitas</p> <p>**concourse/docker-image-resource: ** ghostsquad, dhinus, norbertbuchmueller, hephex, chrishiestand, kmacoskey, irfanhabib, simonjohansson, et7peho, itsdalmo, krishicks, mook-as</p> <p>**concourse/git-resource: ** norbertbuchmueller, talset, ppaulweber, elgohr, alucillo, goddenrich, njbennett, timchavez, suda, jamesjoshuahill, gcapizzi, mdomke, benmoss, ljfranklin, oliveralberini, krishicks</p> <p>**concourse/s3-resource: ** ghostsquad, talset, 46bit, bandesz, ruurdk</p> <p>\u2026and many more. Special thanks to all the contributors who\u2019ve built new resources for Concourse in 2018, contributed to the health of resources and also took over old resources.</p>"},{"location":"blog/2018-12-12-concourse-2018-year-in-review/#see-you-in-2019","title":"See you in 2019!","text":"<p>I hope y\u2019all get to enjoy some time off this holiday season. We\u2019ve got a lot of updates planned for 2019, like our new contributor workflow, Concourse 5.0 and spatial resources! Look forward to an in-depth post from Alex Suraci in the next few days.</p> <p>Thanks again for all the support, and we\u2019ll see you in 2019!</p>"},{"location":"blog/2018-12-20-the-great-process-update-of-2018/","title":"The Great Process Update of 2018","text":""},{"location":"blog/2018-12-20-the-great-process-update-of-2018/#or-why-we-havent-shipped-any-new-features-since-september","title":"Or, \u201cwhy we haven\u2019t shipped any new features since September.\u201d","text":"<p>{{&lt; image src=\"/images/downloaded_images/The-Great-Process-Update-of-2018/1-Fdk1aihMwmllUR7HOBp2kg.jpeg\" width=\"80%\" &gt;}}</p> <p>You may have noticed that our release cadence has slowed down significantly in the past few months. The bad news is we probably won\u2019t get a release out this year (mainly due to end-of-year vacations and slowing down in general), but the good news is the next release is huge \u2014 big enough to bump us to v5.0 \u2014 and it\u2019s just about ready. I\u2019ll have more information on the next release in an upcoming post.</p> <p>This post will go over all the changes we\u2019ve made to our project structure and processes surrounding contribution. These changes aren\u2019t very visible to end-users, but they set the stage for the community growth and collaboration that will make our future releases even better and bring more depth to our culture and ecosystem.</p>"},{"location":"blog/2018-12-20-the-great-process-update-of-2018/#a-newly-minted-process-for-rfcs","title":"A newly minted process for RFCs","text":"<p>We\u2019ve finally established a process for submitting and accepting RFCs! Head over to the concourse/rfcsrepo if you want to check it out.</p> <p>This new process enables anyone in the community to have a big impact on Concourse\u2019s direction. I\u2019m really looking forward to seeing where this goes. We\u2019ll be posting status updates for RFCs on this blog to notify the community of RFCs that are newly opened or near acceptance.</p> <p>We've already started submitting RFCs for substantial features like Resources V2 and RBAC, though we jumped the gun a bit on implementation as we hadn\u2019t yet figured out what we wanted from the RFC process (we just needed a better way to plan things in the open). There are a few loose ends to tidy up with existing RFCs now that we have a full process in place.</p> <p>Credit where it\u2019s due: this process based pretty heavily on Rust\u2019s. Just about every detail seemed to apply just as appropriately to Concourse, and we\u2019re just as cautious about far-reaching changes, so it was a great match.</p>"},{"location":"blog/2018-12-20-the-great-process-update-of-2018/#switching-from-cla-to-dco","title":"Switching from CLA to DCO","text":"<p>Up until now, all pull request authors have had to sign off on the Pivotal CLA in order for their pull request to be accepted (unless it was an \u201cobvious fix\u201d).</p> <p>On occasion contributors would get caught in a corporate quagmire when trying to get their company to sign off on the CLA, and it was also kind of jarring for individuals. The need for something like the CLA hasn\u2019t gone away, but we felt it may have been hindering more than helping.</p> <p>So, we\u2019re abandoning the CLA process and instead adopting the Developer Certificate of Origin (\u201cDCO\u201d) process. This process is much more lightweight, only requiring pull request authors to include a \u201cSigned-off-by:\u201d line in each commit, which can be done via git commit -s. More information on this is available in CONTRIBUTING.md.</p>"},{"location":"blog/2018-12-20-the-great-process-update-of-2018/#completing-the-great-project-restructuring-of-2018","title":"Completing the Great Project Restructuring of 2018","text":"<p>The single biggest cause of the release slowdown has been The Great Project Restructuring of 2018, which was a massive revamp of how we develop, build, test, and ship Concourse. We knew this would be a \u201cstop-the-world\u201d transition that would prevent us from shipping for a while, but we really had to bite the bullet at some point.</p> <p>The focal point of this restructuring: almost all of Concourse\u2019s code now lives in one big concoursemonorepo, using the new Go 1.11 module system to track dependencies. We\u2019ve replaced our BOSH-centric development and pipeline workflow with a Docker-based workflow which is more intuitive and has a much faster feedback cycle.</p> <p>This means you can now git clone the Concourse repo and get a cluster built from source and running in single command: docker-compose up. It\u2019s never been easier to make changes and test them out locally. Check out the new CONTRIBUTING.md for more information!</p> <p>This change kicked off a ripple effect that improved a ton of things about the developer, contributor, and operator experience:</p> <ul> <li>Now that all the code is together in one repo, cross-cutting changes can now be submitted as a single pull request! \ud83c\udf8a   Pull requests now trigger acceptance tests too, which is something we couldn\u2019t really do easily before.</li> <li>Resources are now versioned and shipped independently from Concourse versions. Each resource is published as   concourse/\\&lt;name&gt;-resource with appropriate tags (e.g. 1.2.3, 1.2, 1, latest, dev). This means you can refer to   specific versions when necessary by using resource_types: in your pipeline. A core set of resource types will still   be shipped with Concourse, at whichever version they were when the release was frozen.</li> <li>The concourse repo is no longer a BOSH release; we\u2019ve split it out   into its own repository instead. The new BOSH release simply   wraps the binary distribution, rather than building from source. This reduces the surface area for support and removes   any discrepancies between the platforms \u2014 everything just uses the binary now! This also makes deploying the BOSH   release faster because there\u2019s not much to compile.</li> <li>We\u2019ve changed how the concourse executable is packaged. We\u2019re switching to a .tgz format containing the binary and its   dependencies, rather than a self-extracting \u201call-in-one\u201d binary. This results in way fewer moving parts and   dramatically reduces concourse worker start-up time.</li> </ul>"},{"location":"blog/2018-12-20-the-great-process-update-of-2018/#where-are-we-now","title":"Where are we now?","text":"<p>Overall, I think these recent changes may be the most important thing we\u2019ve done for the project since its inception, even if it meant not shipping for a while.</p> <p>The RFC process will make it easier to collaborate, switching to the DCO removes a hurdle for new contributors, and the the new project structure should dramatically improve the developer experience.</p> <p>I\u2019d like to give special thanks to everyone that has tried out and given feedback on this new development process, and all the users that have waited patiently for the next release. \ud83d\ude05</p>"},{"location":"blog/2018-12-20-the-great-process-update-of-2018/#whats-next","title":"What\u2019s next?","text":"<p>Well, now that the dust is settling it\u2019s time to actually start shipping software again. The next post will go over what\u2019s in store for 5.0 and peek ahead into what we\u2019re planning for 2019. See you then!</p>"},{"location":"blog/2019-01-11-concourse-update-jan-711/","title":"Concourse Update (Jan 7\u201311)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Jan-7-11-/1-xc1d4AtxzZanyNVDiEPrvg.jpeg\" width=\"50%\" &gt;}}</p> <p>\u2026and we\u2019re back! The team\u2019s been pretty quiet over the past few weeks due to vacations and holidays. This was our first week back at full strength so we\u2019ve got some interesting updates for ya\u2019ll</p>"},{"location":"blog/2019-01-11-concourse-update-jan-711/#how-are-issues-managed","title":"How are issues managed?","text":"<p>This is an issue that comes up a lot in our open source community, and Alex Suraci has taken some time to clean up our issues backlog and add in some bots. You can read the full details here: How Issues are Managed</p> <p>In addition to the changes to how issues are labeled, we\u2019ve also changed how we used projects and milestones under concourse/concourse. Epics are now organized under projects in concourse/concourse, and release markers are managed under milestones in concourse/concourse. And as always, our \u201ctracks of work\u201d can be found at the org-level project page.</p>"},{"location":"blog/2019-01-11-concourse-update-jan-711/#updates","title":"Updates","text":"<p>UX</p> <p>Thanks to the hard work of the UX team, they were able to crank through a lot of nice UI issues over the past few weeks. This includes #2405 and #2881. We will also be scheduling a big track of work for transitioning to Elm 0.19.</p> <p>Core</p> <p>We\u2019re picking up from the global resource cache work from last year and picking off the remaining blockers to release. Specifically #2908 needs to be addressed otherwise everyone\u2019s time-resource will kick off at the same time; which may be very bad news for shared environments. In order to keep the release process on track we will be parallelizing #2874 performance testing to another pair.</p> <p>Runtime</p> <p>Having completed the placement strategy and testing it in prod, we\u2019re proceeding to do some refactoring in #2926</p>"},{"location":"blog/2019-01-18-concourse-update-jan-1418/","title":"Concourse Update (Jan 14\u201318)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Jan-14-18-/1-6MKC6FrHvi5u_9yZCklyeA.png\" alt=\"for context... or don\u2019t \ud83e\udd37\" width=\"100%\" &gt;}}</p> <p>Some updates worth bringing up this week. As I had mentioned last week we began to do a re-organization of projects and issues in our concourse/concourse repo; you can read more about it on our wiki page here. With that said, you can find the issues and PRs that are slated for Concourse 5.0.0\u2019s release in our 5.0.0 Milestones. If you\u2019d like to help us with documentation, we\u2019ve started a new branch in the docs repo under v5.0.</p> <p>One of the items we want to resolve before release is issue #3003 \u201cDetermine full set of core resources that we should bundle with Concourse\u201d. In this discussion we\u2019re going over the idea of removing the pre-baked resources in favour of slimming down the Concourse footprint and only shipping what is absolutely needed. We want to hear how this may impact you and your Concourse experience. We\u2019d like to wrap this up soon, so please drop in a comment at your earliest convenience!</p> <p>In other big news, the Concourse core engineering team has officially switched to a PR based workflow. That means we are no longer allowing direct commits to master and all issue \u201cacceptance\u201d will be conducted via the merging of pull requests. We hope this will make our development process even more transparent and further involve the community in day-to-day work!</p> <p>On to the update:</p> <p>UX</p> <ul> <li>Added a comments bar to indicate paused resources are now pinned (   PR#3064)</li> <li>You can now force check a resource from the web UI (PR #3051)</li> </ul> <p>Core</p> <ul> <li>Completed #2908. This is one of the key blocking issues   preventing us from releasing Concourse 5.0.0</li> <li>Picked up #3013 as a way to address the two very clear use cases   where you might not want it: lots of time resources and resources that use IAM roles</li> <li>Picked up the performance test work #2874</li> </ul> <p>Runtime</p> <ul> <li>In the first issue of many around runtime refactoring, we picked   up #3502 to break up the responsibilities of containerProvider</li> </ul>"},{"location":"blog/2019-01-25-concourse-update-jan-2125/","title":"Concourse Update (Jan 21\u201325)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--Jan-21-25-/1-t_CkNyt-IVxZrxMiARCJLQ.jpeg\" alt=\"Dennis Jarvis\" width=\"50%\" &gt;}}</p> <p>Its been a week since we switched over to the PR workflow and so far its been great! We\u2019re still working through some of the kinks with this process so please bear with us while we continue to burn down through the list of open PRs!</p> <p>And now\u2026on to the update! I might have missed a few issues while I\u2019m still getting used to our new workflow. Completed issues now appear as closed PRs in concourse/concourse</p> <p>Docs</p> <ul> <li>Started to burn down our list of todos for Concourse docs pre-release. You can follow along   in #143</li> <li>Proposed a new structure for our docs in #136. Brace yourselves for   broken links.</li> </ul> <p>UX</p> <ul> <li>Added a \u201cnew version\u201d tooltip to versions in Resource page #3136</li> <li>Fixed a whole bunch of UX quirks in preparation for v5.0.0 release</li> <li>Beginning our Elm 0.19 refactor and upgrade</li> </ul> <p>Core</p> <ul> <li>Upgrade and performance testing for Concourse 5.0 #2874</li> </ul> <p>Runtime</p> <ul> <li>Decoupling container and volume creation in   FindOrCreateContainer #3052</li> </ul>"},{"location":"blog/2019-03-08-an-overview-of-authorization-in-concourse-3-4-and-5/","title":"An Overview of Authorization in Concourse 3, 4 and 5","text":"<p>{{&lt; image src=\" /images/downloaded_images/An-Overview-of-Authorization-in-Concourse-3--4-and-5/1-sh1rcJO5eSRDQrmxIF8qTA.jpeg\" alt=\"NASA HQ Photo\" width=\"60%\" &gt;}}</p> <p>With the release of Concourse 5.0.0 this week I thought it would be a good time to review the evolving implementation of authorization in Concourse. I\u2019ll also be covering some helpful debugging information for you to consider when configuring authorization in your own Concourse instance.</p>"},{"location":"blog/2019-03-08-an-overview-of-authorization-in-concourse-3-4-and-5/#read-the-docs","title":"Read the Docs","text":"<p>The revised Concourse Auth &amp; Teams docsis a great place to start when diving into Concourse 5.0.0. The docs will cover important steps around provider configuration and team configuration for your cluster. If you\u2019re more interested in how things used to work compared to how they now work; then read on!</p>"},{"location":"blog/2019-03-08-an-overview-of-authorization-in-concourse-3-4-and-5/#how-authorization-works-in-3x","title":"How Authorization Works in 3.x","text":"<p>This section will only be useful to operators who are migrating into 4.x and beyond. Feel free to skip ahead if this does not apply to you.</p> <p>{{&lt; image src=\" /images/downloaded_images/An-Overview-of-Authorization-in-Concourse-3--4-and-5/1-cNIh0ygLLcNnPbGEDOhcig.png\" alt=\"\" width=\"100%\" &gt;}}</p> <p>Every Concourse instance starts with a main team that must be configured against an Authentication Provider on start-up. The main team is an admin team, meaning it can create teams, update other teams and view system-scoped details on workers, containers, etc.</p> <p>One of the tasks that only a main user can do is to create new teams via set-team. When creating the team, the operator must specify:</p> <ul> <li>An Authentication Provider e.g. Basic Auth, GitHub, OAuth</li> <li>The relevant configuration of the Authentication Provider e.g. secrets, tokens</li> <li>The user/group to authorize (if applicable)</li> </ul> <p>Some important notes to keep in mind:</p> <ul> <li>Authentication Provider configurations are attached to an individual team, and not shared across teams. As an   operator, you will have to repeat/resupply the Authentication Provider configuration for each team. If Team 1 wanted   to change their own auth to add a member or group they would have to ask the Operator for the github API token or   bring their own.</li> <li>Since Authentication Provider details are provided per-team, operators can set unique provders for each. A common   use-case is to provision Team 1 to authenticate against the USA-East-1 OAuth server and Team2 to authentiate against   the EMEA OAuth server.</li> <li>You can stack Authentication Providers by supplying multiple parameters when applying set-team; e.g. a team can have   both GitHub and Basic Auth configured to authenticate users.</li> <li>Users who are authorized to access more than one team can only see one team at a time.</li> </ul>"},{"location":"blog/2019-03-08-an-overview-of-authorization-in-concourse-3-4-and-5/#concourse-40-users","title":"Concourse 4.0\u200a\u2014\u200aUsers","text":"<p>Concourse 4 introduced Users and totally revamped the authorization flow:</p> <ul> <li>Identity providers must be specified when Concourse first starts up (this includes local users as well!)</li> <li>Identity providers are shared across teams and can no longer be customized per-team</li> <li>Adding/removing Identity Providers require a restart to the web node</li> <li>When specifying groups in provider configuration, administrators must use : as the separator instead of /</li> <li>Users logging into Concourse are whitelisted into all teams that match thier provider membership. More on this later</li> </ul>"},{"location":"blog/2019-03-08-an-overview-of-authorization-in-concourse-3-4-and-5/#overview-of-authorization-flow","title":"Overview of Authorization Flow","text":"<ol> <li>Operator determines the Identity Providers they will allow in Concourse and configures their Concourse startup    scripts (Docker, BOSH, Helm, etc.) with the necessary parameters as described    in Configuring Auth.</li> <li>If there are any local users that have Basic Auth (username/password) identities, the operator will add them to the    startup scripts as outlined in Local Auth</li> <li>The Operator will start Concourse and begin creating teams using the fly set-team command. Keeping in mind the auth    providers that were added in step (1) the Operator can specify the allowed users/groups/teams from that provider.    See Configuring Team Auth for more details.</li> <li>When a User logs into Concourse, they are asked to login using one of the configured providers from (1).</li> <li>Once the User selects a provider, Concourse will redirect the User to the identity provider\u2019s authentication    mechanism and wait for a successful login response</li> <li>When a login success response is recieved, Concourse will examine all of the teams/orgs the User belongs to under    that provider. Concourse will then match the user\u2019s information against the internal list of Concourse teams and    their list of whitelisted users/teams/orgs. The resulting list will be the teams that the User can access</li> <li>The User is logged into Concourse and can access the teams they were whitelisted into</li> </ol>"},{"location":"blog/2019-03-08-an-overview-of-authorization-in-concourse-3-4-and-5/#identity-providers","title":"Identity Providers","text":"<p>An Identity Provider is any external entity that creates, manages and maintains identity information to auth. Concourse 4 uses the OSS dex library to do most of the heavy lifting.</p> <p>Specifying Identity Providers</p> <p>You will need to provide the connection details for all the auth connectors you plan to use for teams up front. The full list of supported providers and their require parameters can be found on the Concourse docs site under Configuring Auth.</p> <p>Local Users, The Special Case</p> <p>Local Auth users are a bit of a special case because there\u2019s no external auth provider for them, and you can no longer \u201ccreate\u201d them on set-team.</p> <p>To add a local user you will need to add that user to the Concourse startup parameter list as described in the Local Authdocs.</p> <p>Whitelisting Users with set-team</p> <p>Once you have configured the providers you can freely add users/teams/orgs/groups/whatever to a team. This is as simple as using the parameters described in the fly set-team docs for Configuring Team Auth.</p> <p>As with most fly commands, you can actually attach multiple users/teams across providers to a team. For example: if you have GitHub and OAuth providers set up, a team owner could attach two teams (one from GitHub, one from OAuth) to the team.</p>"},{"location":"blog/2019-03-08-an-overview-of-authorization-in-concourse-3-4-and-5/#examples","title":"Examples","text":"<p>{{&lt; image src=\" /images/downloaded_images/An-Overview-of-Authorization-in-Concourse-3--4-and-5/1-c4yd3A2DIIrRYF8uqh9_fw.png\" width=\" 100%\" &gt;}}</p> <p>In this example we have a simple Concourse installation with two identity providers: GitHub and a single Local User.</p> <p>On the left we have two simple GitHub orgs: Pivotal and Concourse. Pivotal has three teams: cloud, billing and admin. Concourse has one team. Each team has a single user attached to them.</p> <p>On the right we have a map of the Concourse teams and their allowed users/groups.</p> <p>Let\u2019s go through a few scenarios to get a good understanding of how auth works in Concourse 4.</p> <p>Local User Logs In</p> <p>A Concourse user uses the local user provider to login with username:password and only sees Team Local.</p> <p>Alice Logs In</p> <p>Alice logs into Concourse using the GitHub auth scheme. She finishes the flow and sees..two teams! Because she is a member of the Pivotal GitHub org she sees Team All, which is configured to allow all users under the pivotal org on GitHub. She also sees Team 1 because it allows all users who are also memebers of pivotal:cloud on GitHub.</p> <p>Operator Logs In</p> <p>The Operator logs in using GitHub auth and\u2026can see everything! Because the Operator is part of the main team, they can see all teams. However, that does not mean the Operator can see all the team pipelines. In this scenario, the Operator can only see the Main and Team All team pipelines.</p> <p>A non-member logs in</p> <p>Jama finds out about this cool Concourse thing and logs into Concourse using the GitHub auth provider. Since he has a GitHub account he is able to login successfully. However, once the login flow is completed he is returned to Concourse and a blank screen\u2026nothing is available to him! Jama is not a member of a GitHub team/organization that was specified in the Concourse team configurations.</p>"},{"location":"blog/2019-03-08-an-overview-of-authorization-in-concourse-3-4-and-5/#debugging-login-problems","title":"Debugging Login Problems","text":""},{"location":"blog/2019-03-08-an-overview-of-authorization-in-concourse-3-4-and-5/#what-are-the-auth-settings-for-insert-team-name","title":"What are the auth settings for [insert team name]?","text":"<p>If you are an operator and you need to figure out what the exact auth settings are, you can use the new fly teams -dcommand. This will list the teams with details, including the users and groups whitelisted into that team</p>"},{"location":"blog/2019-03-08-an-overview-of-authorization-in-concourse-3-4-and-5/#help-i-logged-in-but-i-cant-see-my-team","title":"Help, I logged in but I can\u2019t see my team","text":"<ol> <li>Try using the search function on the dashboard. This is silly but for large Concourse clusters there are a LOT of    teams with exposed pipelines and it can be hard to find the team you need</li> <li>Logout and Log back in. Due to the implementation of the auth scheme, Users who are already logged into Concourse and    are added into a new team must refresh their token by logging out and logging in.    Yes, we know it sucks.</li> <li>Is the user a member of the org that was specified in set-team? For example, if GitHub team pivotal:foo was used,    make sure to ask if the user is a member of that team on GitHub!</li> <li>Was there a typo? Use fly set-team -d to look for the team in question and triple-check the spelling of usernames and    teams</li> <li> <p>Did you use the correct separator? Concourse requires all group separators to use : and not /:</p> </li> <li> <p>pivotal:foo is OK</p> </li> <li>pivotal/foo will fail silently on set-team</li> </ol>"},{"location":"blog/2019-03-08-an-overview-of-authorization-in-concourse-3-4-and-5/#i-have-two-identity-servers-how-do-i-add-them-both","title":"I have two Identity servers, how do I add them both?","text":"<p>Unfortunately, that is not possible in Concourse 4. You\u2019ll notice that you can only supply one set of credentials when providing auth providers. The side-effect limitation is that a single Concourse installation can\u2019t be connected to more than one of the same provider. The operator will have to set up another Concourse if they absolutely must be able to connect to two differet identity providers of the same type.</p>"},{"location":"blog/2019-03-08-an-overview-of-authorization-in-concourse-3-4-and-5/#concourse-50-rbac","title":"Concourse 5.0\u200a\u2014\u200aRBAC","text":"<p>Concourse 5.0 comes with 4 roles: Concourse Admin, Team Owner, Team Member, and Team Viewer.</p> <p>Concourse Admin</p> <p>A Concourse Admin is the same as today\u2019s admin user. Members of main team will automatically be Concourse Admins* and have the ability to administrate teams with fly: set-team, destroy-team, rename-team, and teams. Given that all Concourse Admins must be a member of the main team, all Concourse Admins must have at least one other role; and that should typically be the Team Owner role.</p> <p>Team Owner</p> <p>Team Owners have read, write and auth management capabilities within the scope of their team. For those familiar with Concourse today, the scope of allowed actions for a Team Owner is very closely aligned to today\u2019s Concourse team member. The new change is that you can no longer rename your own team or destroy your own team as an owner.</p> <p>Team Member</p> <p>Team Member is a new role that lets users operate within their teams in a read &amp; write fashion; but prevents them from changing the auth configurations of their team.</p> <p>Team Viewer</p> <p>Team Viewer is also a new role that gives users \u201cread-only\u201d access to a team. This locks everything down, preventing users from doing a set-pipeline or intercept.</p> <p>Full Roles Breakdown</p> <p>For a full list of each role\u2019s allowed actions you can reference our handy permission matrix on Google Sheets here.</p>"},{"location":"blog/2019-03-08-an-overview-of-authorization-in-concourse-3-4-and-5/#configuring-roles-with-fly","title":"Configuring Roles with fly","text":"<p>Now that we\u2019ve gone over the new roles, we can do a quick overview of how we can go about setting users &amp; roles on teams.</p>"},{"location":"blog/2019-03-08-an-overview-of-authorization-in-concourse-3-4-and-5/#default-behaviour","title":"Default Behaviour","text":"<p>By default, if no configuration is provided the user is given the Team Owner role:</p> <pre><code>fly -t dev set-team -n PowerRangers --local-user=Zordon\n\n#This behaviour also applies to groups as well, so be careful!\nfly -t dev set-team -n A-Team \\\n  --github-team=MightyMorphin:PowerRangers\n</code></pre>"},{"location":"blog/2019-03-08-an-overview-of-authorization-in-concourse-3-4-and-5/#specifying-roles-with-c","title":"Specifying Roles with <code>-c</code>","text":"<p>Roles must be specified in a separate configuration file using the -c</p> <pre><code>fly -t dev set-team -n A-Team -c ./team.yml\n</code></pre> <p><code>team.yml</code></p> <pre><code>roles:\n- name: owner\n  local:\n    users: [\"Zordon\"]\n- name: member\n  local:\n    users: [\"RedRanger\", \"BlueRanger\", \"GreenRanger\"]\n- name: viewer\n  local:\n    users: [\"Alpha\"]\n</code></pre>"},{"location":"blog/2019-03-08-an-overview-of-authorization-in-concourse-3-4-and-5/#inspecting-roles-configuration","title":"Inspecting Roles Configuration","text":"<p>Once you\u2019ve set the team configuration you can verify it using the details flag on fly teams:</p> <pre><code>fly -t dev teams -d\nname users groups\nA-Team/member local:RedRanger, BlueRanger, GreenRanger none\nA-Team/owner local:Zordon none\nA-Team/viewer local:Alpha none\n</code></pre> <p>..where you\u2019ll find the output is now updated to list each team/role combination and its associated users/groups.</p>"},{"location":"blog/2019-03-08-an-overview-of-authorization-in-concourse-3-4-and-5/#further-reading","title":"Further Reading","text":"<ul> <li>Oh, Auth by Josh Winters</li> <li>Concourse RBAC Preview.</li> <li>Concourse Auth &amp; Teams docs</li> </ul>"},{"location":"blog/2019-04-01-concourse-update--april-1-2019/","title":"Concourse Update (\ud83e\udd37-April 1, 2019)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update-----April-1--2019-/1-Z49uzJr_wqYlpCGLBpnoXQ.jpeg\" alt=\"Some airport somewhere... waiting\" width=\"50%\" &gt;}}</p> <p>Phew, it\u2019s been a while since I last wrote an update. For some background behind why I slowed down, hop on over to this thread on our forms: \u201cWhat would you like to see on our blog\u201d.</p> <p>That said, I do have a lot of interesting updates to share, so let\u2019s get started</p>"},{"location":"blog/2019-04-01-concourse-update--april-1-2019/#concourse-500","title":"Concourse 5.0.0","text":"<p>In case you missed it, Concourse 5.0.0 and 5.0.1 came out a few weeks ago in March. This is a major version release with tons of new features, including:</p> <ul> <li>Role Based Access Control</li> <li>Global Resource Cache</li> <li>fewest-build-containers placement strategy</li> <li>Resource pinning</li> <li>Inputs on the put step of a pipeline</li> <li>UI tweaks</li> <li>and much much more!</li> </ul> <p>Be warned, there are some breaking changes in this release as well; so make sure you read all ofthe release notes before you upgrade!</p> <p>You\u2019ll also notice that we recently gave the Concourse homepagea small makeover as well. We\u2019ve tightened up the navigation and expanded some sections of of our docs, check it out:</p> <ul> <li>Expanded docs onCredential Management with Vault and AWS SSM</li> <li>More info on the new Container Placement strategies</li> <li>A primer on the new Global Resources feature</li> <li>Our spiffy new Examples section, which gives you a side-by-side   comparison of a pipeline and the yml that made it</li> </ul>"},{"location":"blog/2019-04-01-concourse-update--april-1-2019/#interesting-blog-posts","title":"Interesting Blog Posts","text":"<p>There\u2019s also been some interesting blog posts about Concourse from around the interwebs\u2026and not all of them were written by me!</p> <ul> <li>An Overview of Authorization in Concourse 3, 4 and 5   is a useful overview of auth across 3 major versions of Concourse</li> <li>Installing Concourse 5.0 on Kubernets using Helm   is a great two-part overview of getting PKS installed and using the Concourse helm chart</li> <li>Building Go code, with and without Go modules, with Concourse</li> <li>Aptomi described how to   do CI/CD for Knative serverless apps on Kubernetes with Concourse</li> <li>Concourse-Up is now renamed   to \u201cControl Tower\u201d</li> <li>Someone compared us to Drone.io   in CI/CD tool showdown pits adoptability vs. adaptability</li> <li>We got a mention   on PorscheDev\u2019s Technology Radar vol 2 (I think   they like us :D)</li> </ul>"},{"location":"blog/2019-04-01-concourse-update--april-1-2019/#concourse-swag","title":"Concourse Swag","text":"<p>We have swag! With the help of the team at Pivotal we\u2019ve listed our first Concourse-branded sweater under the official Pivotal apparel store. A few notes:</p> <ul> <li>The sweaters themselves are listed at-cost, so we\u2019re not making any profit off of them</li> <li>Apologies to anyone who\u2019s not in the United States because international shipping through this store is atrocious.   We\u2019re going to be working with our partners to see if we can find a better shipping solution.</li> <li>At the time of this writing we\u2019re relatively low on M and L sweaters, there\u2019s a new shipment of those sizes coming in   soon so the store should be updated in a week or so</li> <li>Once this batch of sweaters sell out we\u2019ll be planning on doing new designs to keep things fresh!</li> </ul>"},{"location":"blog/2019-04-01-concourse-update--april-1-2019/#concourse-irl","title":"Concourse IRL","text":"<p>The Concourse team will be attending CF Summit NA 2019 this week in Philadelphia, so come by the Pivotal booth and say hi to the team!</p> <p>I\u2019ll also be attending a the ConcourseCI Bay Area User Group meetup on April 11th in Palo Alto. The title of the meetup is \u201cKubernetes Deployments with Concourse CI and Spinnaker\u201d. Come check it out if you\u2019re in the bay area!</p>"},{"location":"blog/2019-04-01-concourse-update--april-1-2019/#milestones-and-interesting-rfcs","title":"Milestones and Interesting RFCs","text":"<p>Alex Suraci has been experimenting with re-organizing our backlog of epics by using the GitHub Projects feature. You can see our current list of epics in the concourse/concourseproject list. The big things we\u2019re working on are:</p> <ul> <li>Spatial Resource</li> <li>API refactoring</li> <li>Ephemeral check containers (Runtime)</li> <li>and Concourse + K8s runtime</li> </ul> <p>On the topic of k8s runtime situation, please take a second to review Topher Bullock\u2019s new RFC #22 How Do We Best Leverage K8s as Runtime?. The team is evaluating Concourse + Tekton CD vs Concourse + K8s our own way.</p>"},{"location":"blog/2019-04-01-concourse-update--april-1-2019/#thanks-to-our-community","title":"Thanks to our Community \ud83d\ude4f","text":"<p>Finally, I wanted to give shout outs to our growing community of Concourse fans and followers. In early 2019 the Concourse team made two changes to our contributor workflow: we switched over to a looser Contributors License Agreement (CLA) and the core team moved towards a PR-based workflow. Since then we\u2019ve seen a lot more engagement on the work that we\u2019ve doing, and we\u2019ve also started to see a lot of new PRs coming in!</p> # of PRs opened over time against concourse/concourse and other key resources <p>In 2018, we saw 263 PRs opened against concourse/concourse and its core resources. As of today we already have more than 160 PRs opened by non-Pivots! Some notable PRs that I wanted to</p> <ul> <li>#3580 Add parallel Step</li> <li>#3163 [POC] Super nasty rendering of jobs that needs manual triggering</li> <li>#3560 Time based retention for build log collector</li> <li>#3430 Default the target if there is exactly one</li> <li>#3577 Auditor</li> <li>#3398 Make values starts with https or http clickable in build</li> <li>#3579 Display Task Duration on Finished Tasks</li> <li>#3475 web: add pause button to top bar of pipeline view</li> <li>#3248 Add option to prune all stalled workers instead of just one at a time</li> </ul>"},{"location":"blog/2019-04-01-concourse-update--april-1-2019/#the-future-of-weekly-updates","title":"The Future of Weekly Updates","text":"<p>I\u2019ll do my best to resume the weekly cadence of the project updates. In the meantime, if you have any specific opinions on what kind of blog posts we should right, I\u2019d suggest you check out this thread on our forums: \u201cWhat would you like to see on our blog\u201d</p>"},{"location":"blog/2019-04-05-concourse-update-april-15/","title":"Concourse Update (April 1\u20135)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--April-1-5-/1-nZQ4xbWXguDpNQzLEkcJcA.jpeg\" alt=\"Concourse in action at the CF Summit 2019 Grape Up booth\" width=\"50%\" &gt;}}</p> <p>Greetings from sunny Philadelphia! The team was there for the Cloud Foundry 2019 NA Summit for a few days; talking to Concourse users and attending talks. Recorded videos of the talks should be uploaded soon; so I\u2019ll point you to the interesting Concourse-related ones next week.</p> <p>On to the update.</p>"},{"location":"blog/2019-04-05-concourse-update-april-15/#for-active-discussion","title":"For Active Discussion","text":"<ul> <li>Please take some time to review and comment on the   latest Concourse + k8s Runtime RFC</li> <li>Regarding the runtime, there\u2019s been an active conversation around better build scheduling and load distribution. You   can catch up on the thread here. We\u2019d love for you to tell us   about your own experience in our meta-issue #3695</li> </ul>"},{"location":"blog/2019-04-05-concourse-update-april-15/#coming-soon-concourse-510","title":"Coming Soon: Concourse 5.1.0","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--April-1-5-/1-dEssJTEo9_VnNszNDUj6gQ.png\" alt=\"Icons on resources\" width=\"100%\" &gt;}}</p> <p>We\u2019re in the process of polishing up some items that we weren\u2019t quite able to zfit into the 5.0.0 release. There\u2019s been also some interesting new features and new PRs that you can look forward to in 5.1.0 as well:</p> <ul> <li>Resource icons #3581 thanks to efforts of   contributor mockersf</li> <li>You can now pause the pipeline from the pipeline view #3475 thanks   to the efforts of contributor robwhitby</li> <li>There\u2019s been a great de-coupling of the API from the runtime &amp;   scheduler #3307. This is a refactor and cleanup that brings us   closer to an API that we\u2019d be happy to publish and support.</li> <li>Introduced an on_error option to allow outside sources to be notified of CI   failure #3652 thanks to   contributor amanw</li> </ul>"},{"location":"blog/2019-04-18-concourse-update-april-818/","title":"Concourse Update (April 8\u201318)","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--April-8-18-/1-gTTAFBV8KHzEL0CV-I-_kA.jpeg\" alt=\"Roman Alekseenkov from Aptomi giving a talk on Concourse at the Bay Area User Group\" width=\"50%\" &gt;}}</p> <p>Sorry for missing the update last week. I was travelling out to the Bay area to attend the ConcourseCI Bay Area User Group. For those who missed it, you can find a recording of the event here. On to the update.</p> <p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--April-8-18-/1-QqwW-_RArz5a_sprZC7PZw.png\" width=\"100%\" &gt;}}</p> <p>In case you missed it, Concourse 5.1.0 is out! It\u2019s got icons on resources, better garbage collection, <code>on_error</code> on pipelines, and much more! As usual, you can read the full list of new features here.</p> <p>Other interesting developments:</p> <ul> <li>The runtime team has been looking into the administrative overhead of running tasks on workers. The results are pretty   sobering. More to come next week!</li> <li>We\u2019re still looking into the k8s Tekton integration. We expect things to pick up in pace starting next week, where   we\u2019ll have a few more Pivots lending a helping hand. Again, you can find our   RFC here</li> <li>The sidebar is coming back, and we\u2019re exploring how we can   extend the search and filtration capabilities across Concourse</li> <li>I added a section called \u201cConcourse Users\u201d on   our Community page. This is just some of the companies and   folks that have spoken about their Concourse usage in the past. If you\u2019d like to add to that list feel free to make   a PR here</li> </ul>"},{"location":"blog/2019-05-03-concourse-update-april-293/","title":"Concourse Update April 29\u20133","text":"<p>In case you missed it, we\u2019ve made some tweaks to the structure of the website. I\u2019m happy to report that Alex Suraci drastically improved our site-wide search. This resolves #181 and we\u2019re all the better for it!</p> <p>Second, you\u2019ll notice that a lot of the community related comment that was on our homepage has now been moved to our Concourse GitHub Wiki. We hope this change will make contributor and community specific content more discoverable and more maintainable over time.</p> <p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update-April-29-3/1-08IsVksi-Nc9O0BnmW5MiA.png\" alt=\"Concourse Wiki with more Contributor things!\" width=\"100%\" &gt;}}</p> <p>Notably, the Resource Types, Tutorials, and Tools page has moved over to the wiki. Content that may be new to some of you include the Project Management section: How Issues are Managed, How to Process PRs, and Release Process.</p> <p>On to the update.</p>"},{"location":"blog/2019-05-03-concourse-update-april-293/#k8s-runtime","title":"K8s Runtime","text":"<p>Bohen and Sameer have been doing some great write-ups on their research. You can get caught up with their latest research in two GitHub issues: What does k8s offer as a runtime and What does Tekton offer as a runtime. If you\u2019d like to track along with this project\u2019s movements you can bookmark the K8s Runtime project board here: https://github.com/concourse/concourse/projects/14</p>"},{"location":"blog/2019-05-03-concourse-update-april-293/#ux","title":"UX","text":"<p>The Sidebar is coming back! Check out our latest designs in #2440.</p> <p>We\u2019ve been looking into a few UI regressions in the web frontend as well. Specifically, #3745 and #3748 have been moved to the top of the backlog</p>"},{"location":"blog/2019-05-03-concourse-update-april-293/#runtime","title":"Runtime","text":"<p>We\u2019ve been working on #3607 and #3810 as sub-stories to help with Ephemeral Check Containers #3424</p> <p>Divya Dadlani has also been thinking a lot more about \u201cPerformance benchmarking for Concourse releases\u201d #3816. The idea is that we should be a bit more rigorous in tracking how Concourse improves with some of the runtime performance changes. Jump on over to the issue and drop a line if you have any ideas/opinions on this subject.</p>"},{"location":"blog/2019-06-07-concourse-update-june-7/","title":"Concourse Update June 7","text":"<p>...and we\u2019re back! Apologies for the lack of updates lately. I\u2019ve just come back from some time off and work travel has taken up a lot of my time. I\u2019m back in Toronto now so let\u2019s get back into it.</p>"},{"location":"blog/2019-06-07-concourse-update-june-7/#release-engineering-concourse-530","title":"Release Engineering &amp; Concourse 5.3.0","text":"<p>In the past, we relied a lot on Alex Suraci to handle a lot of our release engineering work. Release Engineering is incredibly important and valuable work for the Concourse team, but it can also very time consuming. Thankfully, the UX track has volunteered some of their time to spin up our new Release Engineering track of work to help alleviate Alex from some of his responsibilities. This means a short-term slowdown in the throughput of the UX team, but we think its well worth the tradeoff.</p> <p>On that note, you can now follow along with our release plans for Concourse 5.3.0 by tracking our project note. Unfortunately, we were mostly blocked on some metrics instabilities in our production instance this week. Those issues have been mostly cleared up and we hope to be able to continue with our production and wings tests next</p>"},{"location":"blog/2019-06-07-concourse-update-june-7/#coreapi","title":"Core/API","text":"<p>The team\u2019s been making a lot of progress on two key issues:</p> <ul> <li>The Algorithm\u2122</li> <li>Resource check queue</li> </ul> <p>The team has been doing some preliminary performance tests with the new Algorithm and the results so far have been very promising. We\u2019ll be reporting more details on the performance improvements in the coming weeks; so keep an eye out for that!</p>"},{"location":"blog/2019-06-07-concourse-update-june-7/#runtime","title":"Runtime","text":"<p>Ephemeral check containers is back! We\u2019ve deployed our changes as-is on our test environment and are monitoring it for lower container counts in our environments</p> <p>Parallel Input Streaming was picked up by Krishna today, its amazing and there\u2019s totally lots of detail to be found on the linked issue.</p>"},{"location":"blog/2019-06-07-concourse-update-june-7/#k8s-concourse-koncourse","title":"K8s + Concourse == Koncourse?","text":"<p>We have two RFCs in flight, please take some time to read through the changes:</p> <ul> <li>Exploring Initial Run/Store interface: In order to port   Concourse on to non Garden/Baggageclaim runtimes (including Kubernetes!) we need to separate the two concepts of   containers as the unit of execution and volumes as the unit of storage. We\u2019re fleshing out the interface that these   components can implement in this RFC.</li> <li>Extract Core Resource Types: a proposal to not ship bundled base resource   types with concourse. The change would require Concourse to pull the base resource types on-demand at runtime. This is   required for moving establishing a more generic storage interface.</li> </ul> <p>You\u2019ll also note that we\u2019ve created a architecture-rfcs repo. This repository is reserved for internal RFCs that should not directly impact a Concourse user.</p>"},{"location":"blog/2019-06-07-concourse-update-june-7/#duty-free","title":"Duty Free","text":"<p>The proposal for a Concourse \u201cDuty Free\u201d was first reported in issue #191; its the idea of creating a separate site to highlight community resources and other re-usable Concourse artifacts for our community. Today, advertise Concourse resources through the Resources page in our wiki, but a dedicated Concourse Duty Free site would have a lot more pizzaz.</p> <p>We\u2019ve always wanted to build Duty Free but we were never been able to figure out how to slot it into our work schedule. Thankfully, the Pivotal team out in Dublin had some time and offered to help kick-start the project for us. We\u2019re still in the very early stages of development and design, but you can follow along the project on their GitHub repo here: concourse/dutyfree</p>"},{"location":"blog/2019-06-21-concourse-update-july-21-2019/","title":"Concourse Update (July 21 2019)","text":"<p>The Concourse team had the opportunity to visit some Concourse users out in Montreal last week. We had a blast meeting everyone, including some folks from the Concourse OSS community. Thanks again for hosting us!</p> <p>I\u2019ll also be in Kansas City for two days next week to meet some other Concourse users as well, so give me a tap onTwitter or Discord (username jama) if you wanna meet up.</p>"},{"location":"blog/2019-06-21-concourse-update-july-21-2019/#parallel-input-streaming","title":"Parallel Input Streaming","text":"<p>{{&lt; image src=\"/images/downloaded_images/Concourse-Update--July-21-2019-/0-ywZaAHKMEtZGTx5c.png\" alt=\"initialization dropped from 1 hour 22 min to just over 4 min\" width=\"60%\" &gt;}}</p> <p>In addition to the work on Algorithm improvements from the Core track, the Runtime track tested out their new work on Parallel Input Streaming. By parallelizing the input streams we saw a massive improvement on the initialization of tasks in our test pipelines. In our test we saw Dwayne Forde\u2019s Strabo pipeline (which has over 100 input resources on a job) go from a 1 hour, 22 min initialization to just over 4 min. We were able to observe these results on both the BOSH and k8s deployment of Concourse. Exciting work!</p>"},{"location":"blog/2019-06-21-concourse-update-july-21-2019/#runtime-interface-track","title":"Runtime Interface Track","text":"<p>For those who are interested, you can follow along our swappable runtimes (including k8s) work in the Runtime Interface track. We\u2019ve been doing a lot of planning and research, but its all come down to \u201clets just give it a shot\u201d. We\u2019ll probably have more to say on this next update.</p>"},{"location":"blog/2019-06-21-concourse-update-july-21-2019/#release-engineering","title":"Release Engineering","text":"<p>One of the big changes that have come out of our Release Engineering track is extracting our ci automation into its own repository. This was done to make our project more resilient and reusable. You can now track those changes under concourse/ci</p>"},{"location":"blog/2019-07-02-designing-a-dashboard-for-concourse/","title":"Designing a Dashboard for Concourse","text":""},{"location":"blog/2019-07-02-designing-a-dashboard-for-concourse/#how-does-the-concourse-team-go-about-solving-the-problem-of-pipeline-monitoring","title":"How does the Concourse team go about solving the problem of pipeline monitoring?","text":"<p>With the growing popularity of Concourse, we noticed that our development teams wanted to observe and monitor multiple pipelines simultaneously. This behaviour wasn\u2019t limited to just Pivotal engineering teams; in fact, it was even more prevalent amongst our Open Source Community. Our users currently solve this by cramming multiple browser windows into TV their monitor view or they use the Concourse Summary (aka Crystal) by David Goddard of the Pivotal Buildpacks team.</p> <p>{{&lt; image src=\"/images/downloaded_images/1_nU107xCbOq-21YkWl2OBXQ.png\" alt=\"Concourse pipelines (left) Datadog and Concourse Summary (right)\" width=\"100%\" &gt;}} https://github.com/dgodd/concourse-summary</p> <p>So, we embarked on a deeper Discovery effort with the goal of understanding and evaluating our assumptions around how Concourse users were solving this problem today.</p> <p>At Pivotal, we believe that products\u2019 solutions need to be designed with the user in mind and we practice a style of user-centered design that progresses in four phases:</p> <ol> <li>Learning: How are Users are solving this problem today?</li> <li>Framing: Formulate a hypothesis based on your learnings. Create a prototype or experiment that is based on the    exploratory research.</li> <li>Assessing: Put your experiment in front of users to see if your hypothesis is right.</li> <li>Iterating: Repeat steps 1\u20133 to iterate on the solution as you get feedback.</li> </ol>"},{"location":"blog/2019-07-02-designing-a-dashboard-for-concourse/#learning-understanding-the-problem-space","title":"Learning: Understanding the Problem space","text":"<p>We began this process by thinking about the assumptions that were made about this feature and what we needed to validate in our interviews.</p> <ul> <li>Users are not satisfied with the current single pipeline view \u2014 especially on a monitor vs. a dedicated CI display   like a TV</li> <li>Only seeing red or green pipeline status is all that is important for pipeline summary</li> <li>Users want to understand the state of all their teams</li> <li>Users recognize their pipelines by their shape in the UI</li> </ul> <p>{{&lt; image src=\"/images/downloaded_images/1_fnSsJkhigoNgfuURiOPCpg.png\" class=\"Miro board\" width=\"100%\" &gt;}}</p> <p>After we went out in the field to talk to users, we came back to synthesize our findings using this virtual whiteboard tool called Realtimeboard. One of our team members was remote, so this tool allowed us to easily collaborate on our research.</p> <p>\u201cDid it just turn red 10 seconds ago, or one week ago? I have no idea.\u201d \u2014 a Pipeline Engineer</p> <p>From our research, we found that users only care about failed jobs and the amount of time that their pipeline has been failing. This information is crucial for engineering teams as it is used to triage their pipeline errors and influences the prioritization of work. Many development teams we talked to are using a micro-service based architecture and therefore most of their pipelines are composed of four jobs (build, test, deploy and health check). While we assumed that the shape of a pipeline would be identifying, it was more important for the user to see the status.</p> <p>Based on the feedback we collected we began to prioritize our insights and frame our solution. We proceeded to brainstorm and sketch ideas for a prototype experiment.</p> <p>{{&lt; image src=\"/images/downloaded_images/0_Iz72Bh80-LNbQc-I.png\" alt=\"Early Dashboard prototype\" width=\"50%\" &gt;}}</p> <p>Our first InVision prototype represented each team\u2019s pipeline as a series of thumbnails. We believed this approach would help users identify their pipelines, and at the same time have an at-a-glance view of the pipeline status. Our first round of feedback from users revealed that the thumbnail was not as useful as we had thought, and our approach made it more difficult to understand what the pipeline status was.</p> <p>So, we pivoted and started to explore the idea of a pipeline thumbnail that abstracts the current pipeline representation into a more substantial information radiator.</p> <p>Alex Suraci, co-creator of Concourse, had been working on a UI experiment, based on a treemap chart (below), that looked like something we could expand upon. I hypothesized that by removing the resources from this view and stripping down the thumbnail to just jobs we could provide the user with just enough information for \u2018at a glance\u2019 triaging.</p> <p>{{&lt; image src=\"/images/downloaded_images/0_VKfa4IVa51zOWoiU.png\" width=\"50%\" &gt;}} {{&lt; image src=\"/images/downloaded_images/0_V2tAM1z62u0gd-Sx.png\" alt=\"Alex\u2019s pipeline treemap algorithm experiment ( left). Thumbnail compression of the pipeline for the Concourse Dashboard (right).\" width=\"25%\" &gt;}}</p> <p>This was a radical idea with significant departures from the current visual style of Concourse. We didn\u2019t want to just \u201cdo it\u201d and release it to our community of users without some kind of feedback first. As a product designer, my first inclination was to start drawing up thumbnail variations that we could test with our users. However, there was no clear taxonomy of pipelines because every team within Pivotal has a drastically different pipeline configuration. We needed a quick way to test this design with \u201crealistic\u201d pipeline configurations at scale. Luckily for us, the Concourse team runs an internally managed multi-tenant instance of Concourse called Wings. We use Wings as a sandbox for new features, so I paired with an engineer to do a lightweight implementation for Wings.</p> <p>{{&lt; image src=\"/images/downloaded_images/0_bJ8wRINc9fo3aZ5L.png\" width=\"100%\" &gt;}}</p> <p>Since our initial rollout of the dashboard on Wings in September 2017, we have undergone at least 3 major revisions of the dashboard based on the feedback we had received from teams within Pivotal. Our next step was to incorporate this dashboard into the core product as a beta feature without disrupting users who are looking for a more stable Concourse experience.</p> <p>As of Concourse 3.5.0 you can find the dashboard under <code>/dashboard/</code> and as of Concourse 3.6.0 you can find the dashboard under <code>/beta/dashboard</code> . We hope you like this feature and are actively looking for feedback from the community.</p> <p>If you have a comment and want to participate in the conversation for the dashboard UI, please visit the issue in GitHub: https://github.com/concourse/concourse/issues/1829 .</p>"},{"location":"blog/2019-07-17-core-roadmap-towards-v10/","title":"Core roadmap: towards v10","text":"<p>A long-term roadmap for the core design of Concourse, a general-purpose CI/CD tool.</p> <p>Accompanying slides. Recommended viewing: episode 1 of Yu-Gi-Oh.</p> <p>Concourse's design philosophy is to be expressive, versatile, and safe while limited to a handful of simple, proven concepts. The design of these concepts should make good practices feel intuitive and bad practices feel uncomfortable.</p> <p>Coming up with these designs can be very challenging. There are many different workflows and patterns across the software industry, and they each have to be deeply understood in order to know what the good and bad practices are.</p> <p>This post provides a bit of insight into what we've been up to with Concourse's core design - chiefly regarding ' spaces', which has become a bit of a white whale on our roadmap.</p> <p>There are a lot of words here - sorry! If you just want to skim, I've added a single-paragraph summary under each roadmap entry.</p> <p>Each roadmap entry corresponds to an RFC or an issue, linked in their header. If you want to get involved in our design process or just provide feedback, please check them out and submit a PR review! (Thanks!)</p>"},{"location":"blog/2019-07-17-core-roadmap-towards-v10/#table-of-contents","title":"Table of contents","text":"<ol> <li>Where is 'spaces'?</li> <li> <p>Where are we now?</p> </li> <li> <p>Issue #3602: a new algorithm</p> </li> <li> <p>Issue #413: build re-triggering</p> </li> <li> <p>Where are we going?</p> </li> <li> <p>RFC #24: resources v2</p> </li> <li>RFC #26: artifact resources</li> <li>RFC #31: <code>set_pipeline</code> step</li> <li>RFC #32: projects</li> <li>RFC #33: archiving pipelines</li> <li>RFC #34: instanced pipelines</li> <li>RFC #29: spatial resources</li> <li>RFC #27: trigger resources</li> <li> <p>RFC #28: notification resources</p> </li> <li> <p>What comes after all this?</p> </li> <li>Thanks!</li> </ol>"},{"location":"blog/2019-07-17-core-roadmap-towards-v10/#where-is-spaces","title":"Where is 'spaces'?","text":"<p>For those of you not familiar with spaces, it was a big ol' feature that enabled the following workflows:</p> <ul> <li>Dynamically running against things like branches/pull requests, which change over time (i.e. commits to a branch)   and space (i.e. the set of branches themselves). Hence the name 'spaces.'</li> <li>Fanning in using <code>passed</code> constraints across spaces. This is currently impossible to do with separate pipelines,   because pipelines can't reference each other's resources.</li> <li>Automatically cleaning up spaces for closed PRs, etc. This is annoying to automate and requires keeping track of   state.</li> </ul> <p>These workflows still make sense, so why is 'spaces' dead?</p> <p>Well, I approached it the wrong way. To me, the idea of resources tracking change over time and space felt pretty solid from a theoretical standpoint. In hindsight, maybe it just sounded cool.</p> <p>I had no reservations baking 'spaces' in to every layer of the stack - it would add more depth to all the existing ideas. Everything was going to change: the resource interface, the web UI, how jobs work... It was all so exciting!</p> <p>But as time went on it became terrifying. It was a double-or-nothing bet. Either 'spaces' made sense everywhere, or ' spaces' didn't make sense at all. I tried to carve out work that could be done before fully committing to spaces, but it didn't make the monolithic feature any less monolithic.</p> <p>{{&lt; image src=\"/images/2019/07/scaredy-cat-2.gif\" alt=\"me vs the space dragon\" width=\"25%\" &gt;}}</p>"},{"location":"blog/2019-07-17-core-roadmap-towards-v10/#where-are-we-now","title":"Where are we now?","text":"<p>First off, I want to give a quick update on a couple of big things that you can expect in v6.0:</p>"},{"location":"blog/2019-07-17-core-roadmap-towards-v10/#issue-3602-a-new-algorithm","title":"Issue #3602: a new algorithm","text":"<p>We are re-designing the algorithm used for determining the candidate input versions for a job. The new approach will rely less on brute force and will perform better with large installations.</p> <p>This new algorithm fixes long-standing architectural issues with the old one, which loaded each pipeline's entire build and resource version history into memory and determined valid candidates using brute force.</p> <p>The key difference between the old and new algorithm is how <code>passed</code> constraints are implemented, specifically when multiple inputs depend on the same job:</p> <pre><code>plan:\n- get: foo\n  passed: [foo-unit, integration]\n- get: bar\n  passed: [bar-unit, integration]\n- get: baz\n  passed: [integration]\n</code></pre> <p>In Concourse, this means \"give me versions of <code>foo</code>, <code>bar</code>, and <code>baz</code> that have passed through <code>integration</code> together in the same build, with the same version of <code>foo</code> having passed <code>foo-unit</code> and the same version of <code>bar</code> having passed <code>bar-unit</code>.\"</p> <p>How does this work? Well, it's hard to describe either algorithm succinctly, but I'll try:</p> <ul> <li>The old algorithm goes through resource versions, newest first, and checks whether each version satisfies the input's   own <code>passed</code> constraints. Next it checks that any other already-chosen input versions which mention the same job in   their <code>passed</code> constraints also came from the same build, recursing and walking through versions until everything is   satisfied. This process is brute-force, an uses a lot of CPU.</li> <li>The new algorithm instead loops over build output version sets via the jobs listed in each <code>passed</code> constraint,   assigning all the relevant versions for a given build at once as long as the versions match the other already-chosen   versions assigned via builds of prior jobs in the <code>passed</code> constraint.</li> </ul> <p>This new approach really simplifies things because the versions are inherently coming from the same build. Now that we don't have to do the extra cross-referencing, the new flow can just make a handful of cheap database queries instead of having to load the whole pipeline's dataset into memory.</p> <p>We've been testing the old and new algorithm in two separate environments, each at the scale of 1,000 jobs with varying <code>passed</code> constraints and a sprinkle of <code>version: every</code> across four <code>web</code> nodes.</p> <ul> <li>The old algorithm starts off very fast but grows slower and slower as the pipeline dataset grows, eventually   exhausting the <code>web</code> nodes of RAM and swap.</li> <li>The new algorithm starts off slightly slower than the old one - it's hard to beat an in-memory dataset - but it stays   stable, uses less CPU, and does not leak memory.</li> </ul> <p>We're making a few final touches as we to get as much performance out of the new algorithm as possible, since we don't tend to touch it often. Once we're finished, we'll jump straight to...:</p>"},{"location":"blog/2019-07-17-core-roadmap-towards-v10/#issue-413-build-re-triggering","title":"Issue #413: build re-triggering","text":"<p>The new algorithm changes the behavior for today's pinning-based flow for re-triggering a build, so we're going to implement proper support for build re-triggering and ship these two features together in v6.0.</p> <p>Right now the only way to \"re-trigger\" a build is to pin each of the job's upstream resources to the version from the build, trigger a new build, and go back and un-pin them all. It's pretty cumbersome and error-prone.</p> <p>It also kind of breaks with the new algorithm. Now that the new algorithm is based on build output sets and not version history, once the new build succeeds its older versions will end up being the first set attempted for that job, potentially propagating them to downstream jobs.</p> <p>That's not what I would expect from a re-trigger. I would expect a re-trigger to act \"in-place,\" while preserving the logs of the original failure for posterity.</p> <p>To avoid this surprising change in behaviour, we're going to implement build re-triggering properly and stop abusing the version pinning feature, which was originally designed for temporarily pinning a broken upstream dependency to a \"known good\" one.</p> <p>Build re-triggering will be implemented in a way that preserves the order of the builds that the algorithm will go over. If the re-triggered build succeeds, its set of outputs will be available to downstream jobs based on the original build's order.</p> <p>Another benefit to implementing re-triggering soon is that folks using a pull request resource will have a much easier time re-triggering failed pull requests, without having to wait on the rest of the roadmap (i.e. 'spaces').</p>"},{"location":"blog/2019-07-17-core-roadmap-towards-v10/#where-are-we-going","title":"Where are we going?","text":"<p>So, going back to the 'spaces' initiative. The pieces really started to fall into place over the past few months, and I think I've arrived at a roadmap that accomplishes all of the goals of 'spaces' but in a significantly more Concourse-y way.</p> <p>Instead of one monolithic feature, I have a bunch of smaller features to propose that are independently valuable and can be delivered in any order. As we complete them, a bigger picture will start to take shape.</p> <p>Let's jump right in!</p>"},{"location":"blog/2019-07-17-core-roadmap-towards-v10/#rfc-24-resources-v2","title":"RFC #24: resources v2","text":"<p>Resources v2 is the first major revision of the resource interface since Concourse's inception. It's a step to take very carefully. I think we're finally ready to go.</p> <p>**UPDATE: Just kidding! This proposal has been superceded by something even more general: Prototypes! (RFC #37) **</p> <p>The v2 interface brings long-awaited polish to the interface: it renames <code>in</code> and <code>out</code> to <code>get</code> and <code>put</code> to match their step names, introduces a <code>delete</code> action, standardises TLS configuration, and revises terminology so as to not be coupled to the 'versioned artifacts' use case.</p> <p>The latest proposal for Resources v2, RFC #24, is a lot like RFC #1 but with one big difference: 'spaces' is no longer a foundational piece of the interface. Instead, RFC #24 proposes that we generalize and simplify the interface to an extent that it can be used for various pipeline workflows, not just versioning artifacts.</p> <p>The new direction is to leverage composition between resources and pipelines via config fragments, which can be passed from one resource to another or used for <code>((vars))</code> in a pipeline template. 'Config fragments' replace 'versions' in the interface, and are used as versions for the 'versioned artifacts' flow (today's primary use of resources).</p> <p>By generalizing the resource concept we set the stage for proper pipeline-level support for notifications (e.g. Slack alerts, GitHub commit status), trigger-only resources (e.g. <code>time</code>), and spatial resources (e.g. branches, pull requests) without tying each use case into the interface itself.</p> <p>Now that 'spaces' is gone from the interface, the actual change in the interface protocol is somewhat cosmetic. As a result, Concourse pipelines will be able to use v1 and v2 resources side-by-side for all the same functionality. This way we can move forward with pipeline-level resource features without fragmenting the resource ecosystem!</p>"},{"location":"blog/2019-07-17-core-roadmap-towards-v10/#rfc-26-artifact-resources","title":"RFC #26: artifact resources","text":"<p>Artifact resources are an interpretation of the generic resource interface that maps to today's usage of the resource interface.</p> <p>UPDATE: this is now RFC #38, \" Resource Prototypes\"</p> <p>Artifact resources use config fragments as versions, modeling change to an external entity over time. This should sound familiar to anyone using Concourse today: they're the sole use case that Concourse resources were originally designed around.</p> <p>The 'artifact resources' proposal clarifies that this is now just one use case for the general resource interface, and outlines a few long-awaited features:</p> <ul> <li>Versions can be deleted using the <code>delete</code> action in the resource interface.</li> <li>The <code>put</code> action can emit multiple versions. Each will be recorded as an output of the build.</li> <li>The automatic <code>get</code> after the <code>put</code> step will be made opt-in. (Huzzah!)</li> </ul> <p>The automatic <code>get</code> after each <code>put</code> is something that has confused and occasionally frustrated users, but we didn't want to break backwards compatibility and we didn't want users to have to 'opt out' (that's too many knobs to turn).</p> <p>This RFC will provide a backwards-compatible transition path to artifact resources. Check out RFC #26 for more details!</p>"},{"location":"blog/2019-07-17-core-roadmap-towards-v10/#rfc-31-set_pipeline-step","title":"RFC #31: <code>set_pipeline</code> step","text":"<p>The first step on our journey towards 'spaces' is to introduce a simple, but critical piece of the puzzle: a <code>set_pipeline</code> step.</p> <p>The <code>set_pipeline</code> step is used like so:</p> <pre><code>jobs:\n- name: bootstrap\n  plan:\n  - get: ci\n    trigger: true\n  - set_pipeline: concourse\n    file: ci/pipelines/concourse.yml\n</code></pre> <p>This job will configure a <code>concourse</code> pipeline within the job's team. The pipeline will be automatically unpaused, and no authentication is required.</p> <p>The first thing this lets us do is deprecate the <code>concourse-pipeline</code> resource, which has two pretty fundamental problems:</p> <ul> <li>Having to configure auth is really awkward - you have to set up a local user and give the resource the keys to the   kingdom.</li> <li>Keeping the version of <code>fly</code> within the resource in sync with your own Concourse's version is a bit clunky.</li> </ul> <p>With the <code>set_pipeline</code> step, both of these problems immediately go away and pipelines start to feel a more first-class rather than just being the tip of the abstraction iceberg.</p>"},{"location":"blog/2019-07-17-core-roadmap-towards-v10/#rfc-32-projects","title":"RFC #32: projects","text":"<p>Ok, I promised to provide a tl;dr for each roadmap entry, but projects can't really be summed up that easily. This is the most impactful feature on this roadmap.</p> <ul> <li>A \"project\" is a new concept bootstrapped by two existing ones: a resource   from which to continuously load the project's config, which specifies   a build plan to execute whenever the project resource changes.</li> <li>Projects act as a namespace for pipelines, and provide a long-requested workflow for automating their configuration.   As the roadmap goes on, this workflow becomes more and more powerful.</li> <li>Projects allow you to define project-wide resources which let you clean up duplicate definitions across your   pipelines and support cross-pipeline <code>passed</code> constraints.</li> <li>Projects also define project-wide tasks, which remove the need to thread a resource through all your jobs just to   have the task configs to execute, and finally gives meaning to task names (the <code>x</code> in <code>task: x</code>).</li> </ul> <p>A project's build plan can be used for anything you want. Small projects could use the build plan to run tests and/or perform various steps in a single build - a workflow more familiar to users of other CI systems:</p> <pre><code>name: ci\nplan:\n- get: booklit\n  trigger: true\n- task: unit\n</code></pre> <p>Larger projects could use the build plan to execute <code>set_pipeline</code> steps. Concourse has long encouraged users to keep their pipelines under source control, but it never enforced it: <code>fly set-pipeline</code> was still a manual operation, and users would often forget to check in their changes. Projects will fix that:</p> <pre><code>name: ci\nplan:\n- set_pipeline: booklit\n</code></pre> <p>Small projects may start without pipelines and start using pipelines as they grow. Our original slogan, 'CI that scales with your project,' is now pretty literal! The hope is that by introducing build plans without requiring knowledge of pipelines and jobs, we'll have made Concourse's learning curve more gradual and made Concourse feel less overkill for side-projects.</p> <p>This feature will have far-reaching implications for Concourse, so it won't be sneaking in quietly. I've opened RFC #32 and would really appreciate feedback!</p>"},{"location":"blog/2019-07-17-core-roadmap-towards-v10/#rfc-33-archiving-pipelines","title":"RFC #33: archiving pipelines","text":"<p>Archiving pipelines is a way to soft-delete a pipeline while still being able to peruse the build history for a pipeline you no longer want.</p> <p>Well, after that bombshell this one's pretty easy to explain. Let's take a look at our own Concourse team's pipelines:</p> <p>{{&lt; image src=\"/images/2019/07/Screenshot-from-2019-07-16-11-49-33.png\" width=\"100%\" &gt;}}</p> <p>Look at all that cruft! So many old, paused or bit-rotting pipelines which I really don't care about anymore but don't really have the heart to delete. That <code>old-concourse</code> pipeline served us well for years - it has sentimental value. In some cases you may also want to keep the history around for auditing purposes.</p> <p>Archiving pipelines will allow you to humanely retire a pipeline in a way that gets it out of your way while still allowing you to peruse the build history should you ever need to. Archived pipelines are no longer active and will allow you to re-use their name without bringing the old pipeline back.</p> <p>There's already an open pull request for this: #2518 - shout-out to @tkellen! The ball has been in our court for a while to figure out the UI/UX, so we're just going to submit a new RFC and work out all the details.</p>"},{"location":"blog/2019-07-17-core-roadmap-towards-v10/#rfc-34-instanced-pipelines","title":"RFC #34: instanced pipelines","text":"<p>Instanced pipelines group together pipelines which share a common template configured with different <code>((vars))</code>. They provide a simple two-level hierarchy and automatic archiving of instances which are no longer needed.</p> <p>Instanced pipelines are an important piece of the 'spaces' puzzle: it's how users will navigate through their spatial pipelines, and it's what keeps no-longer-relevant spaces for e.g. merged PRs and deleted branches from piling up forever.</p> <p>Pipeline instances are created using the <code>set_pipeline</code> step like so:</p> <pre><code>plan:\n- set_pipeline: branch\n  instance_vars:\n    branch: feature/projects\n- set_pipeline: branch\n  instance_vars:\n    branch: feature/new-algorithm\n</code></pre> <p>At the end of a build which uses <code>set_pipeline</code>, all instances of the named pipelines which were not configured by the build will be automatically archived.</p> <p>Check out RFC #34 for more details!</p>"},{"location":"blog/2019-07-17-core-roadmap-towards-v10/#rfc-29-spatial-resources","title":"RFC #29: spatial resources","text":"<p>Spatial resources are resources whose <code>check</code> monitors spatial change, not change over time. Two common examples are the set of branches or open pull requests for a repo. The <code>across</code> step allows a build to process each 'space' and trigger on changes to the set.</p> <p>UPDATE: the syntax for this step has since been tweaked so that multi-var matrices don't require nesting <code>across</code> steps.</p> <p>When used with the new <code>across</code> step, the \u00a0<code>set_pipeline</code> step, and instanced pipelines, this enables dynamic pipeline configuration across spatial change.</p> <p>The final piece of the puzzle for 'spaces' is the addition of an <code>across</code> step. This step points to a resource and has a plan which will execute for every config fragment returned by the resource's <code>check</code>, all within one build.</p> <p>Let's first look at a simple use case, which is to execute a task across many variants:</p> <pre><code>plan:\n# ...\n- across: supported-go-versions\n  as: go\n  do:\n  - task: unit\n    image: go\n</code></pre> <p>In this case, imagine we have a <code>supported-go-versions</code> resource whose <code>check</code> returns a config fragment for each tag and digest based on a pre-configured list of supported tags (e.g. <code>1.10</code>, <code>1.11</code>, <code>1.12</code>), and whose <code>in</code>/<code>get</code> fetches the image.</p> <p>When nested, the <code>across</code> step enables dynamic build matrices:</p> <pre><code>plan:\n# ...\n- across: supported-go-versions\n  as: go\n  do: # needed so we can define another 'across'\n  - across: other-things\n    as: some-input\n    task: unit\n    image: go\n</code></pre> <p>When used with <code>set_pipeline</code> and instanced pipelines, it enables dynamic pipeline matrices:</p> <pre><code>plan:\n- across: repo-branches\n  as: repo-branch\n  set_pipeline: branch\n  instance_vars:\n    branch_name: ((repo-branch.name))\n</code></pre> <p>(Assuming we provide the ability to access fields of an artifact with <code>((vars))</code>.)</p>"},{"location":"blog/2019-07-17-core-roadmap-towards-v10/#rfc-27-trigger-resources","title":"RFC #27: trigger resources","text":"<p>Trigger resources allow jobs to specify parameters that can trigger new builds but don't have anything to fetch - they just propagate config fragments to the build.</p> <p>UPDATE: this has turned into a <code>get_var</code> step, rather than a <code>param</code> step</p> <p>This is also a relatively simple feature, but it will improve today's usage of the <code>time</code> resource by having per-job trigger semantics rather than having all jobs downstream of one <code>time</code> resource leading to a thundering herd of builds hitting your workers all at once.</p> <p>Rough sketch:</p> <pre><code>jobs:\n- name: smoke-test\n  plan:\n  - param: 10m\n    trigger: true\n</code></pre> <p>Semantically, <code>param</code> is similar to <code>get</code> but with one key difference: there is no central version history. Rather than being used as an artifact, the resource is used solely for its config fragments. Concourse will <code>check</code> against the job's last used config fragment for the trigger resource, <code>10m</code>, and if a different fragment is returned the job will trigger with the new one.</p> <p>This skips the <code>get</code>, eliminates the thundering herd issue (because all jobs have their own interval), and could enable an interesting pattern for manually-parameterized builds: just write a resource type that can fetch user-provided config fragments from some external source (i.e. a repo).</p> <p>Here's one idea of what that may look like, where the config fragments returned by param are somehow usable with <code>((vars))</code> syntax in subsequent steps:</p> <pre><code>plan:\n- param: environment\n- task: smoke-test\n  vars:\n    environment: ((environment.name))\n</code></pre> <p>Another interesting use case would be to use it as a <code>instance_fragment</code> with the <code>set_pipeline</code> step.</p> <p>This idea is pretty half-baked - I've been mainly focusing on the 'spatial resources' idea. Follow along in the RFC #27 and help the idea develop!</p>"},{"location":"blog/2019-07-17-core-roadmap-towards-v10/#rfc-28-notification-resources","title":"RFC #28: notification resources","text":"<p>Notification resources will allow you to monitor the flow of a resource through your pipeline and emit build status notifications (e.g. Slack alerts, GitHub commit status) without having to sprinkle <code>put</code> steps all over your pipeline.</p> <p>Have you ever wanted to reflect your CI build status on your GitHub commits? Or send a Slack notification whenever the build is fixed or broken?</p> <p>If so, you're probably aware of how ugly it can make your pipelines, both in YAML and in the UI.</p> <p>A simple pipeline quickly turns into a mess of boxes and lines:</p> <p>{{&lt; image src=\"/images/2019/07/before-notifications-1.png\" width=\"100%\" &gt;}} {{&lt; image src=\"/images/2019/07/after-notifications.png\" alt=\"a simple pipeline before and after notifications were added\" width=\"100%\" &gt;}}</p> <p>Not only is it a lot of manual work to copy-paste those <code>on_success</code> and <code>on_failure</code> hooks, when you finally configure it it really ruins the signal-to-noise ratio of the pipeline UI.</p> <p>So, the plan for notification resources is to leverage composition, a pattern set forth in the Resources v2 RFC (#24). Instead of annotating every single job, you annotate a resource, and any time that resource is used in a build a notification will be fired, by executing the notification resource's <code>put</code> step with the config fragment of the original resource (e.g. <code>ref: abcdef</code>) and the status of the build.</p> <p>This way you don't have to update all of your jobs, and notifications don't clutter up the pipeline UI. Neato!</p> <p>This idea is also a bit half-baked - follow along in RFC #28 when you have time!</p>"},{"location":"blog/2019-07-17-core-roadmap-towards-v10/#what-comes-after-all-this","title":"What comes after all this?","text":"<p>I dunno.</p> <p>I have a lot of respect for software that is eventually considered 'done.' I would really like Concourse's core design to achieve that someday.</p> <p>We'll always have things to improve, whether it's through better efficiency, better UX, support for new underlying technologies (Kubernetes, Nomad), or just making our codebase more accessible for contributors. But from a core design standpoint, I think the most important thing is stability.</p> <p>The software industry changes quickly. Hot new tools show up all the time and get replaced by newer and better tools. I don't want our users to have to keep re-doing their CI stack just to keep up.</p> <p>Concourse should insulate projects from the constant churn in the industry by providing a solid set of principles and abstractions that hold true regardless of the underlying technology.</p> <p>We will continue to listen to user feedback and improve Concourse. Our goal is for it to support good patterns and prevent anti-patterns that we can identify in workflows across the industry. Thankfully patterns don't change as frequently as tools do.</p>"},{"location":"blog/2019-07-17-core-roadmap-towards-v10/#thanks","title":"Thanks!","text":"<p>Everything I've outlined here comes from years of feedback through all of your GitHub issues, forum posts, and conversations in Discord (or Slack for you OGs). I'm very thankful for those of you that have stuck around and helped us understand your workflows, and I'm especially grateful for your patience.</p> <p>For those of you who couldn't wait and ultimately had to switch tools, I hope we accomplished one of our original goals, and I hope to see you back in the future!</p>"},{"location":"blog/2019-08-30-concourse-mid-year-update/","title":"Concourse Mid-year Update","text":"<p>Phew, it's been a while. I got lots of info to cover so let's just get right into it</p>"},{"location":"blog/2019-08-30-concourse-mid-year-update/#concourse-oss-growth","title":"Concourse OSS Growth","text":"<p>As some of you may know, the Concourse team switched over to a PR-based workflow at the beginning of the year. This change is in line with our objectives of being open and transparent with our community of contributors. Plus, its just good thing to do because that's what most OSS projects do. Since then we've noticed a noticeable uptick in PRs opened by non-Concourse core contributors across our repos:</p> <p>{{&lt; image src=\"/images/2019/08/Screen-Shot-2019-08-30-at-10.12.17-AM-2.png\" width=\"100%\" &gt;}}</p> <p>And while our peak period seemed to be concentrated at the beginning of the year, we're still seeing steady contributions through the summer months</p> <p>{{&lt; image src=\"/images/2019/08/Screen-Shot-2019-08-30-at-10.13.09-AM.png\" width=\"100%\" &gt;}}</p> <p>The Concourse project also hit another big milestone: we now have over 4000 Github stars! As of today we're sitting at 4213 stars, a 52% increase in popularity from this time last year.</p>"},{"location":"blog/2019-08-30-concourse-mid-year-update/#concourse-v10","title":"Concourse v10","text":"<p>In case you missed it, Alex wrote out a great blog post that outlines our long term vision for Concourse. It's got a breakdown of some exciting new features, from references to Spaces, the new Algorithm, Concourse Projects, etc. You can read more about it here 2019-07-17-core-roadmap-towards-v10.md</p>"},{"location":"blog/2019-08-30-concourse-mid-year-update/#concourse-project-planning","title":"Concourse Project Planning","text":"<p>{{&lt; image src=\"/images/2019/08/Screen-Shot-2019-08-30-at-10.27.27-AM.png\" width=\"100%\" &gt;}}</p> <p>There's been some big changes to how we organize and visualize each track of work now. If you take a peek in the project board https://project.concourse-ci.org you'll see now that each of our tracks are clearly labeled as swimlanes, with each prioritized Epic as cards under each swimlane. We hope you'll find this new format easier to consume</p>"},{"location":"blog/2019-08-30-concourse-mid-year-update/#increased-transparency-on-team-process","title":"Increased Transparency on Team Process","text":"<p>We recently held our first Concourse team offsite. We discussed topics such as:</p> <ul> <li>How can we tighten up our PR workflow?</li> <li>When do we release, and how often?</li> <li>Let's tackle the issue of Tech Quality</li> <li>Concourse Principles</li> </ul> <p>We've got a lot of action items and takeaways from that meetings, so look forward to updates from the team once they begin to formalize!</p>"},{"location":"blog/2019-08-30-concourse-mid-year-update/#concourse-teams-in-the-wild","title":"Concourse Teams in the Wild","text":"<p>Members from the Concourse core team will be making a few more conference appearances before the end of year.</p>"},{"location":"blog/2019-08-30-concourse-mid-year-update/#cf-summit-eu-2019","title":"CF Summit EU 2019","text":"<p>Taylor Silva and Scott Foerster will be giving a Concourse CI 102 talk at CF Summit EU 2019. I got a preview of the talk recently and its super informative for folks who are interested in learning more about the internals of the <code>web</code> node and how jobs/resources are scheduled</p>"},{"location":"blog/2019-08-30-concourse-mid-year-update/#springone-2019","title":"SpringOne 2019","text":"<p>The Concourse team will be hosting a 2 hour workshop in Austin during the workshop days before SpringOne 2019. The registration list is already full (sorry!) but if you're lucky you might get a spot if someone drops out. Or, you know, write a Concourse pipeline to watch the website and register yourself if the state changes! You can read more about the event here https://springoneplatform.io/2019/workshops/concourse</p>"},{"location":"blog/2019-10-15-re-inventing-resource-types/","title":"Re-inventing resource types","text":"<p>Before the paint completely dries on the v10 roadmap, there is one last big unknown I want to explore in case it brings more clarity to our direction: generic tasks.</p> <p>Resource types are a great way to share tools and integrations for others to use in their pipelines. Unfortunately, they're basically the only way, and because resources are a very opinionated concept, the resource type interface is not always a good fit.</p> <p>Concurrent to this problem, there's been a lot of talk about generic re-usable tasks. The idea is to make tasks just as easy to share and use as resource types. This would be a great alternative to resource types for workflows that don't really fit the resource model!</p> <p>I finally found the time to dig in to these problems, and I have two new RFCs that I'm excited to propose:</p> <ul> <li>RFC #37: Prototypes</li> <li>RFC #38: Resource Prototypes</li> </ul> <p>These proposals will have a lasting impact so I wanted to share some of my thought process here.</p>"},{"location":"blog/2019-10-15-re-inventing-resource-types/#what-makes-a-resource","title":"What makes a resource?","text":"<p>If you'll humor me for a moment, I want to pin down what makes a resource a resource.</p> <p>Resources are the continuous part of Concourse. They represent inputs changing over time, passing different versions through jobs to form a pipeline. Resources are how the continuous thing-doer knows that there are things to do: pipelines converge on the latest available versions for each job's inputs, running builds until everything stabilizes.</p> <p>A resource is a single object with a linear version sequence. This assumption allows Concourse pipelines to skip ahead to the latest version by default instead of having to process every single version.</p> <p>Resources have an external source of truth ; the same resource definition will always yield the same versions, in the same order, in any pipeline, in any Concourse installation. This makes Concourse pipelines portable and self-contained, which is critical for disaster recovery.</p> <p>Resources are immutable ; fetching the same version will always give you the same bits. This allows <code>get</code> steps to be cached so that they don't have to be downloaded all the time.</p> <p>Resources are idempotent ; outputs will always result in the same external effect when given the same configuration and bits. This allows for builds to be safely re-run even if some of its <code>put</code> steps already ran.</p> <p>A resource definition looks something like this:</p> <pre><code>resources:\n- name: booklit\n  type: git\n  source:\n    uri: https://github.com/vito/booklit\n    branch: master\n</code></pre> <p>Every resource definition has a <code>type</code> and a <code>source</code>. The type denotes the resource type - i.e. the implementation of the Concourse resource interface to use. The source represents the location of the resource, i.e. the source of versions. This configuration is interpreted by the resource type, and is a black box to Concourse.</p>"},{"location":"blog/2019-10-15-re-inventing-resource-types/#how-do-resource-types-work","title":"How do resource types work?","text":"<p>A resource type is packaged as a container image with 3 executables living under <code>/opt/resource</code>: <code>check</code>, used for finding versions, <code>in</code>, used for fetching versions, and <code>out</code>, used for writing versions. Each command reads a JSON request on <code>stdin</code> and emits a JSON response on <code>stdout</code>. These actions are run by Concourse during pipeline scheduling and build execution.</p> <p>Concourse comes with a few \"core\" resource types. Some are necessary for bootstrapping, like the <code>registry-image</code> or <code>docker-image</code> resource types. Some are included just to support common use cases, like <code>git</code> and <code>time</code>. We plan to remove most of them though; it's making the download size pretty big. (#4586)</p> <p>All other resource types must be configured in your pipeline under <code>resource_types:</code>. This makes the pipeline more self-contained, decoupling it from the resource types the Concourse installation happens to have installed.</p> <p>Pipelines define their own resource types by configuring a resource for the type's container image:</p> <pre><code>resource_types:\n- name: git\n  type: registry-image\n  source:\n    repository: concourse/git-resource\n    tag: 1\n</code></pre> <p>Technically, resource types work by using another resource type to fetch their container image. It's turtles all the way down!</p> <p>A resource type that fits the original design of resources implements the following semantics:</p> <ul> <li><code>check</code> queries the external source of truth to find new versions of the object.</li> <li><code>in</code> reads from the external source of truth and and always produces the same bits for the same version and <code>params</code>.</li> <li><code>out</code> writes to the external source of truth if necessary based on the given bits and <code>params</code>. Any version emitted by   <code>out</code> can also be found by <code>check</code>.</li> </ul> <p>The easiest example of a 'proper' resource type is <code>git</code>. The <code>check</code> action consults <code>git log --first-parent</code> to return ordered commits for a single branch. The <code>in</code> action does a <code>git clone</code> to fetch the repo and check out the given commit; this is easily cached. The <code>out</code> action does a <code>git push</code>, optionally rebasing and returning a new version in the event of a conflict.</p>"},{"location":"blog/2019-10-15-re-inventing-resource-types/#when-is-a-resource-type-not-a-resource-type","title":"When is a resource type not a resource type?","text":"<p>{{&lt; image src=\"/images/2019/10/image-3.png\" alt=\"the treachery of container images\" width=\"40%\" &gt;}}</p> <p>Resource types should always implement <code>check</code> and <code>in</code>. Being able to find and fetch versions is what makes a resource a resource. Some resource types, however, only implement <code>out</code>. These resource types exist solely to be run as a <code>put</code> step - a form of \"generic tasks\" limited by the fact that it can't produce any outputs local to the build.</p> <p>Resource types should always represent a single object. This is pretty foundational to Concourse pipeline semantics. Some resource types, however, try to represent sets of objects. The easiest example is pull request resource types, which represent each pull request as a version so that you can use Concourse to run tests for all your PRs.</p> <p>This is fraught with peril:</p> <ul> <li>If you don't set <code>version: every</code> your builds will skip pull requests because all Concourse cares about is converging   on the latest version of each object. If each version is actually a different object, this assumption breaks.</li> <li>Because <code>version: every</code> allows versions to be skipped when used   with <code>passed:</code> constraints, now you have to cram everything into one monolithic job. You can try to work around this   by splitting it up and setting <code>serial: true</code> everywhere, but now you can't run PRs in parallel.</li> <li>Pull requests can skipped if the version history shifts around in a certain way. It's fundamentally impossible to try   to represent changes to all pull requests as one version stream with a stable order, so the order jumps around all the   time. If someone leaves a comment on a PR or pushes a new commit, it can get bumped to \"latest\" - and if a build has   already run for it, the other (\"older\") PRs won't run. Even with <code>version: every</code>, Concourse won't go back in time   to run old versions.</li> <li>Navigation is awkward. The pipeline UI is pretty meaningless since all the jobs just reflect the status of the most   recent PR that ran, and going through the build history of a job is pretty confusing because each build may be a   different pull request.</li> <li>Re-running builds for a pull request is annoying. You have to go to the PR resource, find the version for your PR, pin   it, trigger all the builds, wait for them all to start, and then you can unpin the resource, lest you forget and   your pipeline never runs another PR again. This will get slightly better in v6.0 as we've finally implemented build   re-triggering (#413), but that won't help with triggering builds   for an \"older\" PR that hasn't run yet.</li> </ul> <p>This pain is the main source of motivation for the v10 roadmap, which introduces all the required components to dynamically set a pipeline for each pull request instead - each with a resource representing only one pull request, as Concourse intended.</p> <p>In short, we have an interface being used for things beyond its original design. This results in surprising and unwanted behavior because Concourse functionality that is sensible for resources doesn't make sense for these other workflows. This hurts everyone: users have to deal with surprises and terrible UX, resource type authors have to deal with these limitations and workarounds, and the concept of 'resources' kind of erodes as these patterns spread.</p> <p>At this point it's pretty clear that there's a need to be able to share workflows and bespoke tools within the community, but it's also clear that resources aren't the best pipeline-level representation for all of them. So if resources aren't a good fit, what about tasks?</p>"},{"location":"blog/2019-10-15-re-inventing-resource-types/#usability-of-generic-tasks","title":"Usability of generic tasks","text":"<p>Tasks can almost be packaged up and re-used as easily as resource types. I've been experimenting with this idea by writing a generic task for building OCI images. It works by configuring <code>vito/oci-build-task</code> as the task's image and configuring the rest of the task according to the README in the repo.</p> <p>So far, this UX doesn't sound that far off from using a resource type; you configure a resource type's image in <code>resource_types:</code> and figure out how to configure the rest using its README, too. On paper, the only difference is that a task's image is configured in <code>resources:</code> or with <code>image_resource:</code> instead.</p> <p>Let's compare what it looks like to take a <code>git</code> repo, build an OCI image from its <code>Dockerfile</code>, and push the image to a registry, using a generic task vs. using a resource type.</p> <p>We'll begin with two resources: one for my image source code, and one for the image repository on the registry:</p> <pre><code>resources:\n- name: my-image-src\n  type: git\n  source:\n    uri: # ...\n\n- name: my-image\n  type: registry-image\n  source:\n    repository: # ...\n    tag: latest\n</code></pre> <p>Next we'll add a job that does the build-and-push.</p> <p>Let's see how it looks to use a generic task:</p> <pre><code>jobs:\n- name: build-and-push\n  plan:\n  # fetch repository source (containing Dockerfile)\n  - get: my-image-src\n\n  # build using `oci-build` task\n  - task: build\n    image: oci-build-task\n    config:\n      platform: linux\n\n      image_resource:\n        type: registry-image\n        source:\n          repository: vito/oci-build-task\n\n      params:\n        CONTEXT: my-image-src\n\n      inputs:\n      - name: my-image-src\n\n      outputs:\n      - name: image\n\n      run:\n        path: build\n\n  # push using `registry-image` resource\n  - put: my-image\n    params: {image: image/image.tar}\n</code></pre> <p>Now let's see how it feels to use a resource type instead. If we switch the <code>my-repo</code> resource from <code>registry-image</code> to <code>docker-image</code>, we can leverage its (quite contentious) build-and-push behavior:</p> <pre><code>jobs:\n- name: build-and-push\n  plan:\n  # fetch repository source (containing Dockerfile)\n  - get: my-image-src\n\n  # build + push using `docker-image` resource\n  - put: my-image\n    params:\n      build: my-image-src\n</code></pre> <p>Resources clearly take a lot less effort to use in a pipeline. No wonder they're being used for everything!</p> <p>Providing a full task config is a lot of work. It allows for a lot of flexibility, but it feels verbose. Verbosity means wasting time on typos and forgotten boilerplate.</p> <p>Verbosity aside, tasks are also strictly worse at parameterization. Task <code>params</code> are really environment variables, so every value has to be a string. This is OK for simple values, but anything more complicated will need to be marshalled and unmarshalled. This is really crummy compared to resource types, which support complex YAML/JSON config structures like lists and objects.</p> <p>It seems like we need something in between tasks and resource types. We need something as versatile as tasks and as easy to use as resource types.</p>"},{"location":"blog/2019-10-15-re-inventing-resource-types/#bridging-the-gap","title":"Bridging the gap","text":"<p>{{&lt; image src=\"/images/2019/10/image-1.png\" width=\"100%\" &gt;}}</p> <p>Let's hone in on the reason why resource types don't work for every use case: they have a particular set of actions which have particular semantics because they're built for a particular Concourse use case: resources.</p> <p>The v10 roadmap introduced RFC #24, a \"generalized resource\" interface which supports <code>check</code>, <code>get</code>, <code>put</code>, and <code>delete</code> actions while avoiding resource terminology like \"version\" and \"source\" so that it can be used for other workflows. It's kind of a strange middle ground: it's limited to resource-y actions while avoiding resource-y semantics.</p> <p>Aside from the resource-y actions, RFC #24 was pretty darn close to what I wanted out of generic tasks, so I decided to just fork it as RFC #37 and make one key change: instead of supporting <code>check</code>, <code>get</code>, <code>put</code>, and <code>delete</code>, support arbitrary actions instead.</p> <p>With <code>check</code> and <code>get</code> removed, the interface was definitely not a resource type interface anymore. And with its support of multiple actions, it definitely wasn't a task interface either, so I needed a new name for it.</p> <p>After much deliberation, I decided to call these things prototypes. This name is inspired by prototype-based object-oriented languages like JavaScript, Self, and Io. Conveniently enough, it still has \"type\" in the name, so all those <code>type:</code> fields on resources still make sense!</p> <p>{{&lt; image src=\"/images/2019/10/image-2.png\" width=\"100%\" &gt;}}</p> <p>The next change in my fork of RFC #24 was to adjust the terminology. Now that the interface was so open-ended, I wanted to build a solid mental model so that prototype authors would have an idea of how prototypes are meant to be designed. I did this by stealing more terminology from prototype-based OOP.</p> <p>Here's where I landed: prototypes handle messages (previously 'actions') being sent to objects (previously 'config'). In response to a message, a prototype may emit more objects (previously 'config fragments').</p> <p>Thinking about Concourse as \"object-oriented CI/CD\" feels pretty compelling. This mental model can be easily used to describe how resource types work:</p> <ul> <li>The <code>check</code> message is sent to the <code>source</code> object to list <code>version</code> objects.</li> <li>The <code>get</code> message is sent to a <code>version</code> object (a clone   of the <code>source</code> object) to fetch its bits.</li> <li>The <code>put</code> message is sent to the <code>source</code> object to create <code>version</code> objects.</li> </ul> <p>Prototype implementations have full control over their domain of objects and the messages supported by those objects. For example, a <code>git</code> prototype could support multiple types of objects:</p> <ul> <li>a repo object, <code>{\"uri\":\"...\"}</code>, could support <code>branches</code> to find branch objects and <code>check</code> to find commit objects   in the \"default\" branch</li> <li>a branch object, <code>{\"uri\":\"...\",\"branch\":\"...\"}</code>, could support <code>check</code> to find commit objects on the branch or   <code>delete</code> to delete the branch</li> <li>a commit object, <code>{\"uri\":\"...\",\"branch\":\"...\",\"sha\":\"...\"}</code>, could support <code>get</code> to clone the repo and checkout   the commit</li> </ul> <p>Over time, we can start to identify patterns and implement pipeline semantics for certain interfaces, just like we have with <code>check</code>, <code>get</code>, and <code>put</code>. For example, when a build status changes, Concourse could run the <code>notify</code> message handler for any objects in the build which support it. A <code>git</code> prototype could implement this to automatically update commit status on GitHub. This would eliminate a whole class of <code>put</code>-only resource types and de-clutter everyone's pipelines.</p>"},{"location":"blog/2019-10-15-re-inventing-resource-types/#prototypes-as-generic-tasks","title":"Prototypes as 'generic tasks'","text":"<p>Whereas a task is built around a single action, a prototype is built around objects which can handle messages. As such, the <code>oci-build</code> task would instead be an <code>oci-image</code> prototype supporting a <code>build</code> message.</p> <p>Here's how it could look to use a prototype for building an OCI image (note the use of <code>prototypes:</code> instead of <code>resource_types:</code>):</p> <pre><code>prototypes:\n- name: oci-image\n  type: registry-image\n  source:\n    repository: vito/oci-image-prototype\n\njobs:\n- name: build-and-push\n  plan:\n  # fetch repository source (containing Dockerfile)\n  - get: my-image-src\n\n  # build using `oci-image` prototype\n  - run: build\n    type: oci-image\n    inputs: [my-image-src]\n    params: {context: my-image-src}\n    outputs: [image]\n\n  # push using `registry-image` resource\n  - put: my-image\n    params: {image: image/image.tar}\n</code></pre> <p>Here we use a new <code>run</code> step to run the <code>oci-image</code> prototype and send the <code>build</code> message to an object, given as <code>params</code>. With the <code>run</code> step, <code>inputs</code> and <code>outputs</code> must be explicitly provided, though <code>inputs</code> can be automated in the future with #2692.</p> <p>All in all, this feels a whole lot better than the generic tasks of old. It's way less verbose, and feels a lot like using a <code>put</code> step, with no abstractions being abused and no surprising behavior. Mission accomplished?</p>"},{"location":"blog/2019-10-15-re-inventing-resource-types/#how-does-this-impact-the-roadmap","title":"How does this impact the roadmap?","text":"<p>Through all of this, the only thing I've really added to the roadmap is the <code>run</code> step. Everything else is a lateral move; instead of using 'generalized resources' for spatial resources, notifications, and triggers, we would use ' prototypes' instead.</p> <p>I think the larger impact will be on future roadmaps. With a more flexible model at our disposal we can shorten the path from identifying a common workflow and implementing richer pipeline semantics for it. Concourse becomes a \"language of CI/CD,\" where the objects are provided at runtime and can be shared with the community.</p>"},{"location":"blog/2019-10-15-re-inventing-resource-types/#how-to-get-involved","title":"How to get involved","text":"<p>I'm still getting a grip on this idea myself but I'm excited to see the places we can go with it. If you'd like to get involved, I could use some feedback on the RFCs!</p> <ul> <li>RFC #37: Prototypes is based   on RFC #24, allowing implementations to support arbitrary messages and   switching everything over to prototype-based terminology. It also introduces the above <code>run</code> step for executing   arbitrary message handlers.</li> <li>RFC #38: Resource Prototypes shows that prototypes which implement   <code>check</code> and <code>get</code> messages can be used a resources in a pipeline, while maintaining backwards-compatibility for a   smooth migration to prototype-based resources over time.</li> </ul> <p>If everything goes well I plan to close RFC #24 and the other 'generalized resources' based RFCs in favor of these new prototype-based RFCs. (I still need to write up new prototype-based RFCs for the rest though: spatial resources, notification resources, trigger-only resources.)</p> <p>Special thanks to everyone that has helped me talk through ideas in Discord, on GitHub, and in person!</p>"},{"location":"blog/2020-01-24-a-new-hangar-for-resource-types/","title":"A New Hangar For Resource Types","text":"<p>{{&lt; image src=\"/images/downloaded_images/Strategic-Plan_Page_13_Image_0001-750.jpg\" alt=\"The inside of an airplane hangar\" width=\"100%\" &gt;}}</p> <p>Photo: National Parks Service</p> <p>The idea to build a dedicated resource types catalog has been long-discussed. We\u2019d like to announce that the idea has come to fruition: the new Concourse resource types catalog is wheels up!</p> <p>The catalog lists Concourse resource types that have recently been submitted to the resource types GitHub repo. Originally, resource types were listed on a GitHub wiki page. While the wiki page listed resource types, it didn\u2019t provide much information about each resource. The resource types catalog will provide more information about each resource and enhanced search, both of which will make it easier to compare and find resource types.</p> <p>The addition of the resource types catalog means that the original resource types wiki page will be deprecated. If you have a resource listed on the wiki page, please migrate it over to the GitHub repo.</p>"},{"location":"blog/2020-01-24-a-new-hangar-for-resource-types/#contribution","title":"Contribution","text":"<p>As part of the effort to move resource types to a new home, we\u2019ve also spent some time thinking through the resource type submission process. This new process should make it easier for members of the community to contribute new resource types.</p> <p>The updated process consists of forking the existing resource types repository, adding your YAML file and submitting a pull request. After a quick review by community members, the resource type will be added to the repository and will be available on resource-types.concourse-ci.org. The process is described in more detail here. We\u2019re also working on automating some of this process using Concourse!</p> <p>If you\u2019ve gotten this far, have taken a quick look at the catalog, and are wondering why there is no \u201cresource type for x\u201d, it\u2019s a great opportunity to add your own! There are already some helpful walkthroughs from other community members on writing resource types (Implementing a Resource Type, Developing a Custom Concourse Resource, How to Make a Concourse Resource Type) which are a great place to start.</p>"},{"location":"blog/2020-01-24-a-new-hangar-for-resource-types/#whats-next","title":"What\u2019s Next?","text":"<p>We\u2019ve come a long way with Concourse resource types and are excited about the new catalog. We now have our sights set on adding more functionality on the page (check out the backlog). This includes displaying more information about each resource type on the cards (including GitHub stars and resource type actions), as well as improved search and sorting.</p> <p>We also have an eye on the V10 roadmap and can see prototypes on the horizon.</p> <p>In the spirit of the open-source project that it is, we\u2019d also love feedback to inform our roadmap. So if you have feedback, we\u2019d love to hear it. The best way to reach us is to either drop us a line in #resource-types on Discord or submit an issue against the GitHub repository.</p>"},{"location":"blog/2020-03-17-concourse-2020-community-survey/","title":"Concourse 2020 Community Survey","text":"<p>{{&lt; image src=\"/images/2020/03/whyconcourse2.png\" width=\"100%\" &gt;}}</p>"},{"location":"blog/2020-03-17-concourse-2020-community-survey/#help-shape-the-future-of-concourse","title":"Help shape the future of Concourse","text":"<p>Since Concourse CI was created, thousands of users worldwide have helped the project by opening issues, committing code, and providing feedback to the team that develops the product. This community involvement is priceless - thank you, Concourse community! \ud83d\udc4f</p> <p>One of the ways the Concourse team collects feedback is through our annual Community Survey. This lets us gather crucial information about how users deploy Concourse, how different use cases scale, and various configuration patterns. We can also directly collect requests for new features and bug fixes. Past surveys have led us toward crucial features like the Dashboard UI, RBAC, new container placement strategies, and dozens of performance fixes.</p> <p>Each year\u2019s results are published in a blog post to help share out our most interesting findings.</p>"},{"location":"blog/2020-03-17-concourse-2020-community-survey/#the-state-of-concourse-in-2020","title":"The state of Concourse in 2020","text":"<p>Today we are launching the Concourse 2020 Community Survey. This survey is open to everyone who uses Concourse, whether it\u2019s your daily CI/CD tool, one of many automation tools your company uses, something you\u2019re experimenting with on the side, or something you\u2019re hoping to learn more about in 2020. The answers you provide will help ensure the product, community, and ecosystem fit the needs of the people closest to it.</p> <p>Please help us by participating in this 5-minute survey:</p> <p>Edit: Survey closed! Thank you to everyone who participated. Check out the results in the 2020 Community Report.</p>"},{"location":"blog/2020-03-17-concourse-2020-community-survey/#spread-the-word","title":"Spread the word!","text":"<p>We need as many users as possible to participate in this survey to help us better understand our global user base. We'd be grateful if you would spread the word by sharing this post on your social network feeds, around the office, at meet-ups, and in other communities.</p> <p>Thank you!</p>"},{"location":"blog/2020-03-25-developing-concourse-from-home-/","title":"Developing Concourse (from home \ud83c\udfe1)","text":"<p>In March 2020, countless companies made a shift to have their employees work from home. For remote staff getting work done can be challenging enough, but staying connected to your team and company culture can be even more challenging. On the Concourse team, we\u2019re working hard to keep our product development running smoothly with some additions to our tech stack and day to day workflow.</p>"},{"location":"blog/2020-03-25-developing-concourse-from-home-/#concourse-team-composition","title":"Concourse team composition","text":"<p>At VMware (formerly Pivotal Software), there are fourteen engineers and five product folks working on theConcourse CI project full time. We all care deeply about the software we're building, and put a great deal of effort and consideration into how we build software in order to be as effective as possible.</p> <p>Most of our team lives in Toronto, but in order to maintain velocity as the team expands to include engineering and product talent from other countries, and as we travel to meet with customers and talk about Concourse at conferences and meetups, we've refined our process to make ourselves resilient to occasions when a few employees might need to work from home or abroad.</p> <p>Then 2019's novel coronavirus arrived, and the ensuing pandemic in late February and early March 2020 forced us provided the right opportunity to test a fully-remote team experience.</p> <p>We thought we'd put together a quick post here to share how we're making it work. \ud83d\ude04</p>"},{"location":"blog/2020-03-25-developing-concourse-from-home-/#pre-covid19","title":"Pre-COVID19","text":"<p>The majority of the Concourse team is located in the greater Toronto area, with satellite members in a few cities in the United States. The Pivotal Software office in downtown Toronto is our home throughout the week. The team is set up with rows of computer workstations on the East side of the office, and gathers in various meeting rooms around the office for standups, prioritization meetings, discussions, and presentations.</p> <p>If you're a Pivotal/VMware customer, a Concourse contributor, or a user interview collaborator who's chatted with the team in the past, then you're probably familiar with a few of the meeting rooms from which we conduct Zoom meetings.</p> <p>The Toronto office is a great work environment. We're lucky to have the opportunity to get up to play a game of ping pong between engineering stories or meetings, and it's great to be in the same room to collaborate around a whiteboard or break down a problem with post-it notes.</p> <p>But what happens when your government enforces non-essential businesses to close their offices and asks employees to work from home instead?</p>"},{"location":"blog/2020-03-25-developing-concourse-from-home-/#post-covid19","title":"Post-COVID19","text":"<p>When the news and scale of the outbreak arrived in early March, we made the shift to collectively working from home as quickly as possible. Since the week of March 8th, all of us have been dutifully self-isolating, working out of our respective homes each day.</p> <p>Most of the solutions we've come up with are focused on maintaining our existing process (especially our use of IPMs, pairing, retrospectives, and a high degree of collaboration on every possible front) while making life remote friendly at the same time.</p> <p>With those goals in mind, our team has pulled from different experiences and techniques learned from past projects as well as new ideas that we're still iterating on daily. This effort has made for a novel mix of video, audio, and text applications that help us work in a comfortable, fun, efficient manner.</p>"},{"location":"blog/2020-03-25-developing-concourse-from-home-/#zoom","title":"Zoom","text":"<p>First and foremost, we have a perpetual group Zoom meeting set up that everybody on the team hangs out in throughout the workday.</p> <p>{{&lt; image src=\"/images/2020/03/Screen-Shot-2020-03-20-at-12.08.28-PM.png\" alt=\"A typical workday in the Concourse hangar.\" width=\"100%\" &gt;}}</p> <p>Having one single room might be unconventional, but negates the need to constantly jump in and out of different Zoom meetings, and all of the confusion that can create. It's tied to a easy-to-remember URL that makes it painless to join each day - no more memorizing meeting IDs!</p> <p>Additionally, having everyone in the same place makes it feel more like we're all in the office together. Seeing each other's faces throughout the day makes working at home feel a lot more friendly and less isolated.</p>"},{"location":"blog/2020-03-25-developing-concourse-from-home-/#discord","title":"Discord","text":"<p>The other major difference to Zoom meetings we held in the past is that now we remain fully muted. Zoom takes care of video communication, and we rely on Discord for audio and individual screen sharing.</p> <p>We were already using Discord for our open source community's text-based chat, but it also excels at fast, simple, and effective voice communications. The Concourse team uses a series of private voice channels (named after famous aircraft, of course \u2708\ufe0f) that we can join and depart with a single click.</p> <p>{{&lt; image src=\"/images/2020/03/Screen-Shot-2020-03-23-at-1.56.04-PM.png\" alt=\"Pairs of engineers working in audio channels on Discord\" width=\"20%\" &gt;}}</p> <p>This makes it easy to navigate for pair programming, impromptu meetings, or general chat and attention-getting. There\u2019s even a #water-cooler channel that acts as the defacto hangout spot! With this system you can see who is paired up in the respective rooms at a glance, adding a level of transparency and organization that isn't possible when everyone is pairing through separate Zoom meetings or other telecommunication products.</p>"},{"location":"blog/2020-03-25-developing-concourse-from-home-/#slack","title":"Slack","text":"<p>The Concourse team has always used Slack to communicate internally, and Slack still plays a big role in organizing our work. Since moving to work from home and using Zoom and Discord as described above, however, we're using it less - the number of Slack messages simply doesn't need to be as high. If nothing else, it's great to have Slack as a backup option for screen sharing, especially since we can use it to pull in non-team members from the company as well.</p> <p>It still plays a large role in communicating with other product, engineering, and customer-facing teams in the company, and can't be beat for asynchronous messaging. However, when we need to chat within our team throughout the workday, we can just grab someone's attention and start talking immediately instead.</p>"},{"location":"blog/2020-03-25-developing-concourse-from-home-/#remote-pairing","title":"Remote Pairing","text":"<p>Remote pairing is one area of our work process that is still up in the air. The Concourse team practices pair programming everyday, and trying to do that remotely can be challenging at times. We\u2019ve tried the following methods of pair programming, with each having different strengths and weaknesses for different situations.</p>"},{"location":"blog/2020-03-25-developing-concourse-from-home-/#toronto-workstations","title":"Toronto workstations","text":"<p>The pairing workstations in the Toronto office are set up so we can use OSX's screen sharing tool to securely connect to them over our company\u2019s VPN. This allows us to share everything (browser, IDE, terminal, and more) as we normally would if we were sitting side by side in the office to pair program.</p>"},{"location":"blog/2020-03-25-developing-concourse-from-home-/#discord-go-live","title":"Discord Go Live","text":"<p>In a pinch we\u2019ve been able to share screens using Discord\u2019s Go Live feature. In mid-March Discord raised the viewing limit on Go Live and Go Live - Screen Share streams from 10 people at a time to 50 people, making this work well for mobbing as a group around one person's screen as well.</p> <p>One of the drawbacks is that it only streams in 720p resolution, making it hard to read text on the screen unless the text is enlarged. But there are a lot of times when a modest screen resolution is all you need, and we can switch to Slack's screen sharing in the rare case that we need higher fidelity.</p>"},{"location":"blog/2020-03-25-developing-concourse-from-home-/#ssh-tmux","title":"SSH + tmux","text":"<p>Sometimes you just need a command line. In these situations, the team can also ssh onto any of the Toronto workstations, or any of the team's various VMs running linux on the cloud to share a tmux session.</p>"},{"location":"blog/2020-03-25-developing-concourse-from-home-/#attitude","title":"Attitude","text":"<p>This article has been heavy on technological solutions and workflow, but another thing worth mentioning is how positive and encouraging the team's attitude has been during the pandemic.</p> <p>{{&lt; image src=\"/images/2020/03/Screen-Shot-2020-03-19-at-10.41.42-AM-1.png\" alt=\"Concourse engineers, best engineers.\" width=\"100%\" &gt;}}</p> <p>Even isolated to our respective homes, we've seen everyone step up to keep each other happy and healthy, and to keep work moving at a sustainable pace. I won't go into detail about all the memes, inside jokes, guitar solos, Zoom virtual backgrounds, and pet cameos that have been shared among the team in the past couple weeks - you can use your imagination. \ud83d\ude02</p> <p>Don't underestimate the importance of taking breaks and having fun with your work!</p>"},{"location":"blog/2020-03-25-developing-concourse-from-home-/#what-next","title":"What next?","text":"<p>Nobody knows for certain how long we'll be working in full isolation, but since our goal is to flatten the curve of the outbreak, it's in our best interests to be prepared for a long wait.</p> <p>Our team is built around iterating on process and practices, and we plan to continue working on how we can collaborate to make sure we continue to deliver as much product value as possible.</p> <p>Join us on Discord to learn about new work in progress, report on bugs, collaborate on the codebase, or just keep us company! \ud83d\ude01</p>"},{"location":"blog/2020-04-16-community-update-enter-discussions-/","title":"Community update: enter Discussions! \ud83c\udf89","text":"<p>Hasta la vista, stale bot.</p> <p>{{&lt; youtube src=\"https://www.youtube.com/embed/0Kug8mJ8WiM?start=110&amp;feature=oembed\" &gt;}}</p>"},{"location":"blog/2020-04-16-community-update-enter-discussions-/#tldr","title":"tl;dr:","text":"<ul> <li>We've been granted access to GitHub's beta Discussions feature! \ud83c\udf89</li> <li>Discussions on the <code>concourse</code> repo will be used for questions   and technical support.</li> <li>Discussions on the <code>rfcs</code> repo will be for incubating ideas for new   workflows , which eventually turn into Pull Requests (also on the <code>rfcs</code> repo).</li> <li>From here on, Issues on the <code>concourse</code> repo are exclusively for project backlog and bug reports - i.e.   planned or emergent work.</li> <li>Creating an Issue directs you to these options, so there's   no need to change your muscle memory.</li> <li> <code>CONTRIBUTING.md</code> now covers this workflow   in addition to the more technical content.</li> <li>With these changes in place, the stale bot we all know and hate has been terminated.</li> <li>All Pull Requests will be assigned to someone as part of our daily process, and we will begin dedicating half of each   day to PR review.</li> <li>I am going to shift my focus from planning/prioritizing to shepherding RFCs and writing code. Expect more blog posts   in the future!</li> </ul>"},{"location":"blog/2020-04-16-community-update-enter-discussions-/#an-update-on-triage","title":"An update on triage","text":"<p>With Concourse, there is always a lot of work to do. I personally would love to see some of the larger issues worked on today, but we (the Concourse team) have to choose our battles. A good chunk of our time is spent on upkeep, architectural improvements, and trying to identify the underlying needs across many feature requests so that we can make a lower volume of high-impact changes.</p> <p>The long and short of it is that the amount of work to do \u2013 both in code and in the community \u2013 greatly exceeds the number of people available to do it. Concourse is a product that has the entire software industry as its customer \u2013 including video game devs, mobile app devs, DevOps, and people who just want CI for personal side-projects. It's a lot to stay on top of, but it's something to embrace: it forces us to think in the abstract. It just takes time.</p> <p>The main goal of these changes is to promote healthier discourse by setting expectations about the status of an engagement more clearly. Issues are concrete; they will be prioritized and finished at some point, by the core team or \u2013 in a perfect world \u2013 by a volunteer from the community. Discussions on the other hand are at an earlier stage in the process.</p> <p>Discussions on the <code>concourse</code> repo will be used for for questions and support. These can be more open-ended than bug reports \u2013 there may indeed be a bug, but there might also just be an answer or a better approach. The outcome of these discussions may be a bug report, an improvement to the docs, an answer to the question, or perhaps a new Discussion on the <code>rfcs</code> repo.</p> <p>Discussions on the <code>rfcs</code> repo will be used for incubating new ideas. By eliminating the \"solution-first\" framing of feature request issues, we can begin to focus on the problems instead. The hope is that we can all more easily identify underlying patterns and try to form broader solutions \u2013 whether they're ones we need to plan, whether they're already on the roadmap, or whether there's simply an existing solution that needs to be easier to discover.</p> <p>With these changes, we no longer have any need for the 'stale bot' as Discussions can just keep trucking along at their own pace. The bot has been terminated. Unfortunately, I removed its configuration before uninstalling it, causing it to assume the default settings and unleash its annoying comments across a slew of issues and pull requests, going out in one last blaze of glory. Sorry about that.</p>"},{"location":"blog/2020-04-16-community-update-enter-discussions-/#improving-rfc-engagement","title":"Improving RFC engagement","text":"<p>Some of you have submitted RFCs and haven't received much feedback yet. I'm really sorry about that.</p> <p>With v6.0 out and with the dust settling on the \"v10\" roadmap, I am going to shift my role towards shepherding RFCs and getting back to writing code rather than endlessly planning and prioritizing. It's been a long time! This will also eliminate the conflict-of-interest where I author RFCs and then prioritize them while neglecting others. Definitely not a trend that I want to continue.</p> <p>Expect more RFC update blog posts soon!</p>"},{"location":"blog/2020-04-16-community-update-enter-discussions-/#improving-pull-request-engagement","title":"Improving Pull Request engagement","text":"<p>Another area we're always trying to improve on is Pull Request engagement. We've been tried a lot of things, but in the end it's been hard to integrate into our day-to-day pairing process and escape the single-point-of-failure (cough me).</p> <p>We're going to start assigning each and every PR to someone on the team and dedicate half of each day to PR review. Our goal is to dramatically shorten the feedback cycle time and not leave anyone hanging.</p>"},{"location":"blog/2020-04-16-community-update-enter-discussions-/#what-about-discussconcourse-ciorg","title":"What about discuss.concourse-ci.org?","text":"<p>These changes make our forums a little (ok a lot) redundant. Once the Discussions feature feels solid I plan to shut the forums down down and centralize our community in GitHub (in addition to Discord for real-time chat).</p>"},{"location":"blog/2020-04-16-community-update-enter-discussions-/#whats-happening-with-vmware","title":"What's happening with VMware?","text":"<p>Some of you may be wondering what the future holds for Concourse through VMware's acquisition of Pivotal, the company that has supported Concourse's development since 2015.</p> <p>VMware is heavily invested in Concourse \u2013 in fact some of our recent significant contributions originated from VMware pre-acquisition. Concourse is already being used internally, and there is work underway planning Concourse's integration into VMware's product ecosystem. We ain't going anywhere!</p> <p>Thanks and stay safe everyone!</p>"},{"location":"blog/2020-05-06-rfc-round-up-may-6th-2020/","title":"RFC round-up: May 6th, 2020","text":"<p>Howdy, and welcome to our first RFC round-up! \ud83e\udd20</p> <p>{{&lt; image src=\"/images/2020/05/image.png\" width=\"40%\" &gt;}}</p> <p>For those unaware, Concourse RFCs are a process for proposing and collaborating on improvements to core Concourse functionality, including pipeline behavior, new step types, new operator capabilities, etc.</p> <p>In short, RFCs are where all the cool new stuff is planned. \ud83d\ude0e</p> <p>My goal is to provide an update at least every few weeks on the status of RFCs and shepherd them through the process via blog posts like this one. Each post will be limited to a handful of RFCs in order to focus our energy and not overwhelm readers.</p>"},{"location":"blog/2020-05-06-rfc-round-up-may-6th-2020/#rfcs-ready-to-merge","title":"RFCs ready to merge","text":"<p>The following RFCs have been given the <code>resolution/merge</code> label:</p> <ul> <li>RFC #33: archiving pipelines proposes that pipelines can be \"archived\" -   effectively a soft-delete, or perhaps a long-pause. This RFC is ready to go, and in fact we've already started to   implement it. It will be an experimental opt-in feature until this RFC is merged.</li> <li>RFC #34: pipeline instances proposes a mechanism for grouping related   pipelines together under a single identifier, further breaking down each instance by a set of associated vars.</li> </ul> <p>Both of these RFCs are key components to our plan for Git branch/PR pipeline automation, as described in the v10 blog post.</p> <p>Per the resolution process, if there are no objections or significant changes in the 2 weeks after this post is published, they will be merged! \ud83d\ude80</p>"},{"location":"blog/2020-05-06-rfc-round-up-may-6th-2020/#rfcs-in-need-of-specific-feedback","title":"RFCs in need of specific feedback","text":"<p>These two RFCs are nearing completion, but have some outstanding questions:</p> <ul> <li>RFC #39: var sources is the RFC behind the experimental   <code>var_sources:</code> feature introduced in v5.8.0. The main question is   around whether and how it may be used to replace the cluster-wide credential manager configuration.</li> <li>RFC #31: <code>set_pipeline</code> step is mostly implemented already,   also shipped experimentally in   v5.8.0. The remaining question is around whether to support <code>set_pipeline: self</code> - this is a point of contention as   there may be a better pattern for that sort of thing in the   future (hint).</li> </ul> <p>Lend us your opinions!</p>"},{"location":"blog/2020-05-06-rfc-round-up-may-6th-2020/#rfcs-in-need-of-attention","title":"RFCs in need of attention","text":"<p>These ones just need more eyes on'em:</p> <ul> <li>RFC #43: task queue proposes a \"Resource Pool\" mechanism with the end   goal of fixing the age-old problem of Concourse overloading workers. If you've run into this before and you'd like to   see it fixed, this is your chance to get involved!</li> <li>RFC #41: OPA integration proposes support for policy enforcement   through Open Policy Agent, which would allow access control to be delegated to an   external OPA endpoint. Neat!</li> </ul>"},{"location":"blog/2020-05-06-rfc-round-up-may-6th-2020/#wrapping-up","title":"Wrapping up...","text":"<p>Thanks to everyone who has gotten involved already, and special thanks to the RFC authors for your patience!</p> <p>Sorry if you had an RFC that didn't make the cut. \ud83d\ude15 We have a backlog of 23 RFCs at the moment, and I'll be going through all of them through the next few posts.</p> <p>Happy trails! \ud83d\udc0e</p>"},{"location":"blog/2020-05-14-concourse-2020-community-report/","title":"Concourse 2020 Community Report","text":"<p>A little over a month ago, the Concourse team sent a survey out to the community. The purpose of this survey was to gain insight into our users as well as measure our year-over-year growth. In the process of learning about how you all deploy and manage Concourse, we also received tons of great feedback about what's working well and what needs work in order to make Concourse even better. We\u2019re excited to share our findings!</p> <p>A huge thank you to everyone who responded. At the time of this writing, we\u2019ve received over 100 responses and that number is still climbing. Your contributions are valuable, and learning about how different segments of our user base works with our product is going to help us make Concourse even better in 2020!</p>"},{"location":"blog/2020-05-14-concourse-2020-community-report/#feature-requests-areas-to-improve","title":"Feature requests, areas to improve","text":""},{"location":"blog/2020-05-14-concourse-2020-community-report/#configuration","title":"Configuration \u2699\ufe0f","text":"<p>This is a big one. The community wants more control for administrators and operators, more options for integrations, and more power over resource types configuration. We also learned a lot about the specific ways Concourse is making life more difficult than it needs to be in terms of configuring tasks, pipelines, teams, and the product itself.</p> <p>Code and configuration duplication is a serious issue, and our users want more powerful templating tools to help them split pipeline configuration into more manageable chunks that will be easier to reason about and maintain.</p> <p>In addition, there's a lot of support for concepts covered by our Instanced Pipelines, Spatial Resources, and other major architectural ideas that we have prioritized for 2020.</p> <p>We're also paying particular attention to the number of responses that were focused on git integration and GitOps workflows. If you have a way of using Concourse that you feel isn\u2019t well represented by the current featureset or CLI/UI, please @mention us on Twitter or drop by Discord and tell us about it.</p>"},{"location":"blog/2020-05-14-concourse-2020-community-report/#web-ui","title":"Web UI \ud83d\udda5","text":"<p>Concourse\u2019s web UI is a hot topic! While most of the web UI feedback is positive, there are lots of suggestions on how to improve it or what to add next. Feedback from the survey about the web UI could make for its own blog post, so in the interest of being brief, I\u2019m just going to touch lightly on the strongest signals/insights that were generated.</p> <p>A number of respondents called to attention the ease of use and clarity of information in the current UI. While we\u2019ve been continuously iterating to add text labels instead of just icons where possible, and to add clarifying tooltips elsewhere, there\u2019s clearly a need for more. In addition to several smaller tweaks, we have work underway around adding the minimum viable Favorite Pipelines functionality that will be built upon to extend the Archiving Pipelines functionality introduced in v6.1.0 to the front end. Hopefully these fixes will make a big impact, decluttering Concourse dashboards and making it a lot faster to find what you want at the same time.</p> <p>Another area where we can clearly improve is by adding more detail to the dashboard. Users are requesting more options for adding notes, tracking an audit trail of actions in the UI, clearer and more detailed error messages, and more statistical information like build duration and lead times. We\u2019ll be looking at the possibilities in this space over the coming months. If you have ideas, start a Discussion on Github.</p>"},{"location":"blog/2020-05-14-concourse-2020-community-report/#runtime-improvements","title":"Runtime Improvements \ud83d\udcc8","text":"<p>In addition to more stability and performance, the community puts a high level of importance and value on improving the efficient use of check containers, global locks on resource checking, and the ability to clear cached resource versions of a worker on demand with fly.</p>"},{"location":"blog/2020-05-14-concourse-2020-community-report/#docker-enhancements-and-performance","title":"Docker Enhancements and Performance \ud83d\udca8","text":"<p>We hear you. \ud83d\ude00</p> <p>Comments from the community emphasized optimizing docker-image resources, facilitating docker in worker containers, and better reporting on docker image status. There are a number of different voices in this conversation all with very different strategies for how they use Concourse, and we're sorting through feedback to help us prioritize low hanging fruit and high value enhancements that the team can prioritize.</p> <p>Additionally, we're actively monitoring issues and continuously collecting data on Docker performance so that we can make more improvements - we understand that every last bit of performance we can squeeze out of Docker interactions results in a huge benefit to many of our users.</p>"},{"location":"blog/2020-05-14-concourse-2020-community-report/#stability-kubernetes-documentation","title":"Stability, Kubernetes, Documentation \u2696\ufe0f \ud83d\udea2 \ud83d\udcda","text":"<p>These issues have remained top of mind in the community for the past few years, and this year's survey is no exception. From a stability perspective, the team has made great strides with the release of the new algorithm in version 6.0.0. The team has also taken further steps into being more k8s native by beginning an ongoing track of work dedicated to running K8s workloads. And lastly, our documentation work is ongoing - we hope to prioritize more \u2018getting started\u2019 materials for \u00a0beginners in order to enable new users to climb the learning curve faster than before. For more advanced users, we also plan more documentation around topics like autoscaling, tracing, and build statistics, among others.</p>"},{"location":"blog/2020-05-14-concourse-2020-community-report/#demographic-data","title":"Demographic Data","text":""},{"location":"blog/2020-05-14-concourse-2020-community-report/#how-long-have-you-used-concourse","title":"How long have you used Concourse?","text":"<p>{{&lt; image src=\"/images/2020/05/Screen-Shot-2020-05-14-at-11.24.35-AM-1.png\" width=\"100%\" &gt;}}</p> <p>Most of the people who responded indicated they had been using Concourse for one year or less. It's great to see that more people are picking up and experimenting with Concourse with each new release, and it's just as exciting to see that people stick around: more than 45% of respondents said they have been using Concourse for 2+ years. Whenever we interpret feedback from the community, we want to make sure we're taking into account the experiences of both newcomers, established users, and very experienced power users. Each segment experiences different challenges, and prioritizes different parts of the product.</p>"},{"location":"blog/2020-05-14-concourse-2020-community-report/#other-cicd-tools-used","title":"Other CI/CD tools used","text":"<p>{{&lt; image src=\"/images/2020/05/Screen-Shot-2020-05-14-at-11.24.03-AM-1.png\" width=\"100%\" &gt;}}</p> <p>Another dimension that's helpful to understand is the related experiences that each survey respondent is equipped with. When looking at other CI/CD tools that our community employs, Jenkins is still the top dog, accounting for nearly 30% of the tools mentioned. Github Actions has seen a rise in adoption since its initial release, and Travis, Gitlab, Bitbucket, and CircleCI are all fairly common options as well.</p>"},{"location":"blog/2020-05-14-concourse-2020-community-report/#how-did-you-find-out-about-concourse","title":"How did you find out about Concourse?","text":"<p>{{&lt; image src=\"/images/2020/05/Screen-Shot-2020-05-14-at-11.22.53-AM.png\" width=\"100%\" &gt;}}</p> <p>Pivotal Software (now VMware) has been Concourse's largest supporter since the project's inception. In previous years, it was common to see more than half of respondents say they were introduced to Concourse CI through a Pivotal Labs engagement, or through Concourse\u2019s role in automation of the Pivotal Platform, Pivotal Cloud Foundry. Now the community has started to branch out, with only 22% of people reporting that they learned about the product through Pivotal.</p> <p>The majority of users seem to have found Concourse organically, through search engines or social media. We're hoping to expand the use of our blog this year to help support the number of people hunting for Concourse content. Be on the lookout for more tutorials, advanced operations articles, and general updates about the Concourse product development and roadmap.</p> <p>We'd love to grow that Conference or Meetup section in 2020 - who's up for a remote meetup over Zoom? \ud83d\ude4c</p>"},{"location":"blog/2020-05-14-concourse-2020-community-report/#why-use-concourse","title":"Why use Concourse?","text":"<p>{{&lt; image src=\"/images/2020/05/Screen-Shot-2020-05-14-at-11.24.16-AM.png\" width=\"100%\" &gt;}}</p> <p>When asked about the very important _ why _ behind their Concourse usage, concerns about Open Source tooling and flexibility were top of mind. The special emphasis that Concourse put on reproducibility and user interface also ranked highly, along with Concourse's scalability and overall feature set. Scalability is always a huge concern for the team, as we see enterprise customers frequently testing the limits of their tooling (sometimes with hundreds of Concourse clusters, many thousands of teams, and many hundreds of thousands of pipelines). Likewise, reproducibility is a commitment we're not planning on straying from any time soon.</p>"},{"location":"blog/2020-05-14-concourse-2020-community-report/#concourse-versions","title":"Concourse Versions","text":"<p>{{&lt; image src=\"/images/2020/05/Screen-Shot-2020-05-14-at-11.53.24-AM.png\" width=\"100%\" &gt;}}</p> <p>We released the survey just as v6.0.0 of Concourse was being finalized, so it was only close to the end that we started to see people upgrading to v6. We're thrilled, nonetheless, to see so many people had already upgraded to v5.8.x. Together, versions v5.8.x and v5.7.x represented the majority of survey respondents, with a low (&gt;10) rate of responses for any other version.</p> <p>To those 12 users who are still on v4.x.x and 7 users still on v3.x.x, feel free toget in touch on the Concourse Discord if you need any help upgrading! You can find all of the wonderful reasons to upgrade in therelease notes, and we'll write blog articles in the coming months highlighting some of the latest and greatest new features and optimizations, as well as some upcoming enhancements on our roadmap.</p>"},{"location":"blog/2020-05-14-concourse-2020-community-report/#scale","title":"Scale","text":"<p>{{&lt; image src=\"/images/2020/05/Screen-Shot-2020-05-14-at-11.23.29-AM.png\" width=\"100%\" &gt;}}</p> <p>The data gathered shows that the majority of respondents are working with Concourses organized with fewer teams. And when it comes to users...</p> <p>{{&lt; image src=\"/images/2020/05/Screen-Shot-2020-05-14-at-11.23.48-AM.png\" width=\"100%\" &gt;}}</p> <p>... we see a lot of smaller Concourse instances of under 10 users. There are also a few examples of large, enterprise scale deployments of 100+ users over 50+ teams. On the Concourse team, we frequently reach out to enterprise customers for special feedback on more massive implementation concerns. We also survey and interview members of the open source community to make sure we're building solutions that scale down to single users and small teams.</p> <p>If you'd like to add your voice, feel free to join in on theConcourse Discussions board.</p>"},{"location":"blog/2020-05-14-concourse-2020-community-report/#deployment-method","title":"Deployment Method","text":"<p>{{&lt; image src=\"/images/2020/05/Screen-Shot-2020-05-14-at-11.22.23-AM.png\" width=\"100%\" &gt;}}</p> <p>Docker remains the most frequently used deployment method, but the margins are slowly shrinking, and there's more even distribution across other popular options than we've seen in past years.</p> <p>Nearly identical numbers of responses came in citing Kubernetes (via the Helm chart), BOSH , and VM deployment strategies, reinforcing both our interest in facilitating K8s workflows and supporting our substantial BOSH user base.</p>"},{"location":"blog/2020-05-14-concourse-2020-community-report/#concourse-usage-style","title":"Concourse Usage Style","text":"<p>{{&lt; image src=\"/images/2020/05/Screen-Shot-2020-05-14-at-11.24.53-AM.png\" width=\"100%\" &gt;}}</p> <p>This year we asked about our users' usage style - specifically, what sort of development scenarios they were using Concourse to facilitate. Concourse remains an Infrastructure Automation powerhouse, and a similar number of users are using it to perform CI for web development and deploying software as part of their path to production.</p>"},{"location":"blog/2020-05-14-concourse-2020-community-report/#workloads","title":"Workloads","text":"<p>{{&lt; image src=\"/images/2020/05/Screen-Shot-2020-05-14-at-11.57.17-AM.png\" width=\"100%\" &gt;}}</p> <p>Linux workloads represent the vast majority for the Concourse community. We're also paying attention to special concerns for those running Windows and Darwin workloads, however this knowledge will help us prioritize fixes to help the largest group of users possible.</p>"},{"location":"blog/2020-05-14-concourse-2020-community-report/#preferred-iaas","title":"Preferred IAAS","text":"<p>{{&lt; image src=\"/images/2020/05/Screen-Shot-2020-05-14-at-1.10.07-PM.png\" alt=\"\" width=\"100%\" &gt;}} Note: RMDH is remotely-managed dedicated hardware</p> <p>Finally, when asked about their preferred IAAS, AWS takes the top position again for the third year in a row. We consistently see a strong vSphere presence from enterprise customers, but it's really interesting to see the variety of setups that the open source community as a whole employs when deploying Concourse.</p>"},{"location":"blog/2020-05-14-concourse-2020-community-report/#summary","title":"Summary","text":"<p>A recurring topic that comes up in conversations with customers and internal teams at VMware is the sheer variety of ways that Concourse can be set up and put to work. Running this survey further reinforces that idea, giving us insight into an even larger number of configurations and implementations than what we see during our day to day enterprise development and support.</p> <p>It\u2019s also interesting to reflect on how far the project has come since Concourse CI was first introduced. We\u2019re nearing 22k commits from over 318 contributors adding up to 333 releases as of the typing of this sentence, and we\u2019re looking forward to speeding up even further in 2020.</p> <p>Of course, we want to make sure that we\u2019re developing the right features, prioritizing the right fixes and enhancements, and validating that each step we take has been made in the right direction. In the upcoming months we\u2019ll be consolidating all of these ideas into a new high level roadmap that sets out quarterly milestones for the team.</p> <p>Keep watch on the Github discussions page, this blog, and the Concourse Twitter feed for more updates, and don\u2019t forget tojoin the conversation on Discord.</p>"},{"location":"blog/2020-05-25-introduction-to-task-inputs-and-outputs/","title":"Introduction to Task Inputs and Outputs","text":"<p>Understanding how task inputs and outputs work in Concourse can be a little confusing initially. This post will walk you through a few example pipelines to show you how inputs and outputs work within a single Concourse job. By the end you should understand how inputs and outputs work within the context of a single job.</p> <p>Let's define some jargon first.</p> <ul> <li>step : A step is a container running code within the context of a   Concourse job. A step may have inputs and/or outputs, or neither.</li> <li>Job plan : A list of steps that a job will execute when triggered.</li> <li>Inputs and Outputs : These are directories. Within Concourse they're generically referred to as artifacts.   These artifacts are mounted in a step's container under a directory with some-name. You, as a writer of   Concourse pipelines, have control over what the name of your artifacts will be. If you're coming from the Docker   world, artifact is synonymous with volumes.</li> </ul> <p>To run the pipelines in the following examples yourself you can get your own Concourse running locally by following the Quick Start guide. Then use  <code>fly set-pipeline</code> to see the pipelines in action.</p> <p>Concourse pipelines contain a lot of information. Within each pipeline YAML there are comments to help bring specific lines to your attention.</p>"},{"location":"blog/2020-05-25-introduction-to-task-inputs-and-outputs/#example-one-two-tasks","title":"Example One - Two Tasks","text":"<p>This pipeline will show us how to create outputs and pass outputs as inputs to the next step(s) in a job plan.</p> <p>This pipeline has two tasks. The first task outputs a file with the date. The second task reads and prints the contents of the file from the first task.</p> <pre><code>jobs:\n  - name: a-job\n    plan:\n      - task: create-one-output\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: alpine }\n          outputs:\n            # Concourse will make an empty dir with this name\n            # and save the contents for later steps\n            - name: the-output\n          run:\n            path: /bin/sh\n            args:\n              - -cx\n              - |\n                ls -lah\n                date &gt; ./the-output/file\n      - task: read-ouput-from-previous-step\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: alpine }\n          # You must explicitly name the inputs you expect\n          # this task to have.\n          # If you don't then outputs from previous steps\n          # will not appear in the step's container.\n          # The name must match the output from the previous step.\n          # Try removing or renaming the input to see what happens!\n          inputs:\n            - name: the-output\n          run:\n            path: /bin/sh\n            args:\n              - -cx\n              - |\n                ls -lah\n                cat ./the-output/file\n</code></pre> <p>Here's a visual graphic of what happens when the above job is executed.</p> <p>{{&lt; image src=\"/images/2020/05/example-one-10.gif\" width=\"100%\" &gt;}}</p>"},{"location":"blog/2020-05-25-introduction-to-task-inputs-and-outputs/#example-two-two-tasks-with-the-same-output-who-wins","title":"Example Two - Two tasks with the same output, who wins?","text":"<p>This example is to satisfy the curiosity cat inside all of us! Never do this in real life because you're definitely going to hurt yourself!</p> <p>There are two jobs in this pipeline. The first job has two steps; both steps will produce an artifact named <code>the-output</code> in parallel. If you run the <code>writing-to-the-same-output-in-parallel</code> job multiple times you'll see the file in <code>the-output</code> folder changes depending on which of the parallel tasks finished last. Here's a visualization of the first job.</p> <p>{{&lt; image src=\"/images/2020/05/example-two-parallel.gif\" width=\"100%\" &gt;}}</p> <p>The second job is a serial version of the first job. In this job the second task always wins because it's the last task that outputs <code>the-output</code>, so only <code>file2</code> will be in <code>the-output</code> directory in the last step in the job plan.</p> <p>{{&lt; image src=\"/images/2020/05/example-two-serial.gif\" width=\"100%\" &gt;}}</p> <p>This pipeline illustrates that you could accidentally overwrite the output from a previous step if you're not careful with the names of your outputs.</p> <pre><code>jobs:\n  - name: writing-to-the-same-output-in-parallel\n    plan:\n      # running two tasks that output in parallel?!?\n      # who will win??\n      - in_parallel:\n          - task: create-the-output\n            config:\n              platform: linux\n              image_resource:\n                type: registry-image\n                source: { repository: busybox }\n              outputs:\n                - name: the-output\n              run:\n                path: /bin/sh\n                args:\n                  - -cx\n                  - |\n                    ls -lah\n                    date &gt; ./the-output/file1\n          - task: also-create-the-output\n            config:\n              platform: linux\n              image_resource:\n                type: registry-image\n                source: { repository: busybox }\n              outputs:\n                - name: the-output\n              run:\n                path: /bin/sh\n                args:\n                  - -cx\n                  - |\n                    ls -lah\n                    date &gt; ./the-output/file2\n      # run this job multiple times to see which\n      # previous task wins each time\n      - task: read-ouput-from-previous-step\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          inputs:\n            - name: the-output\n          run:\n            path: /bin/sh\n            args:\n              - -cx\n              - |\n                ls -lah ./the-output\n                echo \"Get ready to error!\"\n                cat ./the-output/file1 ./the-output/file2\n\n  - name: writing-to-the-same-output-serially\n    plan:\n      - task: create-one-output\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          outputs:\n            - name: the-output\n          run:\n            path: /bin/sh\n            args:\n              - -cx\n              - |\n                ls -lah\n                date &gt; ./the-output/file1\n      - task: create-another-output\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          outputs:\n            - name: the-output\n          run:\n            path: /bin/sh\n            args:\n              - -cx\n              - |\n                ls -lah\n                date &gt; ./the-output/file2\n      - task: read-ouput-from-previous-step\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          inputs:\n            - name: the-output\n          run:\n            path: /bin/sh\n            args:\n              - -cx\n              - |\n                ls -lah ./the-output\n                echo \"Get ready to error!\"\n                cat ./the-output/file1 ./the-output/file2\n</code></pre>"},{"location":"blog/2020-05-25-introduction-to-task-inputs-and-outputs/#example-three-inputoutput-name-mapping","title":"Example Three - Input/Output Name Mapping","text":"<p>Sometimes the names of inputs and outputs don't match, or they do match and you don't want them overwriting each other, like in the previous example. That's when  <code>input_mapping</code> and  <code>output_mapping</code> become helpful. Both of these features map the inputs/outputs in the task's config to some artifact name in the job plan.</p> <p>This pipeline has one job with four tasks.</p> <p>The first task outputs a file with the date to the <code>the-output</code> directory. <code>the-output</code> is mapped to the new name <code>demo-disk</code>. \u00a0The artifact <code>demo-disk</code> is now available in the rest of the job plan for future steps to take as inputs. The remaining steps do this in various ways.</p> <p>The second task reads and prints the contents of the file under the new name <code>demo-disk</code>.</p> <p>The third task reads and prints the contents of the file under another name, <code>generic-input</code>. The <code>demo-disk</code> artifact in the job plan is mapped to <code>generic-input</code>.</p> <p>The fourth task tries to use the artifact named <code>the-output</code> as its input. This task fails to even start because there was no artifact with the name <code>the-output</code> available in the job plan; it was remapped to <code>demo-disk</code>.</p> <p>Here's a visualization of the job.</p> <p>{{&lt; image src=\"/images/2020/05/example-three-1.gif\" width=\"100%\" &gt;}}</p> <p>Here's the pipeline YAML for you to run on your local Concourse.</p> <pre><code>jobs:\n  - name: a-job\n    plan:\n      - task: create-one-output\n        # The task config has the artifact `the-output`\n        # output_mapping will rename `the-output` to `demo-disk`\n        # in the rest of the job's plan\n        output_mapping:\n          the-output: demo-disk\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          outputs:\n            - name: the-output\n          run:\n            path: /bin/sh\n            args:\n              - -cx\n              - |\n                ls -lah\n                date &gt; ./the-output/file\n      # this task expects the artifact `demo-disk` so no mapping is needed\n      - task: read-ouput-from-previous-step\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          inputs:\n            - name: demo-disk\n          run:\n            path: /bin/sh\n            args:\n              - -cx\n              - |\n                ls -lah\n                cat ./demo-disk/file\n      - task: rename-and-read-output\n        # This task expects the artifact `generic-input`.\n        # input_mapping will map the tasks `generic-input` to\n        # the job plans `demo-disk` artifact\n        input_mapping:\n          generic-input: demo-disk\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          inputs:\n            - name: generic-input\n          run:\n            path: /bin/sh\n            args:\n              - -cx\n              - |\n                ls -lah\n                cat ./generic-input/file\n      - task: try-and-read-the-output\n        input_mapping:\n          generic-input: demo-disk\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          # `the-output` is not available in the job plan\n          # so this task will error while initializing\n          # since there's no artiact named `the-output` in\n          # the job's plan\n          inputs:\n            - name: the-output\n          run:\n            path: /bin/sh\n            args:\n              - -cx\n              - |\n                ls -lah\n                cat ./generic-input/file\n</code></pre>"},{"location":"blog/2020-05-25-introduction-to-task-inputs-and-outputs/#example-four-can-you-add-files-to-an-existing-output-artifact","title":"Example Four - Can you add files to an existing output artifact?","text":"<p>This pipeline will also have two jobs in order to illustrate this point. What happens if we add a file to an output? If you think back to example two you may already know the answer.</p> <p>The first task will create <code>the-output</code> with <code>file1</code>. The second task will add <code>file2</code> to the <code>the-output</code>. The last task will read the contents of <code>file1</code> and <code>file2</code>.</p> <p>As long as you re-declare the input as an output in the second task you can modify any of your outputs.</p> <p>This means you can pass something between a bunch of tasks and have each task add or modify something in the artifact.</p> <pre><code>jobs:\n  - name: add-file-to-output\n    plan:\n      - task: create-one-output\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          outputs:\n            - name: the-output\n          run:\n            path: /bin/sh\n            args:\n              - -cx\n              - |\n                ls -lah\n                date &gt; ./the-output/file1\n      - task: add-file-to-previous-output\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          # this task lists the same artifact as\n          # its input and output\n          inputs:\n            - name: the-output\n          outputs:\n            - name: the-output\n          run:\n            path: /bin/sh\n            args:\n              - -cx\n              - |\n                ls -lah\n                date &gt; ./the-output/file2\n      - task: read-ouput-from-previous-step\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          inputs:\n            - name: the-output\n          run:\n            path: /bin/sh\n            args:\n              - -cx\n              - |\n                ls -lah ./the-output\n                cat ./the-output/file1 ./the-output/file2\n</code></pre> <p>Here's a visualization of the job.</p> <p>{{&lt; image src=\"/images/2020/05/example-four.gif\" width=\"100%\" &gt;}}</p>"},{"location":"blog/2020-05-25-introduction-to-task-inputs-and-outputs/#example-five-multiple-outputs","title":"Example Five - Multiple Outputs","text":"<p>What happens if you have a task that has multiple outputs and a second task that only lists one of the outputs? Does the second task get the extra outputs from the first task?</p> <p>The answer is no. A task will only get the artifacts that match the name of the inputs listed in the task's config.</p> <pre><code>jobs:\n  - name: multiple-outputs\n    plan:\n      - task: create-three-outputs\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          outputs:\n            - name: the-output-1\n            - name: the-output-2\n            - name: the-output-3\n          run:\n            path: /bin/sh\n            args:\n              - -cx\n              - |\n                ls -lah\n                date &gt; ./the-output-1/file\n                date &gt; ./the-output-2/file\n                date &gt; ./the-output-3/file\n      - task: take-one-output\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          # only one of the three outputs are\n          # listed as inputs\n          inputs:\n            - name: the-output-1\n          run:\n            path: /bin/sh\n            args:\n              - -cx\n              - |\n                ls -lah ./\n                cat ./the-output-1/file\n      - task: take-two-outputs\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          # this task pulls in the other\n          # two outputs, just for fun!\n          inputs:\n            - name: the-output-2\n            - name: the-output-3\n          run:\n            path: /bin/sh\n            args:\n              - -cx\n              - |\n                ls -lah ./\n                cat ./the-output-2/file\n                cat ./the-output-3/file\n</code></pre> <p>Here's a visualization of the above job.</p> <p>{{&lt; image src=\"/images/2020/05/example-five.gif\" width=\"100%\" &gt;}}</p>"},{"location":"blog/2020-05-25-introduction-to-task-inputs-and-outputs/#example-six-get-steps","title":"Example Six - Get Steps","text":"<p>The majority of Concourse pipelines have at least one resource, which means they have at least one get step. Using a get step in a job makes an artifact with the name of the get step available for later steps in the job plan to consume as inputs.</p> <pre><code>resources:\n  - name: concourse-examples\n    type: git\n    source: { uri: \"https://github.com/concourse/examples\" }\n\njobs:\n  - name: get-step\n    plan:\n      # there will be an artifact named\n      # \"concourse-examples\" available in the job plan\n      - get: concourse-examples\n      - task: take-one-output\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          inputs:\n            - name: concourse-examples\n          run:\n            path: /bin/sh\n            args:\n              - -cx\n              - |\n                ls -lah ./\n                cat ./concourse-examples/README.md\n</code></pre> <p>Here's a visualization for the above job.</p> <p>{{&lt; image src=\"/images/2020/05/example-six.gif\" width=\"100%\" &gt;}}</p> <p>I hope you found these example helpful with figuring out how inputs and outputs work within a single Concourse job.</p>"},{"location":"blog/2020-06-10-rfc-round-up-june-10th-2020/","title":"RFC round-up: June 10th, 2020","text":"<p>First off: sorry, I immediately failed to keep my target pace for these. \ud83d\ude13 I got wrapped up in a deadline, and since I alternate weeks between engineering and community duties like this post, when I miss a week for RFC updates the 2-week interval can quickly turn into 4 or 5.</p> <p>Owing to the missed round-up, and in hopes of burning through the backlog more quickly so that interested contributors may volunteer for merged RFCs, I'm going to expand the scope of this post to include more RFCs than the last one - primarily by proposing that we merge ones that are nearly certain for the v10 roadmap.</p>"},{"location":"blog/2020-06-10-rfc-round-up-june-10th-2020/#merged-rfcs","title":"Merged RFCs","text":"<ul> <li>RFC #33 (pipeline archiving)   and RFC #34 (pipeline instances) have both been merged! \ud83c\udf89</li> </ul>"},{"location":"blog/2020-06-10-rfc-round-up-june-10th-2020/#rfcs-ready-to-merge","title":"RFCs ready to merge","text":"<p>The following RFCs have been given the <code>resolution/merge</code> label:</p> <ul> <li>RFC #31: <code>set_pipeline</code> step is the RFC corresponding to the   <code>set_pipeline</code> step that was introduced experimentally in v5.8. Once this is merged, the step itself will no longer be   experimental, but there are a couple of experimental features for the step that are now outlined in the RFC - <code>self</code>   and <code>team:</code>. These features will result in warnings when used.</li> <li>RFC #40: valid identifiers proposes that we restrict the set of allowed   characters in Concourse identifiers such as pipeline names, job names, and resource names. Existing pipelines and   objects will be grandfathered in to ease the transition. Note: if you're worried about this change you may be   interested in RFC #34.</li> <li>RFC #39: var sources is the RFC corresponding to the <code>var_sources</code>   feature, which was also introduced experimentally in v5.8. This feature is a key component to v10 - it unblocks   spatial pipelines, per-job timed triggers, and per-pipeline credential management configuration.</li> <li>RFC #27: var steps is behind the  <code>load_var</code> step (shipped experimentally in v6.0), and also   introduces a <code>get_var</code> step which can theoretically be used to implement per-job trigger intervals. This RFC builds on   the var sources concept described in RFC #39.</li> </ul> <p>Per the resolution process, if there are no objections or significant changes in the 2 weeks after this post is published, they will be merged! \ud83d\ude80</p>"},{"location":"blog/2020-06-10-rfc-round-up-june-10th-2020/#rfcs-in-need-of-attention","title":"RFCs in need of attention","text":"<p>Quite a few RFCs have had some pretty interesting discussions or developments since the last round-up:</p> <ul> <li>RFC #36: manual step has had some juicy conversation around how things   like approval and manual gating in a pipeline should be expressed in a Concoursey way - if you have thoughts on this,   please chime in!</li> <li>RFC #37: prototypes is the RFC for the \"Prototypes\" concept introduced in   the Re-inventing resource types blog post. The latest revision   introduces encryption, which will enable Prototypes to implement credential managers. If you are a resource type   author or if you have a security background, please give it a look!</li> <li>RFC #32: projects now has a pretty radical new question: can Projects   replace Teams in order to provide more complete cluster config automation? If you've ever had a need for automating   team configuration, or if you have a thirst for GitOps, this should be a pretty interesting conversation!</li> </ul>"},{"location":"blog/2020-06-10-rfc-round-up-june-10th-2020/#new-rfcs","title":"New RFCs","text":"<ul> <li>RFC #53: configurable build event stores proposes a pluggable   architecture for build event storage as an alternative to storing them in the database.</li> <li>RFC #59: static configuration proposes a method for configuring Concourse   with a config file that prescribes the teams and projects, in addition to the regular config that would previously   have been set in flags or env vars. It also proposes disallowing the use of <code>fly set-team</code> at runtime so that the   config is the source of truth.</li> </ul>"},{"location":"blog/2020-06-10-rfc-round-up-june-10th-2020/#thanks","title":"Thanks!","text":"<p>Giving feedback on RFCs is critical to our ability to move forward more quickly and with higher confidence. Any and all comments and questions we receive are deeply appreciated. Thanks to everyone who's been involved, and thanks in advance to everyone else! \ud83d\ude42</p> <p>(Stay safe!)</p>"},{"location":"blog/2020-06-19-how-to-build-and-publish-a-container-image/","title":"How To Build and Publish a Container Image","text":"<p>In this blog post we are going to show how to build and publish container images using the oci-build task and registry-image resource. This post assumes you understand how to build container images with <code>Dockerfile</code>'s and publish to Docker Hub or another image registry using the <code>docker</code> cli.</p> <p>If you just want to see the pipeline, scroll to the bottom or click here. What follows is a detailed explanation of what each part of the pipeline does.</p> <p>First we need a Dockerfile. You can store this in your own repo or reference the github.com/concourse/examples repo. The rest of this post assumes you use the examples repo. All files in this blog post can be found in the examples repo.</p>"},{"location":"blog/2020-06-19-how-to-build-and-publish-a-container-image/#the-dockerfile","title":"The Dockerfile","text":"<p>We are going to use a very basic Dockerfile so we can focus on building the Concourse pipeline.</p> <pre><code>FROM busybox\n\nRUN echo \"I'm simple!\"\nCOPY ./stranger /stranger\nRUN cat /stranger\n</code></pre>"},{"location":"blog/2020-06-19-how-to-build-and-publish-a-container-image/#defining-pipeline-resources","title":"Defining Pipeline Resources","text":"<p>Now we can start building out our pipeline. Let's declare our resources first. We will need one resource to pull in the repo where our Dockerfile is located, and a second resource pointing to where we want to push the built container image to.</p> <p>There are some variables in this file that we will fill out later.</p> <pre><code>resources:\n  # The repo with our Dockerfile\n  - name: concourse-examples\n    type: git\n    icon: github\n    source:\n      uri: https://github.com/concourse/examples.git\n      branch: master\n\n  # Where we will push the image to\n  - name: simple-image\n    type: registry-image\n    icon: docker\n    source:\n      repository: ((image-repo-name))/simple-image\n      username: ((registry-username))\n      password: ((registry-password))\n</code></pre>"},{"location":"blog/2020-06-19-how-to-build-and-publish-a-container-image/#create-a-job","title":"Create a Job","text":"<p>Next we will create a job that will build and push our container image.</p> <pre><code>jobs:\n  - name: build-and-push\n</code></pre>"},{"location":"blog/2020-06-19-how-to-build-and-publish-a-container-image/#retrieve-the-dockerfile","title":"Retrieve the Dockerfile","text":"<p>The first step in the job plan will be to retrieve the repo where our Dockerfile is.</p> <pre><code>jobs:\n  - name: build-and-push\n    plan:\n      - get: concourse-examples\n</code></pre>"},{"location":"blog/2020-06-19-how-to-build-and-publish-a-container-image/#build-the-container-image","title":"Build the Container Image","text":"<p>The second step in our job will build the container image.</p> <p>To build the container image we are going to use the oci-build-task. The oci-build-task is a container image that is meant to be used in a Concourse task to build other container images. Check out the  <code>README</code> in the repo for more details on how to configure and use the oci-build-task in more complex build scenarios.</p> <p>Let's add a task to our job plan and give it a name.</p> <pre><code>jobs:\n  - name: build-and-push\n    plan:\n      - get: concourse-examples\n      - task: build-task-image\n</code></pre> <p>All configuration of the <code>oci-build-task</code> is done through a task config. Viewing the <code>README</code> from the repo we can see that the task needs to be run as a privileged task on a linux worker.</p> <pre><code>jobs:\n  - name: build-and-push\n    plan:\n      - get: concourse-examples\n      - task: build-task-image\n        privileged: true\n        config:\n          platform: linux\n</code></pre> <p>To use the <code>oci-build-task</code> container image we specify the  <code>image_resource</code> that the task should use.</p> <pre><code>jobs:\n  - name: build-and-push\n    plan:\n      - get: concourse-examples\n      - task: build-task-image\n        privileged: true\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source:\n              repository: vito/oci-build-task\n</code></pre> <p>Next we will add <code>concourse-examples</code> as an input to the build task to ensure the artifact from the get step (where our <code>Dockerfile</code> is fetched) is mounted in our <code>build-task-image</code> step.</p> <pre><code>jobs:\n  - name: build-and-push\n    plan:\n      - get: concourse-examples\n      - task: build-task-image\n        privileged: true\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source:\n              repository: vito/oci-build-task\n          inputs:\n            - name: concourse-examples\n</code></pre> <p>The <code>oci-build-task</code> outputs the built container image in a directory called <code>image</code>. Let's add <code>image</code> as an output artifact of our task so we can publish it in a later step.</p> <pre><code>jobs:\n  - name: build-and-push\n    plan:\n      - get: concourse-examples\n      - task: build-task-image\n        privileged: true\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source:\n              repository: vito/oci-build-task\n          inputs:\n            - name: concourse-examples\n          outputs:\n            - name: image\n</code></pre> <p>Next we need to tell the <code>oci-build-task</code> what the build context of our Dockerfile is. The  <code>README</code> goes over a few other methods of creating your build context. We are going to use the simplest use-case. By specifying <code>CONTEXT</code> the <code>oci-build-task</code> assumes a <code>Dockerfile</code> and its build context are in the same directory.</p> <pre><code>jobs:\n  - name: build-and-push\n    plan:\n      - get: concourse-examples\n      - task: build-task-image\n        privileged: true\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source:\n              repository: vito/oci-build-task\n          inputs:\n            - name: concourse-examples\n          outputs:\n            - name: image\n          params:\n            CONTEXT: concourse-examples/Dockerfiles/simple\n</code></pre> <p>The last step is specifying what our <code>build-task-image</code> should execute. The <code>oci-build-task</code> container image has a binary named  <code>build</code> located in its <code>PATH</code> in the  <code>/usr/bin</code> directory. We'll tell our task to execute that binary, which will build our container image.</p> <pre><code>jobs:\n  - name: build-and-push\n    plan:\n      - get: concourse-examples\n      - task: build-task-image\n        privileged: true\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source:\n              repository: vito/oci-build-task\n          inputs:\n            - name: concourse-examples\n          outputs:\n            - name: image\n          run:\n            path: build\n          params:\n            CONTEXT: concourse-examples/Dockerfiles/simple\n</code></pre> <p>At this point in our job the container image is built! The <code>oci-build-task</code> has saved the container image as a tarball named <code>image.tar</code> in the <code>image</code> artifact specified in the task outputs. This tar file is the same output you would get if you built the container image using Docker and then did  <code>docker save</code>.</p>"},{"location":"blog/2020-06-19-how-to-build-and-publish-a-container-image/#publish-the-container-image","title":"Publish the Container Image","text":"<p>Now let's push the container image to an image registry! For this example we're pushing to Docker Hub using the  <code>registry-image</code> resource. You can use the <code>registry-image</code> resource to push to any image registry, private or public. Check out the  <code>README.md</code> for more details on using the resource.</p> <p>To push the container image add a put step to our job plan and tell the regstry-image resource where the tarball of the container image is.</p> <p>The put step will push the container image using the information defined in the resource's source, when we defined the pipeline's resources.</p> <p>This is where you'll need to replace the three variables found under <code>resource_types</code>. You can define them statically using <code>fly</code>'s <code>--var</code> flag when setting the pipeline. (In production make sure to use a credential management system to store your secrets!)</p> <pre><code>jobs:\n  - name: build-and-push\n    plan:\n      - get: concourse-examples\n      - task: build-task-image\n        privileged: true\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source:\n              repository: vito/oci-build-task\n          inputs:\n            - name: concourse-examples\n          outputs:\n            - name: image\n          params:\n            CONTEXT: concourse-examples/Dockerfiles/simple\n          run:\n            path: build\n      - put: simple-image\n        params:\n          image: image/image.tar\n</code></pre>"},{"location":"blog/2020-06-19-how-to-build-and-publish-a-container-image/#the-entire-pipeline","title":"The Entire Pipeline","text":"<p>Putting all the pieces together, here is our pipeline that builds and pushes (publishes) a container image.</p> <pre><code>resources:\n  # The repo with our Dockerfile\n  - name: concourse-examples\n    type: git\n    icon: github\n    source:\n      uri: https://github.com/concourse/examples.git\n      branch: master\n\n  # Where we will push the image\n  - name: simple-image\n    type: registry-image\n    icon: docker\n    source:\n      repository: ((image-repo-name))/simple-image\n      username: ((registry-username))\n      password: ((registry-password))\n\njobs:\n  - name: build-and-push\n    plan:\n      - get: concourse-examples\n      - task: build-task-image\n        privileged: true\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source:\n              repository: vito/oci-build-task\n          inputs:\n            - name: concourse-examples\n          outputs:\n            - name: image\n          params:\n            CONTEXT: concourse-examples/Dockerfiles/simple\n          run:\n            path: build\n      - put: simple-image\n        params:\n          image: image/image.tar\n</code></pre> <p>You can set the pipeline with the following <code>fly</code> command, updating the variable values with real values the pipeline can use. The behaviour is similar to <code>docker push</code>:</p> <pre><code>fly -t &lt;target&gt; set-pipeline -p build-and-push-image \\\n    -c ./examples/pipelines/build-and-push-simple-image.yml \\\n    --var image-repo-name=&lt;repo-name&gt; \\\n    --var registry-username=&lt;user&gt; \\\n    --var registry-password=&lt;password&gt;\n</code></pre> <p>{{&lt; image src=\"/images/2020/06/build-and-publish-pipeline-3.png\" alt=\"build-and-push-pipeline\" &gt;}}</p>"},{"location":"blog/2020-06-19-how-to-build-and-publish-a-container-image/#further-readings","title":"Further Readings","text":"<p>Understanding what the build context is is important when building container images. You can read Dockerfile Best Practices for more details about build contexts.</p> <p>The inputs section of the oci-build-task's <code>README</code> has examples on how to create a build context with multiple inputs and other complex build scenarios.</p> <p>Read the <code>README</code>'s in the oci-build-task and registry-image resource to learn more about their other configuration options.</p> <p>If you had trouble following how the artifacts get passed between the steps of a job then read our other blog post about task inputs and outputs.</p>"},{"location":"blog/2020-06-24-rfc-round-up-june-24th-2020/","title":"RFC round-up: June 24th, 2020","text":"<p>With the four(!) RFCs from the last round-up now merged, it's time to move on to the next RFC milestone: Prototypes!</p>"},{"location":"blog/2020-06-24-rfc-round-up-june-24th-2020/#merged-rfcs","title":"Merged RFCs \ud83c\udf89","text":"<ul> <li>RFC #31: <code>set_pipeline</code> step</li> <li>RFC #40: valid identifiers</li> <li>RFC #39: var sources</li> <li>RFC #27: var steps</li> </ul>"},{"location":"blog/2020-06-24-rfc-round-up-june-24th-2020/#rfcs-ready-to-merge","title":"RFCs ready to merge \ud83e\udd1e","text":"<ul> <li>RFC #37: Prototypes is finally ready to go! For (much) further reading,   check out the Re-inventing resource types blog post. The importance   of this RFC really cannot be overstated; it will be the most significant change to Concourse since its creation.</li> <li>RFC #38: Resource Prototypes demonstrates how the Prototype protocol may   be used to implement the next generation of resource prototypes (formerly resource types) and gain long-requested   functionality along the way.</li> </ul>"},{"location":"blog/2020-06-24-rfc-round-up-june-24th-2020/#shiny-new-rfcs","title":"Shiny new RFCs \u2728","text":"<ul> <li>RFC #62: worker pools introduces a \"worker pool\" which will allow a   many-to-many relationship between workers and teams.</li> <li>RFC #63: API auth flow for applications is a conversation-starter around   adding a token-based auth flow for read-only APIs.</li> <li>RFC #61: add \"watch\" parameter for API endpoints introduces a   long-polling approach to API requests to reduce the load from constant polling from the web UI.</li> </ul>"},{"location":"blog/2020-06-24-rfc-round-up-june-24th-2020/#open-call-for-contributors","title":"Open call for contributors \ud83d\udce2","text":"<p>The following is a list of issues for each merged RFC that still has work to be done.</p> <ul> <li>Pipeline instances: #5808</li> <li>Valid identifiers: #5810</li> <li>Finishing var sources: #5813</li> <li>Finishing the <code>set_pipeline</code> step: #5814</li> <li>Implementing the <code>get_var</code> step: #5815</li> </ul> <p>If anyone's interested in throwing their hat into the ring and getting involved with Concourse development, let us know by replying to one of the issues linked above! Future RFC round-ups will include the same list, presumably with more entries.</p> <p>The v10 roadmap is highly parallelizeable, so if more people get involved we can make it to v10 much more quickly and with a healthier project that has more people able to contribute. We're super keen to give guidance and help out. \ud83d\udc4c</p> <p>Thanks!</p>"},{"location":"blog/2020-07-10-rfc-round-up-july-10th-2020/","title":"RFC round-up: July 10th, 2020","text":"<p>Happy Friday! This one's brief.</p>"},{"location":"blog/2020-07-10-rfc-round-up-july-10th-2020/#merged-rfcs","title":"Merged RFCs","text":"<ul> <li>RFC #37: prototypes has landed! ...but it probably could have use more   detail regarding the <code>run</code> step, which is the only immediately actionable part of it. \ud83e\udd14 I'll draft another RFC for   that; #37 mainly covered the protocol.</li> <li>RFC #38: resource prototypes is in! Its associated issue for   implementation is #5870.</li> </ul>"},{"location":"blog/2020-07-10-rfc-round-up-july-10th-2020/#rfcs-to-merge","title":"RFCs to merge","text":"<ul> <li>n/a - taking a breather for this round-up to focus on the below RFCs and \"reset\" the 2 week merge window so I can   start publishing these posts earlier in the week. \ud83d\ude05</li> </ul>"},{"location":"blog/2020-07-10-rfc-round-up-july-10th-2020/#rfcs-in-need-of-feedback","title":"RFCs in need of feedback","text":"<ul> <li>RFC #43: tasks queue still needs some love! The goal is to introduce a   queuing mechanism to resolve the long-running issue of Concourse over-working workers.</li> <li>RFC #29: <code>across</code> step introduces the special sauce for build matrices   and branch/PR pipeline automation, and the proposal has been heavily revised. Check it out!</li> </ul>"},{"location":"blog/2020-07-10-rfc-round-up-july-10th-2020/#open-call-for-contributors","title":"Open call for contributors","text":"<p>Valid identifiers (#5810) is now spoken for - thanks @mouellet! \ud83c\udf7b</p> <p>The following issues are up for grabs:</p> <ul> <li>Pipeline instances: #5808</li> <li>Finishing var sources: #5813</li> <li>Finishing the <code>set_pipeline</code> step: #5814</li> <li>Implementing the <code>get_var</code> step: #5815</li> </ul> <p>If anyone's interested in helping out, or just learning how, let us know by replying to any of the issues linked above or asking in Discord!</p> <p>This section will be repeated in each RFC round-up - the goal is to get to the finish line on the v10 roadmap by tackling items in parallel while improving project health by enabling more people to make significant contributions.</p> <p>Thanks everyone!</p>"},{"location":"blog/2020-08-24-gitops-for-your-pipelines/","title":"GitOps For Your Pipelines","text":"<p>In this blog post we're going to cover how to use git and Concourse to automatically set, update, and archive your pipelines using the <code>set_pipeline</code> step. No longer will you need to use <code>fly set-pipeline</code> to update any of your pipelines!</p> <p>For consistency we will refer to the pipeline that contains all the <code>set_pipeline</code> steps as the parent pipeline. The pipelines created by the <code>set_pipeline</code> steps will be called child pipelines.</p> <p>Scroll to the bottom to see the final pipeline template or click here. What follows is a detailed explanation of how the parent pipeline works along with git and automatic archiving.</p>"},{"location":"blog/2020-08-24-gitops-for-your-pipelines/#prerequisites","title":"Prerequisites","text":"<p>To run the pipelines in this blog post for yourself you can get your own Concourse running locally by following the Quick Start guide.</p> <p>You will also need to fork the github.com/concourse/examples repo and replace <code>USERNAME</code> with your github username in the below examples. We will continue to refer to the repo as <code>concourse/examples</code>. Once you have forked the repo clone it locally onto your machine and <code>cd</code> into the repo.</p> <pre><code>$ git clone git@github.com:USERNAME/examples.git\n$ cd examples\n</code></pre>"},{"location":"blog/2020-08-24-gitops-for-your-pipelines/#create-the-parent-pipeline","title":"Create the Parent Pipeline","text":"<p>Inside your fork of <code>concourse/examples</code> that you have cloned locally, create a file named <code>reconfigure-pipelines.yml</code> inside the <code>pipelines</code> folder. This is the pipeline that we are going to be building. We will refer to this pipeline as the parent pipeline.</p> <pre><code>$ touch ./pipelines/reconfigure-pipelines.yml\n</code></pre> <p>Like the <code>fly set-pipeline</code> command, the <code>set_pipeline</code> step needs a YAML file containing a pipeline configuration. We will use the concourse/examples repo as the place to store our pipelines and thankfully it already contains many pipelines! Let's add the repo as a resource to our parent pipeline.</p> <pre><code>resources:\n  - name: concourse-examples\n    type: git\n    icon: github\n    source:\n      uri: git@github.com:USERNAME/examples.git\n</code></pre> <p>Now we will add a job that will set our pipelines. The first step in the job will fetch the <code>concourse/examples</code> repo, making it available to future steps as the <code>concourse-examples</code> artifact. We will also add the <code>trigger</code> parameter to ensure that the job will run whenever a new commit is pushed to the <code>concourse/examples</code> repo.</p> <pre><code>resources:\n  - name: concourse-examples\n    type: git\n    icon: github\n    source:\n      uri: git@github.com:USERNAME/examples.git\n\njobs:\n  - name: configure-pipelines\n    public: true\n    plan:\n      - get: concourse-examples\n        trigger: true\n</code></pre> <p>Next we will add the <code>set_pipeline</code> step to set one of the pipelines in the <code>concourse/examples</code> repo. We will set the <code>hello-world</code> pipeline first.</p> <pre><code>resources:\n  - name: concourse-examples\n    type: git\n    icon: github\n    source:\n      uri: git@github.com:USERNAME/examples.git\n\njobs:\n  - name: configure-pipelines\n    public: true\n    plan:\n      - get: concourse-examples\n        trigger: true\n      - set_pipeline: hello-world\n        file: concourse-examples/pipelines/hello-world.yml\n</code></pre> <p>Let's commit what we have so far and push it to github.</p> <pre><code>$ git add pipelines/reconfigure-pipelines.yml\n$ git commit -m \"add reconfigure-pipelines\"\n$ git push -u origin head\n</code></pre>"},{"location":"blog/2020-08-24-gitops-for-your-pipelines/#setting-the-parent-pipeline","title":"Setting the Parent Pipeline","text":"<p>Now we have a chicken or the egg problem, except in this case we know our parent pipeline comes first! Let's set our pipeline with <code>fly</code> and execute the <code>configure-pipelines</code> job.</p> <pre><code>$ fly -t local set-pipeline \\\n  -p reconfigure-pipelines \\\n  -c pipelines/reconfigure-pipelines.yaml\n\n...\napply configuration? [yN]: y\n\n$ fly -t local unpause-pipeline \\\n  -p reconfigure-pipelines\n\nunpaused 'reconfigure-pipelines'\n\n$ fly -t local trigger-job \\\n  -j reconfigure-pipelines/configure-pipelines \\\n  --watch\n</code></pre> <p>Once the job is done running you should see two pipelines, <code>reconfigure-pipelines</code> and <code>hello-world</code>.</p> <p>{{&lt; image src=\"/images/2020/08/hello-world.png\" alt=\"Concourse dashboard showing two pipelines\" width=\"100%\" &gt;}}</p> <p>Now any changes you make to the <code>hello-world</code> pipeline will be updated automatically in Concourse once it picks up the commit with your changes.</p>"},{"location":"blog/2020-08-24-gitops-for-your-pipelines/#pipelines-setting-themselves","title":"Pipelines Setting Themselves","text":"<p>Our parent pipeline is setting and updating one other pipeline now but it has one glaring limitation: it doesn't set itself. We have to <code>fly set-pipeline</code> every time we want to add a new pipeline to the <code>configure-pipelines</code> job.</p> <p>To resolve this we can do the following to our parent pipeline:</p> <ul> <li>Add a job before the <code>configure-pipelines</code> job that self-updates the parent pipeline. We'll name the job   <code>configure-self</code>.</li> <li>Add a <code>passed</code> constraint to the <code>configure-pipelines</code> job to only run once the <code>concourse-examples</code> resource has   passed the new <code>configure-self</code> job.</li> </ul> <p>By doing the above we will never have to use <code>fly</code> to update the parent pipline again. Every commit to the <code>concourse/examples</code> repo will cause the parent pipeline to update itself and then all of its child pipelines. Now our pipelines are following a GitOps type of workflow!</p> <p>Here is what the above changes look like when implemented:</p> <pre><code>resources:\n  - name: concourse-examples\n    type: git\n    icon: github\n    source:\n      uri: git@github.com:USERNAME/examples.git\n\njobs:\n  - name: configure-self\n    plan:\n      - get: concourse-examples\n        trigger: true\n      - set_pipeline: reconfigure-pipelines\n        file: concourse-examples/pipelines/reconfigure-pipelines.yml\n  - name: configure-pipelines\n    plan:\n      - get: concourse-examples\n        trigger: true\n        passed: [ configure-self ]\n      - set_pipeline: hello-world\n        file: concourse-examples/pipelines/hello-world.yml\n</code></pre> <p>Side-note : for the <code>configure-self</code> job, you could also use the  <code>self</code> keyword, though this is labelled as experimental and may disappear in the future.</p> <p>Lets set the parent pipeline one more time with <code>fly</code> and then we'll make commits to the repo to make all future changes.</p> <pre><code>$ fly -t local set-pipeline \\\n  -p reconfigure-pipelines \\\n  -c pipelines/reconfigure-pipelines.yaml\n\n...\napply configuration? [yN]: y\n</code></pre> <p>The parent pipeline should now look like this. Now the pipeline will first update itself and then update any existing child pipelines.</p> <p>{{&lt; image src=\"/images/2020/08/set-self.png\" alt=\"parent pipeline with config-self job\" width=\"100%\" &gt;}}</p> <p>Let's commit our changes, which will be a no-op since we've already updated the pipeline with the latest changes.</p> <pre><code>$ git add pipelines/reconfigure-pipelines.yml\n$ git commit -m \"add configure-self job\"\n$ git push\n</code></pre> <p>Now comes the real fun! To add a pipeline to Concourse all we need to do is add a <code>set_pipeline</code> step to the parent pipeline, commit it to the <code>concourse/examples</code> repo, and let the parent pipeline pick up the new commit and make the changes for us.</p> <p>Lets add the <code>time-triggered</code> pipeline to our <code>reconfigure-pipelines.yml</code> file.</p> <pre><code>resources:\n  - name: concourse-examples\n    type: git\n    icon: github\n    source:\n      uri: git@github.com:USERNAME/examples.git\n\njobs:\n  - name: configure-self\n    plan:\n      - get: concourse-examples\n        trigger: true\n      - set_pipeline: reconfigure-pipelines\n        file: concourse-examples/pipelines/reconfigure-pipelines.yml\n  - name: configure-pipelines\n    plan:\n      - get: concourse-examples\n        trigger: true\n        passed: [ configure-self ]\n      - set_pipeline: hello-world\n        file: concourse-examples/pipelines/hello-world.yml\n      - set_pipeline: time-triggered\n        file: concourse-examples/pipelines/time-triggered.yml\n</code></pre> <p>Commit and push the changes to github.</p> <pre><code>$ git add pipelines/reconfigure-pipelines.yml\n$ git commit -m \"add time-triggered pipeline\"\n$ git push\n</code></pre> <p>Once Concourse picks up the commit (may take up to a minute by default) you should see three pipelines on the dashboard. Now you never need to use <code>fly</code> to set pipelines!</p> <p>{{&lt; image src=\"/images/2020/08/three-pipelines.png\" alt=\"parent and child pipelines\" width=\"100%\" &gt;}}</p>"},{"location":"blog/2020-08-24-gitops-for-your-pipelines/#detour-a-future-alternative-of-setting-pipelines","title":"Detour: A Future Alternative of Setting Pipelines","text":"<p>In the future there will be a different solution to setting parent pipelines: no more parent pipelines! How will Concourse eliminate the current need to start with a parent pipeline in order to set child pipelines? The answer is RFC 32: Projects.</p> <p>If RFC 32 is implemented as currently described then you won't have to ever use <code>fly set-pipeline</code> to create pipelines, you'll simply create a Project , which involves pointing Concourse to a repo where you code lives. In the proposed <code>project.yml</code> you can then define all of your child pipelines with <code>set_pipeline</code> steps. No need to create a parent pipeline; the <code>project.yml</code> replaces the parent pipeline and no longer requires you to have a separate job that does <code>set_pipeline: self</code>.</p> <p>The RFC is still open and looking for feedback. Check out the PR and leave your thoughts for the community to discuss!</p> <p>Now let's get back on track and talk about the last step in a pipeline's lifecycle: archiving.</p>"},{"location":"blog/2020-08-24-gitops-for-your-pipelines/#automatically-archiving-pipelines","title":"Automatically Archiving Pipelines","text":"<p>Having Concourse automatically set pipelines for you is great but that only covers half of the lifecycle that a pipeline can go through. Some pipelines stay around forever and get continously updated. Other pipelines may only be around for a small amount of time and then be deleted or archived.</p> <p>Thanks to RFC #33 you can now archive pipelines and have Concourse * automatically archive* pipelines for you as well. You've been able to archive pipelines using <code>fly</code> since Concourse 6.1.0. Automatic archiving was added in 6.5.0.</p> <p>A pipeline will only be considered for automatic archiving if it was previously set by a <code>set_pipeline</code> step. It will be archived if one of the following is true:</p> <ul> <li>the <code>set_pipeline</code> step is removed from the job</li> <li>the job that was setting the child pipeline is deleted</li> <li>the parent pipeline is deleted or archived</li> </ul> <p>We can test this out with the parent pipeline we were just using. Let's remove the <code>hello-world</code> pipeline.</p> <pre><code>resources:\n  - name: concourse-examples\n    type: git\n    icon: github\n    source:\n      uri: git@github.com:USERNAME/examples.git\n\njobs:\n  - name: configure-self\n    plan:\n      - get: concourse-examples\n        trigger: true\n      - set_pipeline: reconfigure-pipelines\n        file: concourse-examples/pipelines/reconfigure-pipelines.yml\n  - name: configure-pipelines\n    plan:\n      - get: concourse-examples\n        trigger: true\n        passed: [ configure-self ]\n      - set_pipeline: time-triggered\n        file: concourse-examples/pipelines/time-triggered.yml\n</code></pre> <p>Commit and push the changes to github.</p> <pre><code>$ git add pipelines/reconfigure-pipelines.yml\n$ git commit -m \"remove hello-world pipeline\"\n$ git push\n</code></pre> <p>After a few seconds the pipeline should disappear from the dashboard (unless you toggle \"show archived\" on).</p> <p>With automatic archiving the entire lifecycle of your pipelines can now be managed with a git repo and a few commits.</p> <p>I suggest checking out the documentation for  <code>set_pipeline</code> to see all the other fields available for the step, like <code>team</code> and <code>vars</code>!</p>"},{"location":"blog/2020-08-24-gitops-for-your-pipelines/#the-parent-pipeline-template-tldr","title":"The Parent Pipeline Template (tl;dr)","text":"<pre><code>resources:\n  - name: ci\n    type: git\n    icon: github\n    source:\n      uri: git@github.com:USERNAME/repo-where-pipelines-live.git\n\njobs:\n  - name: configure-self\n    plan:\n      - get: ci\n        trigger: true\n      - set_pipeline: self\n        file: ci/path/to/parent-pipeline.yml\n  - name: configure-pipelines\n    plan:\n      - get: ci\n        trigger: true\n        passed: [ configure-self ]\n      - set_pipeline: some-pipeline\n        file: ci/path/to/some-pipeline.yml\n      - set_pipeline: another-pipeline\n        file: ci/path/to/another-pipeline.yml\n</code></pre>"},{"location":"blog/2020-12-29-running-docker-in-concourse/","title":"Running Docker in Concourse","text":"<p>So you want to run Docker in Concourse? Well this is the guide for you!</p> <p>Let' clarify what it is we want to do. We want to be able to run <code>docker-compose</code> inside a task in Concourse to bring up our application along side some other services (i.e. Redis, Postgres, MySQL, etc.).</p> <p>Thankfully this challenge has been solved by the community! There are a few \"Docker-in-Docker\" images designed to run in Concourse that are maintained by the community. Here's a short list made from a cursory search, in no particular order:</p> <ul> <li>github.com/meAmidos/dcind</li> <li>github.com/karlkfi/concourse-dcind</li> <li>github.com/fhivemind/concourse-dind</li> <li>github.com/taylorsilva/dcind</li> </ul> <p>You can also opt to build your own fork of the above images.</p> <p>All of the above repositories have their own example pipelines that you can use to get started. What follows are some bits of information that are useful to know when using these task images.</p>"},{"location":"blog/2020-12-29-running-docker-in-concourse/#privileged-tasks","title":"Privileged Tasks","text":"<p>Running Docker inside Concourse requires the task step to be privileged because Docker needs access to the hosts cgroup filesystem in order to create containers.</p> <p>You can verify this by looking at the bash scripts for each of the above images which all take inspiration from the docker-image resource. Read the  <code>sanitize_cgroups</code> function to see what exactly is being mounted from the host. (tldr: mount all cgroups as read-write)</p>"},{"location":"blog/2020-12-29-running-docker-in-concourse/#externalize-all-images","title":"Externalize All Images","text":"<p>You should avoid having Docker fetch any images from inside your task step where you are running <code>docker-compose</code>. You should externalize these as image resources if they're a dependency of your application (e.g. Postgres, MySQL).</p> <p>For the container image that contains your application you should have that built in a previous step or job. You can build and publish an image using the oci-build task.</p> <p>To ensure Docker doesn't try to fetch the images itself you can use  <code>docker load</code> and  <code>docker tag</code> to load your externalized images into Docker. meAmidos's has a great example pipeline that does exactly that.</p> <p>meAmidos also makes two great points about why you should externalize your image:</p> <ul> <li>If the image comes from a private repository, it is much easier to let Concourse pull it, and then pass it through to   the task.</li> <li>When the image is passed to the task, Concourse can often get the image from its cache.</li> </ul> <p>That's all you need to know to run Docker inside Concourse!</p>"},{"location":"blog/2025-01-06-concourse-2024-in-review/","title":"Concourse 2024 in Review","text":"<p>Hey Concourse community, it\u2019s been a while since a blog post was made. My name is Taylor Silva and I\u2019m the current lead maintainer of the project. I have fallen into this role for historical (was on the Concourse team at Pivotal starting in 2019) and personal reasons (still using Concourse at my day job). I really like using Concourse and I haven't found another tool that works as well as Concourse does, that's why I've stuck around.</p> <p>This post isn't about me though, it's about the project and what's happening with it. I'm going to talk about the last year of the project to recap where the project is at. Then I'll discuss where I see the project going over the next year.</p>"},{"location":"blog/2025-01-06-concourse-2024-in-review/#concourse-is-10-years-old","title":"Concourse is 10 Years Old!","text":"<p>The first commit for Concourse was made April 13th, 2014. That's over 10 years ago! Not sure how all that time flew by, but I guess it means Concourse is \"legacy software\", especially on the timescale of the internet. Concourse is well on its way to getting its pilot license, only four more years to go ( in Canada at least).</p> <p>Concourse has changed so much over the years. Overall I would say Concourse's development has been about slow and thoughtful improvements. I think it's paid off well so far for the project and will continue to do so in the future. There are a lot of exciting things we can still add onto Concourse, and I think there are a lot of existing things we can continue to refine and improve.</p>"},{"location":"blog/2025-01-06-concourse-2024-in-review/#v7120","title":"v7.12.0","text":"<p>2024 was a very slow on the release front. We had one Minor release, v7.12.0 and two earlier patch releases for v7.11.0.</p> <p>There was quite a bit of turbulence this year in Concourse's development. Broadcom has unfortunately scaled down the engineering time they dedicate towards Concourse. I picked up the slack mid-way through the year and got v7.12.0 pushed out. I was able to get Broadcom to reaffirm their commitment to providing the infrastructure behind ci.concourse-ci.org.</p> <p>There weren't many features added in v7.12.0. I think the biggest one that's worth shouting out is IPv6 support being added by Qjammer in #8801. This feature only works for the Containerd runtime. This feature is a big push in making sure Concourse is future-proofed as more people build out networks with IPv6 or dual-stack setups.</p>"},{"location":"blog/2025-01-06-concourse-2024-in-review/#project-leadership","title":"Project Leadership","text":"<p>Overall it kinda sucked how little development happened this year. Lots of folks where posting messages on GitHub and Discord, asking what was going on with the project. There's definitely been a leadership gap since Alex (vito) left Pivotal/VMware, and therefore the project. (Please don't message him about Concourse stuff, he's moved on to other things).</p> <p>Earlier this year I decided I would try to start filling that leadership gap. This was hard for me do while working a full-time job, but I was able to push out v7.12.0 using my evenings and weekends. It was rewarding but also very draining. I learned that I could not do my full-time job and properly steward Concourse at the same time. Concourse is too large of a project to manage in one's spare time.</p> <p>My reward for pushing out v7.12.0 is that I got people seeing me as the leader of the project. Yay! Goal accomplished! This lead to people in the community reaching out to me and one group came to me with an interesting offer, which I'll talk about more in a bit.</p>"},{"location":"blog/2025-01-06-concourse-2024-in-review/#concourse-in-2025","title":"Concourse in 2025","text":"<p>Where is Concourse going in 2025?</p> <p>Right now I'm planning to focus my efforts on refining what we have right now. There are some annoying bugs that I'd like to get fixed, and PR's I want to merge in. I've updated the milestones to reflect what I'm prioritizing: https://github.com/concourse/concourse/milestones</p> <p>There might also be a v8 release this year to bundle together some larger changes, like changing the default worker runtime to containerd. There's also a milestone for this.</p> <p>I am also going to declare Issue Bankruptcy. There are over 700 issues in the main concourse/concourse repo which is completely unmanageable. I want to get the number of open issues down to less than 100. I will keep more recent ones open and anything that's an obvious feature request or bug that could reasonably be done open as well. If I can't grok the issue within a few seconds of looking at it, it's getting closed.</p> <p>I also really want to get an ARM64 version of Concourse officially built. The work on this has already been started by Rui, I just need to pick up the thread from where he left off. I am very confident that we will have official ARM64 builds this year!</p> <p>Now you might be wondering:</p> <p>* Taylor, you just said you can't do your full-time job AND steward Concourse at the same time. How will you find time for all of this?!*</p> <p>My answer to that is: I'm not doing both. I quit my job. I'm doing Concourse full-time.</p> <p>Hooray, problem solved, everything is good now, Concourse has a full-time maintainer again!</p> <p>Okay, of course this problem is not fully solved. How am I going to afford to live?!</p>"},{"location":"blog/2025-01-06-concourse-2024-in-review/#a-concourse-company","title":"A \"Concourse\" Company","text":"<p>Some folks in the community reached out to me offering to try starting a company centered around Concourse. I of course said yes! Right now we are a small, dedicated team with a combined 10+ years of experience running Concourse clusters both small and large. The goal of this commercial venture is to advance and sustain then open-source Concourse project. We think Concourse is still the best CI/CD tool out there and that we can make a compelling commercial offering around it.</p> <p>~~If your company may be interested in what a \"Concourse\" company has to offer then please share your email with us here: LINK REMOVED~~</p> <p>May 2025 Update - If you're looking for someone to run a managed Concourse (SaaS) for you please reach out to the folks at CentralCI. If you're looking for commercial support for your on-premise Concourse please reach out to Pixel Air.</p> <p>One last thing I want to mention about this company we're building, because it's important to us, is that we are not taking any kind of VC funding. We are not creating a company that will be focused on \"growth at all costs\". Our focus will be on developing the product (Concourse) and using the product to solve CI/CD problems for customers, and finally catching up to the rest of the CI/CD world with a managed/SaaS version of Concourse. We want to build a sustainable business. We are not building a business to eventually sell; we are building a business that will advance and sustain Concourse and the entire community surrounding it.</p>"},{"location":"blog/2025-01-06-concourse-2024-in-review/#2025","title":"2025","text":"<p>So that's everything about the project right now. If you have any thoughts or comments you can leave them in the discussion thread for this blog post: https://github.com/concourse/concourse/discussions/9048</p> <p>Here's to a better 2025 \u2708\ufe0f\ud83e\udd42</p>"},{"location":"blog/2025-04-03-v7130-release-and-project-update/","title":"v7.13.0 Release and Project Update","text":"<p>First minor release of 2025! This release is FULL of bug fixes, performance improvements, and even a few new features. I'll start with a quick project update and then dive into the exciting things you can find in this release.</p>"},{"location":"blog/2025-04-03-v7130-release-and-project-update/#concourse-joins-the-cloud-foundry-foundation","title":"Concourse Joins the Cloud Foundry Foundation","text":"<p>Concourse officially joined the Cloud Foundry Foundation back in February. Derek Richard from Broadcom deserves the credit for making this happen. This was one of those tasks that so many folks have wanted to happen over the last few years, but through all the acquisitions (Pivotal -&gt; VMware -&gt; Broadcom) it kept getting started and stopped over and over and over. A HUGE thanks to Derek for finally making this happen.</p> <p>There are still some small stuff transitioning behind the scenes that Derek is taking care of. You can watch our monthly working group meetings for more details or chat with us on Discord if you have any questions about this.</p> <p>Now let's get into the details about 7.13.0!</p>"},{"location":"blog/2025-04-03-v7130-release-and-project-update/#v7130","title":"\ud83c\udf89 v7.13.0","text":"<p>Like any release, I recommend reading the release notes for all the details. I'm going to call out some of the big ticket items here though.</p> <p>Overall this release is light on new features, but is packed full of bug fixes, optimizations, and upgrades.</p>"},{"location":"blog/2025-04-03-v7130-release-and-project-update/#breaking-change-for-pgbouncer-users","title":"Breaking Change for PgBouncer users","text":"<p>We've migrated our database driver from lib/pq to jackc/pgx. <code>lib\\pq</code> has been in maintenance mode for years now and the majority of the Go community now uses <code>pgx</code> as the preferred Postgresql driver.</p> <p>This means we had to remove the <code>CONCOURSE_POSTGRES_BINARY_PARAMETERS</code> flag because it was exposing a feature specific to <code>lib/pq</code>. As far as I know, this flag was introduced and used by PgBouncer users. There is a similar flag that pgx exposes, but based on recent pgx discussions and the PgBouncer release notes, it seems there shouldn't be any issues for PgBouncer users of Concourse as long as you're using PgBouncer &gt;1.21.0. Concourse has never made any promises about compatibility with PgBouncer, but if PgBouncer users have any issues I'll gladly review a PR to improve the situation for you folks.</p> <p>Thankfully this is the only breaking change and I don't plan to make any new breaking changes outside of a Major version bump. The scope of this one seemed quite small which is why I decided to push this out in a Minor version bump.</p>"},{"location":"blog/2025-04-03-v7130-release-and-project-update/#new-features","title":"New Features","text":"<ul> <li>@A1kmm added <code>CONCOURSE_CONTAINERD_PRIVILEGED_MODE</code> to the <code>concourse worker</code> command.   This is useful for the security-conscious operator and limits the permissions that privileged containers can get while   still allowing tools like Podman and Buildah to work. You can also use this flag to disable the use of privileged   containers completely. PR 9017</li> <li>@analytically added a <code>background_filter</code> option to the <code>display</code> field, which   allows you to specify CSS filters on your pipeline   background images. Useful if you're tired of grey backgrounds and want more colour in your pipelines   \ud83c\udf08 PR 9117</li> <li>@IvanChalukov added the <code>--team</code> flag to the <code>containers</code> and   <code>clear-resource-cache</code> fly commands.   PRs 9106, 9107</li> </ul> <p>Like I said, this release is light on new features. Most of the work went into fixing long-standing bugs and updating the code base.</p>"},{"location":"blog/2025-04-03-v7130-release-and-project-update/#uuid-collisions","title":"\ud83d\udcab UUID Collisions?!","text":"<p>If you search \"what are the chances of a UUID collision?\" in your preferred search engine, you'll find many comments stating \"You're more likely to be killed by a gamma ray than get a UUID collision\", usually with a caveat that you're generating v4 UUID's. Well, I have another caveat to add to that statement: the library you're using to generate UUID' s implements RFC 9562 correctly!</p> <p>If you want one reason to upgrade to 7.13.0, I'd say this is why. All versions prior to this release will occasionally have UUID collisions when creating containers and volumes. I'm not sure how often this happens, it could be every 1,000 or 100,000,000, calls to <code>uuid.New()</code>, but it definitely does happen. On a low-usage cluster we only saw it once. The error we saw was this one:</p> <pre><code>container \"bba06975-46f6-4bbe-73f5-9e39a869719a\": already exists\n</code></pre> <p>The UUID library we were using was the most popular library at the time. Concourse has been using this library from the very beginning. I'm sure it's been the source of a handful of weird \"ghost in the machine\" type of errors over the years. We can now lay this ghost to rest! We are now using the github.com/google/uuid library instead.</p> <p>PR 9083 for full details.</p>"},{"location":"blog/2025-04-03-v7130-release-and-project-update/#fly-login-with-chrome","title":"Fly Login With Chrome","text":"<p>If you use a Chromium web browser and have tried to <code>fly login</code> you've definitely run into this bug where Chrome says \" your token could not be sent to fly\", but saw that it was sent to fly. What gives? Preflight requests is what gives! You write your web app to send one HTTP request and SURPRISE, Chrome sends a bonus second request first!</p> <p>The <code>fly</code> CLI will now handle this \u2b50special bonus\u2b50 preflight request from Chrome, give Chrome the thumbs up, and then wait until the real request from Concourse actually comes through. You'll now see a \"login successful!\" message when you <code>fly login</code> now.</p> <p>PR 9051 for full details.</p> <p>There is of course another browser bug that's been annoying users for the last few years...</p>"},{"location":"blog/2025-04-03-v7130-release-and-project-update/#preserve-existing-browser-session","title":"Preserve Existing Browser Session","text":"<p>After you did that janky <code>fly login</code> with Chrome, you'd then run into another issue. You had a tab open and logged into Concourse before logging in with <code>fly</code>. Now when you go back to that tab and click around in the UI you get told to login AGAIN. What gives?!</p> <p>@IvanChalukov dove into this issue and fixed it. I can only imagine the amount of hours he spent debugging this issue. The TL;DR is that a CSRF token got wrapped in quotes and the quotes were then considered part of the token, resulting in an invalid CSRF check server-side. Thank you Ivan for fixing this mild but annoying bug. Many browser sessions will now be saved! \ud83d\ude4f</p> <p>PR 9109 for full details.</p>"},{"location":"blog/2025-04-03-v7130-release-and-project-update/#everything-else","title":"Everything Else","text":"<p>Those are the big bugs that I think most people will be excited to see fixed. There's also been a lot of chore-level changes as well. Concourse is quite a big application and has a lot of dependencies. I think we've done a good job of dusting things off and upgrading things. Here's a quick rundown of the other exciting things in this release:</p> <ul> <li>This release is built with Go 1.24, gaining the performance improvements from that   release, which boasts a 2-3% decrease in CPU</li> <li>@analytically upgraded a bunch of stuff in the web frontend:<ul> <li>Upgraded Graphviz from v2.47.1 to v12.2.1</li> <li>Upgraded D3js from v3.5.5 to v7</li> <li>Updated Material Design Icons from v5.0.45 to 7.4.47, adding 2,350 new icons to use in your pipelines!</li> <li>Reduced the size of all SVG's using svgo</li> <li>Replaced the unmaintained NYTimes/gziphandler   with klauspost/compress, giving a performance boost to all HTTP   endpoints.</li> </ul> </li> <li>@IvanChalukov and @Kump3r upgraded our fork of Dex to   use the CF v3 API, ensuring users of CF Auth aren't locked out of their Concourse when the CF v2 API goes away.</li> <li>The experimental warning seen during the <code>set_pipeline</code> step is now gone. It's interface and current behaviour are   considered stable.</li> <li>Modernization of the Go codebase, mostly removing usage of deprecated Go functions and other similar improvements. * The registry-image, s3, and semver resources have been updated to use v2 of the AWS Go SDK. While making this change I've also changed the authentication behaviour when these resources are interacting with AWS. They will now use the default authentication chain that the AWS SDK uses. This means these resource types can now use the Concourse Worker's IAM role and static credentials are no longer required to use these resources.</li> <li>@mariash enabled cgroupv2 support for the Guardian runtime, enabling the use of the   Guardian runtime on newer kernel versions.</li> <li>I updated Concourse's seccomp profile to include newer syscalls, bringing it inline with the default seccomp profile   from Docker and Containerd.</li> <li>Shout-out to @aliculPix4D and the folks at Pix4D for testing and finding some last   minute critical bugs before the release went out.</li> <li>Shout-out to @IvanChalukov and @Kump3r from SAP for   their help testing Concourse on Bosh.</li> </ul> <p>Again, read the release notes for everything that's been fixed or improved.</p> <p>Thank you everyone that contributed to this release. If you find any bugs, open an issue on GitHub.</p> <ul> <li>GitHub Release</li> <li>Docker Hub Image</li> <li>Helm Chart</li> <li>Bosh Release</li> </ul>"},{"location":"blog/2025-04-03-v7130-release-and-project-update/#one-more-thing","title":"\ud83c\udf4e One More Thing...","text":"<p>Myself and my co-founders are happy to officially launch CentralCI, a company providing managed Concourse clusters. We run Concourse for you, owning the operational overhead of running Concourse. We've put a lot of effort into solving some common pains that operators of Concourse have, allowing you to focus on writing your pipelines.</p> <p>You can learn more about CentralCI in our introduction blog post.</p>"},{"location":"blog/2025-05-08-may-2025-project-update/","title":"May 2025 Project Update","text":"<p>It's the May 2025 project update! I'm going to try and do this at a somewhat regular cadence. Once a month seems like a good idea, though I may skip a month here and there if there's nothing interesting to write about.</p>"},{"location":"blog/2025-05-08-may-2025-project-update/#administrative","title":"Administrative","text":"<p>I've opened up a discussion thread about the breaking changes currently planned to go into v8 of Concourse. Nothing is set in stone, all feedback is welcome! Likely the most disruptive one so far is to finally enforce the valid identifiers instead of warning when they're detected. See the link for full details and reasoning.</p> <p>The Concourse Working Group has been meeting once per month. You can view past meetings on YouTube and view meeting notes here.</p> <p>The last thing I want to mention is that I decided to step away from CentralCI. They are still operating and working at making a fantastic managed Concourse that you can go and buy right now!!! If you want Concourse but don't want the overhead of running it, I highly recommend reaching out to them. I will be focusing my time on the community and those currently running Concourse on-premise.</p> <p>If you want to support my work stewarding Concourse you can sponsor me on GitHub. Thank you to those who already found the page and are sponsoring me \ud83d\udc99</p>"},{"location":"blog/2025-05-08-may-2025-project-update/#roadmap","title":"Roadmap","text":"<p>I have two project boards that I'm using to track work right now.</p> <ul> <li>Roadmap</li> <li>Pull Requests</li> </ul> <p>The Roadmap board is tracking work that I am actively working on and planning to work on next. Right now the ARM build stuff is taking up most of my time. I have to update some of the tooling we use to build images (the registry-image resource and oci-build task) to make it easier to build and push multi-arch images. I'm also taking the time to clean up a bunch of stuff in the concourse/ci repo. It's a lot of work but it's slowly happening. I see no major roadblocks with this work right now.</p> <p>The Pull Requests board is a place for me to see all open pull requests across all repositories. I've added most open PR's to this board. If you see your PR on this board, that means I'm aware of it and I'll get to it eventually.</p>"},{"location":"blog/2025-05-08-may-2025-project-update/#s3-resource-type","title":"S3 Resource Type","text":"<p>I made a few breaking changes with the S3 resource type that came out with 7.13. The v2.0.0 release notes go over those. I did not hit the mark with these changes sadly. Users found that they couldn't pull down items from public S3 buckets. Resources pulling from public buckets were using no credentials previously, but with v2 they now tried to use any credentials the default SDK authentication chain could find, which usually ended up being an EC2 instance profile. I then made a PR to fix this, but then that made it, again, impossible for users to use the EC2 instance profile. Fritz then made a PR that adds a new flag to the S3 resource, <code>enable_aws_creds_provider</code>, which allows the behaviour introduced in v2 to happen if you want it to.</p> <p>I published a new version of the resource type with this PR, v2.2.0. If you want to use that in your pipelines you can do so with this snippet:</p> <pre><code>resource_types:\n  - name: s3\n    type: registry-image\n    source:\n      repository: docker.io/concourse/s3-resource\n      tag: 2.2.0\n</code></pre> <p>That will override the S3 resource type found on the worker for pipelines that you add this to. Apologies again for the blunder and thank you to those who helped get the resource back in a state that works for everyone.</p>"},{"location":"blog/2025-05-08-may-2025-project-update/#vs-code-extension","title":"VS Code Extension","text":"<p>Shouting this out as it looks handy. A user made a VS code extension for previewing Concourse pipelines. You can see their post where that shared that here: https://github.com/concourse/concourse/discussions/9193</p>"},{"location":"blog/2025-05-08-may-2025-project-update/#cloud-foundry-day-north-america","title":"Cloud Foundry Day North America","text":"<p>Cloud Foundry Day is happening next week on May 14th. Derek (my co-lead of the Concourse working group) has a talk about Concourse's journey into the Cloud Foundry foundation. Make sure you check it out and say hi to Derek if you'll be there.</p>"},{"location":"blog/2025-05-08-may-2025-project-update/#thats-all-folks","title":"That's All Folks!","text":"<p>And that's the update! If anyone wants to chat I'm always hanging around on discord. You can also reach me at <code>dev</code> at <code>taydev.net</code>.</p>"},{"location":"blog/2025-08-11-v7140---the-first-arm-build-of-concourse/","title":"v7.14.0 - The First ARM Build of Concourse","text":"<p>v7.14.0 is out and with it also comes the first ARM build of Concourse! There were a lot of behind the scenes changes that were required to make this happen, so let's dive into everything that's in this release.</p>"},{"location":"blog/2025-08-11-v7140---the-first-arm-build-of-concourse/#pipeline-identity-tokens","title":"\ud83e\udec6Pipeline Identity Tokens","text":"<p>I figure we'll start with the new features, because that's always fun. #9035 added a whole new <code>var_source</code> called \"Identity Tokens\". These are JWT's that Concourse can generate for you and that you can then use to authenticate to third-party systems that support \"identity federation\", such as Vault, AWS, and Azure.</p> <p>@dbaumgarten did everything here: wrote the RFC, made the PR, AND wrote a comperhensive set of docs with examples on how to use it. Huge thank you to him for bringing this feature to the community. I think a lot of users will find it useful and help them migrate away from using static credentials.</p>"},{"location":"blog/2025-08-11-v7140---the-first-arm-build-of-concourse/#the-road-to-arm","title":"\ud83e\uddbe The Road to ARM","text":"<p>This has been a longgggggg time coming. There was a community fork of Concourse out there for a while, specifically for building an ARM version of Concourse. I remember when Ciro, a co-worker from Pivotal, did a little exploration running Concourse on his Raspberry Pi. He showed it was possible, though the road wasn't completely smooth.</p> <p>Thankfully, the container ecosystem has continued to develop and mature these last few years while Concourse was in limbo. More workloads are running on ARM now and as a result more of our tools and libraries just work when trying to do cross-compilation or ARM stuff. The big win for us was Docker making multi-platform builds a thing. This saved us from having to manually build an ARM Concourse worker, like Ciro did, just so we could build ARM images of Concourse and all the resource-types that we ship with Concourse.</p> <p>At this point, all we needed to do was update our pipelines to support building and releasing ARM versions of everything!</p> <p>The journey went like this:</p> <ul> <li>Update all 12 base resource-types to use   Wolfi as their base image because the   previous base image did not have an ARM variant. The <code>concourse/concourse</code>   image also uses Wolfi as its base image now.</li> <li>Update the OCI Build task and   Registry Image   resource to better   support multi-platform images and workflows.</li> <li>Update the pipeline used to build, test, and release the resource-types, and   release ARM versions of all the resource-types.</li> <li>Update the main Concourse pipeline and the release pipeline to build and test the ARM variant of Concourse.</li> <li>Added a <code>/download-fly</code>   page to support all variants of <code>fly</code>, replacing the three static download   links previously located in the footer</li> </ul> <p>Each of those steps took many hours to complete. I had to touch every repository we own and got to do a little clean-up everywhere.</p> <p>One nice side-effect of moving to Wolfi for the base image is that the size of all the container images we produce dropped. Some by a lot, some by just a little. For example, the Git resource went from 218MB to 37MB, a massive drop in size! Some other resources dropped by only a few MB's. The size drops weren't 100% due to Wolfi. I took some extra time to ensure we were only adding what was necessary for each resource-type to function.</p> <p>Collectively, this results in us shipping a much smaller <code>concourse/concourse</code> image. v7.14.0 clocks in at 928MB (x86_64) and 883MB (ARM), down from 1.41GB (x86_64). That's a 34% drop in size for the x86_64 image and 37% for the ARM image. The ARM-based images are also always smaller, so you save a bit more disk space if you go for a fully ARM-based Concourse deployment.</p> <p>Now there is finally an ARM version of Concourse and fly that folks can run on their Raspberry Pi's, M-Series macs, and ARM cloud servers. I'm excited to see what Concourse will end up running on now \ud83c\udf89</p>"},{"location":"blog/2025-08-11-v7140---the-first-arm-build-of-concourse/#cloud-foundry-foundation","title":"\u2601\ufe0f Cloud Foundry Foundation","text":"<p>As a project member of the Cloud Foundry Foundation (CFF), Concourse has had two tasks assigned to it.</p> <ol> <li>Reduce project cost: We've reduced project costs by    40%,    leaving us in a decent state. There's some smaller things we can tackle, but    urgency from CFF is gone.</li> <li>Running a shared Concourse    cluster for CFF member    projects. This is related to the CFF's wider goal of reducing costs across    all projects. This is something myself and Derek plan to work on over the    next few months.</li> </ol>"},{"location":"blog/2025-08-11-v7140---the-first-arm-build-of-concourse/#whats-next","title":"\ud83e\udded What's Next","text":"<p>My goal with Concourse right now is to continue to refine and improve what we currently have. There are plenty of little bugs littered throughout the code base that I want to resolve to help make Concourse feel even more stable and reliable than it currently is.</p> <p>I try to keep this GitHub project board up to date with what I plan to work on. Folks are free to look at the board, and if it isn't in the \"In Progress\" column, feel free to pick up the issue and work on it.</p> <p>I'll be putting a lot of my attention to the breaking changes planned for v8. See this discussion post for details and leave any thoughts or comments there.</p> <p>That's all I have for everyone now. See everyone over on Discord or GitHub Discussions. Enjoy the new release!</p>"},{"location":"docs/","title":"Docs","text":"<p>Concourse is a pipeline-based continuous thing-doer.</p> <p>The term \"pipeline\" has become widespread in CI discussions, so being precise about what this means is important; Concourse's pipelines differ significantly from others.</p> <p>Pipelines are built around Resources, which represent all external state, and Jobs, which interact with them. Concourse pipelines function as dependency flows, similar to distributed Makefiles. Pipelines are designed to be self-contained to minimize server-wide configuration. Maximizing portability also reduces risk, making it simpler for projects to recover from CI disruptions.</p> <p>Resources like the git resource and s3 resource are used to express source code, dependencies, deployments, and other external states. This interface also models more abstract concepts like scheduled or interval triggers, via the time resource.</p> <p>Resource Types are defined within the pipeline itself, making the pipelines more self-sufficient while keeping Concourse lean and versatile without needing a complex plugin system.</p> <p>Jobs are sequences of get, put, and task steps to execute. These steps determine the job's inputs and outputs. Jobs are designed to be idempotent and loosely coupled, allowing the pipeline to evolve with project needs without requiring engineers to maintain too much context simultaneously.</p> <p>Everything in Concourse runs in a container. Instead of modifying workers to install build tools, Tasks define their own container image (typically using Docker images via the registry-image resource).</p>"},{"location":"docs/#what","title":"...What?","text":"<p>Concourse admittedly has a steeper learning curve initially, and depending on your background it might seem like a lot to grasp. A key goal of this project is for that curve to flatten out shortly after and lead to greater productivity and reduced stress over time.</p> <p>If this all sounds confusing, that's OK - you may want to simply continue onward, start experimenting a bit, and use the above as a quick reference of the \"big picture\" as your understanding develops.</p>"},{"location":"docs/config-basics/","title":"Config Basics","text":"<p>Concourse configuration for things like Pipelines and Tasks is done through declarative YAML files.</p> <p>Concourse configuration supports basic variable substitution by way of <code>((vars))</code>. There is no built-in support for fancier templating constructs, e.g. loops and conditionals; users are free to use whatever templating system they like.</p>"},{"location":"docs/config-basics/#intro-to-yaml","title":"Intro to YAML","text":"<p>YAML is a human-friendly syntax for writing structured documents. You can think of it as JSON without the sharp edges.</p> <p>If you want a slightly more in-depth overview of YAML compared to what we provide below, we recommend reading Learn YAML in Y Minutes.</p> <p>Here's a quick example demonstrating common YAML syntax:</p> <pre><code># commented lines are prefixed with the '#' character\n\n# strings\nquoted_string: \"bar\"\nunquoted_string: hello world!\nmultiline_string: |\n  hello, world!\n  this is one big string with a trailing linebreak!\n\n# arrays\narray: [ hello, world ]\nmultiline_array:\n  - hello\n  - world\n\n# objects\nobject: { one: uno, two: dos }\nmultiline_object:\n  one: uno\n  two: dos\n\n# boolean values\nbooleans: [ true, false ]\n\n# numeric values\nnumeric: [ 1234, 12.34 ]\n</code></pre>"},{"location":"docs/config-basics/#yaml-tips-tricks","title":"YAML Tips &amp; Tricks","text":"<p>YAML anchor syntax can be used to avoid repetition within configuration.</p> <p>For example, the following YAML document...:</p> <pre><code>large_value: &amp;my_anchor\n  do_the_thing: true\n  with_these_values: [ 1, 2, 3 ]\n\nduplicate_value: *my_anchor\n</code></pre> <p>...is exactly equivalent to:</p> <pre><code>large_value:\n  do_the_thing: true\n  with_these_values: [ 1, 2, 3 ]\n\nduplicate_value:\n  do_the_thing: true\n  with_these_values: [ 1, 2, 3 ]\n</code></pre> <p>If you find yourself repeating configuration throughout your pipeline, it may be a sign that Concourse is missing some kind of abstraction to make your pipeline less verbose. If you have the time and are interested in helping out with Concourse's design, feedback of this sort is welcome in GitHub Discussions!</p> <p>We do want to avoid implementing an entire YAML templating engine within Concourse. We encourage you to reach for your favourite templating tool if you're eager about DRYing up your pipelines as much as possible.</p>"},{"location":"docs/config-basics/#yaml-quirks","title":"YAML Quirks","text":"<p>YAML has some weird parts. For example, all the following terms are acceptable boolean values: <code>true</code>, <code>false</code>, <code>yes</code>, <code>no</code>, <code>on</code>, <code>off</code>.</p> <p>YAML is also whitespace-sensitive. For the most part, this is really handy because it keeps you from having to count curly-braces in deeply nested parts of configuration such as  <code>job.plan</code>. Sometimes, though, it can be hard to keep track of the correct indentation level.</p>"},{"location":"docs/config-basics/#basic-schemas","title":"Basic Schemas","text":"<p>Throughout the Concourse documentation you will come across schema definitions for each API.</p> <p>The following are basic schema definitions that the other schemas refer to. You can probably skip past this and just make assumptions along the way; this is just here for completeness!</p>"},{"location":"docs/config-basics/#number-schema","title":"<code>number</code> schema","text":"<p>Any integer, i.e. <code>1000</code>.</p>"},{"location":"docs/config-basics/#string-schema","title":"<code>string</code> schema","text":"<p>An arbitrary string value with no content restrictions.</p>"},{"location":"docs/config-basics/#config-schema","title":"<code>config</code> schema","text":"<p>An arbitrary object representing configuration that is not directly interpreted by Concourse - typically given to a resource type.</p> <pre><code>uri: https://github.com/vito/booklit\nbranch: master\n</code></pre> <p>All object keys must be strings, preferably <code>snake_cased</code>.</p>"},{"location":"docs/config-basics/#vars-schema","title":"<code>vars</code> schema","text":"<p>An arbitrary object representing key-value definitions for <code>((vars))</code>.</p> <p>As with <code>config</code> schema, all object keys must be strings, preferably <code>snake_cased</code>.</p>"},{"location":"docs/config-basics/#env-vars-schema","title":"<code>env-vars</code> schema","text":"<p>An object containing string keys and string values. Each pair represents an environment variable to set to the given value.</p> <pre><code>SOME_SIMPLE_VAR: simple-var\nSOME_LONG_VAR: |\n  This is an example of using YAML multi-line string syntax to set a very\n  long environment variable value.\nSOME_NUMERIC_VALUE: \"1\"\n</code></pre> <p>Note that in the last example we took special care to quote the number.</p>"},{"location":"docs/config-basics/#boolean-schema","title":"<code>boolean</code> schema","text":"<p><code>true</code> or <code>false</code>.</p> <p>YAML also supports the alias <code>yes</code>, <code>no</code>, <code>on</code>, or <code>off</code>, but ... please don't.</p>"},{"location":"docs/config-basics/#value-schema","title":"<code>value</code> schema","text":"<p>An arbitrary YAML value. It may be a <code>number</code> schema, <code>string</code> schema,  <code>boolean</code> schema, <code>config</code> schema, or a <code>[value</code> schema<code>]</code>.</p> <pre><code>values:\n  - 123\n  - bar\n  - true\n  - key1: abc\n    key2: def\n  - [ hello, world ]\n</code></pre>"},{"location":"docs/config-basics/#identifier-schema","title":"<code>identifier</code> schema","text":"<p>An identifier is a string value. The following defines the allowed character set for an identifier:</p> <ul> <li>Unicode lowercase letters, while still supporting languages that don't have any casing (e.g. Japanese).</li> <li>Decimal numbers.</li> <li>Hyphens <code>-</code> and underscores <code>_</code> as word separators.</li> <li>Periods <code>.</code> in order to support domain names and version numbers.</li> </ul> <p>The validation rule is as follows:</p> <pre><code>^[\\p{Ll}\\p{Lt}\\p{Lm}\\p{Lo}\\d][\\p{Ll}\\p{Lt}\\p{Lm}\\p{Lo}\\d\\-_.]*$\n</code></pre> <p>Where all identifier must start with a Unicode lowercase letter or number, followed by any number of allowed characters.</p> <p>Currently, the validation will only show as warnings. For the sake of future-proofing, you may want to conform to it.</p>"},{"location":"docs/config-basics/#dir-path-schema","title":"<code>dir-path</code> schema","text":"<p>A string value specifying a (typically relative) path of a directory.</p>"},{"location":"docs/config-basics/#file-path-schema","title":"<code>file-path</code> schema","text":"<p>A string value specifying a (typically relative) path of a file.</p>"},{"location":"docs/config-basics/#duration-schema","title":"<code>duration</code> schema","text":"<p>A string value in Go <code>time.ParseDuration</code> format. <code>1h</code> for one hour, <code>5m</code> for 5 minutes.</p>"},{"location":"docs/config-basics/#version-schema","title":"<code>version</code> schema","text":"<p>An object with string keys and string values.</p> <p>The following is an array of versions:</p> <pre><code>- { \"ref\": \"33042e15e930b6786fc9b0a9ea5dec78689c5e4b\" }\n- ref: v1.2.0,\n  sha: 33042e15e930b6786fc9b0a9ea5dec78689c5e4b\n- foo: \"0\"\n</code></pre> <p>Note that in the last example we took special care to quote the number.</p> <p>In many scenarios where a version can be specified, e.g. <code>get</code> step <code>version</code>, only a subset of the full set of fields is necessary. The latest version matching the fields specified will be chosen.</p>"},{"location":"docs/fly/","title":"The <code>fly</code> CLI","text":"<p>The first step to getting started with Concourse is to install the <code>fly</code> CLI tool. You can download <code>fly</code> from any Concourse installation by clicking the download link in the bottom-right corner of the web UI.</p> <p>Throughout the Concourse documentation we'll stick to the long-form name of every command and flag. Once you've learned what the commands do, you may want to consult <code>fly -h</code> to learn the short forms.</p>"},{"location":"docs/fly/#fly-login","title":"<code>fly login</code>","text":"<p>The first thing you'll want to do is authenticate with your target. This is done with the <code>fly login</code> command. This is also useful to save targets under a more convenient alias, so you don't have to type out the URL all the time:</p> <p>The <code>login</code> command serves double duty: it authenticates with a given endpoint, and saves it under a more convenient name. The name and token are stored in <code>~/.flyrc</code> (though you shouldn't really edit the file manually).</p> <p>Concourse deployments can be occupied by multiple teams. To specify the team to which to log in, specify the <code>--team-name</code> or <code>-n</code> flag. If not specified, this defaults to the  <code>main</code> team.</p> <p>So, to log in to a team <code>my-team</code> an endpoint served at <code>https://ci.example.com</code> and save it as the more convenient name <code>example</code>, you would run:</p> <pre><code>fly --target example login --team-name my-team \\\n    --concourse-url https://ci.example.com\n</code></pre> <p>The <code>login</code> command will see which authentication methods are available for the specified team and prompt you to choose one. For basic auth, it will ask your username and password and use them to acquire a token. For OAuth, it will give you a link to click, and after you've gone through the OAuth flow it will print an OAuth token on the page that you can then copy and paste into the prompt.</p> <p>Note that if no authentication methods are configured, <code>fly</code> will acquire a token without any prompting. You can then use the alias like normal.</p> <p>In any case, a token is saved in your <code>~/.flyrc</code>, which will expire after one day.</p> <p>If your Concourse uses SSL but does not have a certificate signed by a trusted CA, you can use the <code>--ca-cert</code> flag so that <code>fly</code> can trust the connection, like so:</p> <pre><code>fly -t example login -c https://ci.example.com --ca-cert ./ca.crt\n</code></pre> <p>This will read the value out of the file <code>./ca.crt</code> and save it into <code>~/.flyrc</code> so you don't have to pass it on every <code>login</code> invocation.</p> <p>If your Concourse instance is protected by a proxy server requiring client certificates, you can use <code>--client-cert</code> and <code>--client-key</code> to point to where your certificate is stored. These paths will be stored in <code>.flyrc</code> and the certificate will by attached to every request made to that target.</p> <pre><code>fly -t example login -c https://ci-example.com \\\n    --client-cert ./client.pem \\\n    --client-key ./client.key\n</code></pre> <p>After you've logged in you can use <code>--target example</code> (or <code>-t example</code> for short) to run a command against the saved target <code>example</code>. For example, <code>fly -t example builds</code> will list the last few builds on the <code>example</code> Concourse instance.</p> <p>The <code>-t</code> flag is intentionally stateless and must be explicitly added to each command. This reduces the risk of accidentally running a command against the wrong environment when you have multiple targets defined.</p>"},{"location":"docs/fly/#fly-targets","title":"<code>fly targets</code>","text":"<p>To see what targets are currently known to <code>fly</code>, run:</p> <pre><code>fly targets\n</code></pre> <p>This will show each target's name, URL, and when its token expires.</p>"},{"location":"docs/fly/#fly-status","title":"<code>fly status</code>","text":"<p>To check your current authentication status with a given target, run:</p> <pre><code>fly -t example status\n</code></pre> <p>This will let you know if the token has expired.</p>"},{"location":"docs/fly/#fly-userinfo","title":"<code>fly userinfo</code>","text":"<p>To check what user you're logged in as, as well as which teams you are currently authenticated to and which roles within each team you have, run:</p> <pre><code>fly -t example userinfo\n</code></pre>"},{"location":"docs/fly/#fly-logout","title":"<code>fly logout</code>","text":"<p>To clear out your token for a given target, run:</p> <pre><code>fly -t example logout\n</code></pre> <p>To clear out your token for all targets, run:</p> <pre><code>fly logout -a\n</code></pre> <p>Note</p> <p>These two variations are mutually exclusive. If the target parameter <code>-t</code> and all parameter <code>-a</code> are both  specified, an error will occur.</p>"},{"location":"docs/fly/#fly-edit-target","title":"<code>fly edit-target</code>","text":"<p>To modify a target's name, team, or URL, run:</p> <pre><code>fly -t example edit-target \\\n    --target-name new-name \\\n    --concourse-url https://ci.example.com \\\n    --team-name my-team\n</code></pre> <p>Each flag is optional - only the specified flags will be changed.</p>"},{"location":"docs/fly/#fly-delete-target","title":"<code>fly delete-target</code>","text":"<p>When logging out just isn't enough, a target can be completely removed from <code>~/.flyrc</code> by running:</p> <pre><code>fly -t example delete-target\n</code></pre> <p>To delete all targets, run:</p> <pre><code>fly delete-target -a\n</code></pre> <p>Note</p> <p>These two variations are mutually exclusive. If the target parameter <code>-t</code> and all parameter <code>-a</code> are both  specified, an error will occur.</p>"},{"location":"docs/fly/#fly-sync","title":"<code>fly sync</code>","text":"<p>Occasionally we add additional features to <code>fly</code> or make changes to the communication between it and Concourse's API server. To make sure you're running the latest and greatest version that works with the Concourse you are targeting we provide a command called <code>sync</code> that will update your local <code>fly</code>. It can be used like so:</p> <pre><code>fly -t example sync\n</code></pre> <p>The <code>fly</code> command will also warn you if it notices that your CLI version is out of sync with the server.</p>"},{"location":"docs/fly/#fly-completion","title":"<code>fly completion</code>","text":"<p>Fly can output autocomplete configuration for some shells. For example, you can add an entry to your <code>.bashrc</code> like this:</p> <pre><code>source &lt;(fly completion --shell bash)\n</code></pre> <p>or, using the <code>/etc/bash_completion.d</code> directory:</p> <pre><code>fly completion --shell bash &gt; /etc/bash_completion.d/fly\n</code></pre> <p>Note that, unlike other fly commands, this command does not interact with a remote server so you do not need to provide the <code>-t</code> or <code>--target</code> flag.</p>"},{"location":"docs/jobs/","title":"Jobs","text":""},{"location":"docs/jobs/#job-schema","title":"<code>job</code> schema","text":""},{"location":"docs/vars/","title":"Vars","text":""},{"location":"docs/vars/#var-syntax","title":"<code>((var))</code> syntax","text":""},{"location":"docs/vars/#the-var-source","title":"The \"<code>.</code>\" var source","text":""},{"location":"docs/vars/#interpolation","title":"Interpolation","text":""},{"location":"docs/vars/#static-vars","title":"Static vars","text":""},{"location":"docs/vars/#dynamic-vars","title":"Dynamic vars","text":""},{"location":"docs/vars/#across-step-dynamic-vars","title":"Across Step &amp; Dynamic Vars","text":""},{"location":"docs/vars/#var-sources-experimental","title":"Var sources (experimental)","text":""},{"location":"docs/vars/#the-cluster-wide-credential-manager","title":"The cluster-wide credential manager","text":""},{"location":"docs/auth-and-teams/","title":"Auth & Teams","text":"<p>A single Concourse installation can accommodate many projects and users.</p> <p>Pipelines, builds, and all other user data are owned by teams. A team is just a conceptual owner and a separate namespace, tied to an authorization config. For example, a team may authorize all members of the <code>concourse</code> GitHub organization to be a member.</p> <p>When a user authenticates, each team's authorization config is checked against the user to determine which role, if any, to grant for the team. This information is then stored in the user's token to determine access control for future requests.</p>"},{"location":"docs/auth-and-teams/caveats/","title":"Security Caveats","text":"<p>At present, teams only provide trusted multi-tenancy. This means it should be used for cases where you know and trust who you're allowing access into your Concourse cluster.</p> <p>There are a few reasons it'd be a bad idea to do otherwise:</p> <ul> <li>Any team can run builds with <code>task</code>   step <code>privileged</code> tasks. A bad actor in the mix   could easily use this to harm your workers and your cluster. You   can lock down privileged mode if you   use the containerd runtime and avoid this issue all together.</li> <li>There are no networking restrictions in place, and traffic to and from the worker's Garden and Baggageclaim endpoints   is currently unencrypted and unauthorized. Anyone could run a task that does horrible things to your worker's   containers, possibly stealing sensitive information.       This can be remedied with configuration specified on Garden to restrict access to the internal network, but this is   not detailed in our docs, and we'll probably want to find a better answer than configuration in the future.       You could put firewall rules in place between workers to mitigate this issue as well.</li> </ul>"},{"location":"docs/auth-and-teams/exposing/","title":"Pipeline & Build Visibility","text":"<p>Every newly configured pipeline is hidden to anyone but the pipeline's team. To make a pipeline publicly viewable, both by other teams and unauthenticated users, see  <code>fly expose-pipeline</code>.</p> <p>Even with a pipeline exposed, all build logs are hidden by default. This is because CI jobs are prone to leaking credentials and other ... unsavory information. After you've determined that a job's builds should be safe for public consumption, you can set <code>public: true</code> on the job in your pipeline.</p>"},{"location":"docs/auth-and-teams/main-team/","title":"The <code>main</code> team","text":"<p>Out of the box, Concourse comes with a single team called <code>main</code>.</p> <p>The <code>main</code> team is an admin team, meaning members (specifically, users with the owner role) can create and update other teams. Currently there is no way to promote a team to become an admin team, so <code>main</code> is a special-case.</p> <p>The <code>main</code> team is different in that all flags normally passed to  <code>fly set-team</code> are instead passed to the <code>concourse web</code> command, prefixed with <code>--main-team-</code>. The values set in these flags take effect whenever the <code>web</code> node starts up. This is done so that you can't get locked out.</p> <p>To learn how to configure your <code>main</code> team, continue on to the appropriate section for your auth provider of choice under Configuring Auth.</p>"},{"location":"docs/auth-and-teams/managing-teams/","title":"Managing Teams","text":""},{"location":"docs/auth-and-teams/managing-teams/#fly-set-team","title":"<code>fly set-team</code>","text":"<p>Once you've logged in as the <code>main</code> team with <code>fly</code>, you can run  <code>fly set-team</code> to create or update other teams. Users with a  <code>owner</code> role can also update their own configuration with the same command.</p> <p>For example, to create a new team that authorizes the local <code>foo</code> user, you would run:</p> <pre><code>fly -t example set-team --team-name my-team --local-user foo\n</code></pre> <p>Note that each time <code>set-team</code> is run, the team's authorization config is set as a whole - it is not a stateful operation.</p> <p>There are many different ways to configure team auth; see Configuring Auth for more information.</p> <p>Once the team has been created, you can use <code>fly login</code> to log in:</p> <pre><code>fly -t example login -n my-team\n</code></pre> <p>Any newly configured pipelines (via  <code>fly set-pipeline</code>) and one-off builds (via  <code>fly execute</code>) will be owned by the authorized team. Commands that list content will be scoped to the current team by default, such as  <code>fly pipelines</code> and  <code>fly builds</code>. The web UI will reflect the same state.</p> <p>Newly configured pipelines are hidden by default, meaning other teams and unauthorized visitors cannot view them. To make them publicly viewable, see Pipeline &amp; Build Visibility.</p>"},{"location":"docs/auth-and-teams/managing-teams/#setting-user-roles","title":"Setting User Roles","text":"<p>By default, authorization config passed to <code>set-team</code> configures the  <code>owner</code> role.</p> <p>More advanced roles configuration can be specified through the <code>--config</code> or <code>-c</code> flag.</p> <p>The <code>-c</code> flag expects a <code>.yml</code> file with a single field, <code>roles:</code>, pointing to a list of role authorization configs.</p> <p>All the attributes in each config will vary by provider. Consult the appropriate section for your provider under Configuring Auth for specifics.</p> <p>For example, the following config sets three roles with different auth config for each role's provider:</p> <pre><code>roles:\n  - name: owner\n    github:\n      users: [ \"admin\" ]\n  - name: member\n    github:\n      teams: [ \"org:team\" ]\n  - name: viewer\n    github:\n      orgs: [ \"org\" ]\n    local:\n      users: [ \"visitor\" ]\n</code></pre>"},{"location":"docs/auth-and-teams/managing-teams/#fly-active-users","title":"<code>fly active-users</code>","text":"<p>To list all users that have logged into your instance in the last two months, run:</p> <pre><code>fly -t example active-users\n</code></pre> <p>The output will include the username, connector (which method they used to authenticate) and the date of their last login.</p> <p>You can list users whose last login was within a different range by using:</p> <pre><code>fly -t example active-users --since yyyy-MM-dd\n</code></pre> <p>This can be helpful to get a sense of how active your cluster is.</p>"},{"location":"docs/auth-and-teams/managing-teams/#fly-teams","title":"<code>fly teams</code>","text":"<p>To list all the teams, run:</p> <pre><code>fly -t example teams\n</code></pre> <p>This can be useful if you've forgotten your team name.</p>"},{"location":"docs/auth-and-teams/managing-teams/#fly-teams-d-with-details","title":"<code>fly teams -d</code>: With Details","text":"<p>To list all the teams with authentication details and members, run:</p> <pre><code>fly -t example teams -d\n</code></pre> <p>This can be helpful when debugging OAuth, OIDC groups or listing all individual members.</p>"},{"location":"docs/auth-and-teams/managing-teams/#fly-get-team","title":"<code>fly get-team</code>","text":"<p>To show a team's configuration, run:</p> <pre><code>fly -t example get-team -n some-team\n</code></pre>"},{"location":"docs/auth-and-teams/managing-teams/#fly-rename-team","title":"<code>fly rename-team</code>","text":"<p>To rename a team, run:</p> <pre><code>fly -t example rename-team --old-name my-team --new-name cool-team\n</code></pre> <p>This can only be run by the <code>main</code> team.</p>"},{"location":"docs/auth-and-teams/managing-teams/#fly-destroy-team","title":"<code>fly destroy-team</code>","text":"<p>To remove a team, including all of its pipelines and one-off builds, first log in as the <code>main</code> team, and then run:</p> <pre><code>fly -t example destroy-team --team-name my-team\n</code></pre> <p>Currently, if there were any workers assigned specifically to this team, they'll be orphaned, without having their containers or volumes cleaned up.</p>"},{"location":"docs/auth-and-teams/user-roles/","title":"User Roles & Permissions","text":"<p>Concourse comes with five roles:</p> <ol> <li>Concourse Admin</li> <li>Team Owner</li> <li>Team Member</li> <li>Pipeline Operator</li> <li>Team Viewer</li> </ol> <p>These roles are strictly ordered, so that each role always has all the permissions of any other role lower on the list. This means that a Pipeline Operator can always do anything a Team Viewer can, and so on.</p> <p>In this document we say an action is assigned to a role if that role is capable of performing the action, but any less-privileged role is not. For example, the <code>SaveConfig</code> action is assigned to the <code>member</code> role, so owners and members can set a pipeline config, but pipeline operators and viewers cannot.</p>"},{"location":"docs/auth-and-teams/user-roles/#concourse-admin","title":"Concourse Admin","text":"<p><code>Admin</code> is a special user attribute granted only to owners of the <code>main</code> team.</p> <p>Admins have the ability to administrate teams using <code>fly set-team</code>,  <code>fly destroy-team</code>, <code>fly rename-team</code>, etc.</p> <p>Admins always have permission to perform any action on any team. You cannot assign actions to the admin role using the <code>--config-rbac</code> flag.</p> <p>The following actions are also assigned to admins, and cannot be reconfigured:</p> <pre><code>- GetLogLevel\n- ListActiveUsersSince\n- SetLogLevel\n- GetInfoCreds\n- SetWall\n- ClearWall\n</code></pre>"},{"location":"docs/auth-and-teams/user-roles/#owner-role","title":"<code>owner</code> role","text":"<p>Team owners have read, write and auth management capabilities within the scope of their team, and can rename or destroy the team.</p> <p>Actions assigned to the <code>owner</code> role by default:</p> <pre><code>owner:\n  - SetTeam\n  - RenameTeam\n  - DestroyTeam\n</code></pre>"},{"location":"docs/auth-and-teams/user-roles/#member-role","title":"<code>member</code> role","text":"<p>Team members can operate within their team in a read &amp; write fashion, but they can not change the configuration of their team.</p> <p>Actions assigned to the <code>member</code> role by default:</p> <pre><code>member:\n  - SaveConfig\n  - CreateBuild\n  - DeletePipeline\n  - OrderPipelines\n  - OrderPipelinesWithinGroup\n  - ExposePipeline\n  - HidePipeline\n  - RenamePipeline\n  - ArchivePipeline\n  - CreatePipelineBuild\n  - RegisterWorker\n  - LandWorker\n  - RetireWorker\n  - PruneWorker\n  - HeartbeatWorker\n  - DeleteWorker\n  - HijackContainer\n  - ReportWorkerContainers\n  - ReportWorkerVolumes\n  - CreateArtifact\n  - GetArtifact\n</code></pre>"},{"location":"docs/auth-and-teams/user-roles/#pipeline-operator-role","title":"<code>pipeline-operator</code> role","text":"<p>Team pipeline operators can perform pipeline operations such as triggering builds and pinning resources, however they cannot update pipeline configurations.</p> <p>Actions assigned to the <code>pipeline-operator</code> role by default:</p> <pre><code>pipeline-operator:\n  - AbortBuild\n  - RerunJobBuild\n  - CreateJobBuild\n  - PauseJob\n  - UnpauseJob\n  - ClearTaskCache\n  - UnpinResource\n  - SetPinCommentOnResource\n  - CheckResource\n  - CheckResourceWebHook\n  - CheckResourceType\n  - EnableResourceVersion\n  - DisableResourceVersion\n  - PinResourceVersion\n  - PausePipeline\n  - UnpausePipeline\n  - ClearResourceCache\n</code></pre>"},{"location":"docs/auth-and-teams/user-roles/#viewer-role","title":"<code>viewer</code> role","text":"<p>Team viewers have \"read-only\" access to a team and its pipelines. This locks everything down, preventing users from doing a <code>fly set-pipeline</code> or  <code>fly intercept</code>.</p> <p>Actions assigned to the <code>viewer</code> role by default:</p> <pre><code>viewer:\n  - GetConfig\n  - GetCC\n  - GetBuild\n  - GetCheck\n  - GetBuildPlan\n  - ListBuilds\n  - BuildEvents\n  - BuildResources\n  - GetBuildPreparation\n  - GetJob\n  - ListAllJobs\n  - ListJobs\n  - ListJobBuilds\n  - ListJobInputs\n  - GetJobBuild\n  - GetVersionsDB\n  - JobBadge\n  - MainJobBadge\n  - ListAllResources\n  - ListResources\n  - ListResourceTypes\n  - GetResource\n  - ListResourceVersions\n  - GetResourceVersion\n  - ListBuildsWithVersionAsInput\n  - ListBuildsWithVersionAsOutput\n  - GetResourceCausality\n  - ListAllPipelines\n  - ListPipelines\n  - GetPipeline\n  - ListPipelineBuilds\n  - PipelineBadge\n  - ListWorkers\n  - DownloadCLI\n  - GetInfo\n  - ListContainers\n  - GetContainer\n  - ListDestroyingContainers\n  - ListVolumes\n  - ListDestroyingVolumes\n  - ListTeams\n  - GetTeam\n  - ListTeamBuilds\n  - ListBuildArtifacts\n</code></pre>"},{"location":"docs/auth-and-teams/user-roles/#action-matrix","title":"Action Matrix","text":"<p>In this table, an action is marked as customizable if it is possible to change its permissions by providing the <code>--config-rbac</code> flag, documented below. Assigning an action to a role that is not customizable will have no effect on its permissions.</p> Action <code>fly</code> commands affected UI actions affected can be performed unauthenticated? customizable GetBuild n/a view one-off build page BuildResources n/a view build page GetBuildPreparation n/a view build page BuildEvents <code>fly watch</code>,<code>fly execute</code> view build page GetBuildPlan n/a view build page ListBuildArtifacts n/a n/a AbortBuild <code>fly abort-build</code> abort button on build page PruneWorker <code>fly prune-worker</code> n/a LandWorker <code>fly land-worker</code> n/a RetireWorker n/a n/a ListDestroyingVolumes n/a n/a ListDestroyingContainers n/a n/a ReportWorkerContainers n/a n/a ReportWorkerVolumes n/a n/a GetPipeline n/a view pipeline page GetJobBuild n/a view build page PipelineBadge n/a n/a JobBadge n/a n/a ListJobs <code>fly jobs</code> view pipeline page GetJob n/a view job page ListJobBuilds <code>fly builds</code> view job page ListPipelineBuilds <code>fly builds</code> n/a GetResource n/a view resource page ListBuildsWithVersionAsInput n/a expand version on resource page ListBuildsWithVersionAsOutput n/a expand version on resource page GetResourceCausality n/a n/a GetResourceVersion n/a n/a ListResources fly resources view pipeline page ListResourceTypes n/a n/a ListResourceVersions fly resource-versions,<code>fly pin-resource</code> view resource page CreateBuild <code>fly execute</code> n/a GetContainer n/a n/a HijackContainer <code>fly intercept</code> n/a ListContainers <code>fly containers</code> n/a ListWorkers <code>fly workers</code> n/a RegisterWorker n/a n/a HeartbeatWorker n/a n/a DeleteWorker n/a n/a GetTeam <code>fly get-team</code> n/a SetTeam <code>fly set-team</code> n/a ListTeamBuilds <code>fly builds</code> n/a RenameTeam <code>fly rename-team</code> n/a DestroyTeam <code>fly destroy-team</code> n/a ListVolumes <code>fly volumes</code> n/a DownloadCLI <code>fly sync</code> icons on dashboard and pipeline pages CheckResourceWebHook n/a n/a GetInfo n/a n/a GetCheck <code>fly check-resource</code>,<code>fly check-resource-type</code> check button on resource page ListTeams <code>fly teams</code> view dashboard page ListAllPipelines n/a view dashboard page ListPipelines <code>fly pipelines</code> n/a ListAllJobs <code>fly teams</code> view dashboard page ListAllResources n/a view dashboard page ListBuilds <code>fly builds</code> n/a MainJobBadge n/a n/a GetLogLevel n/a n/a SetLogLevel n/a n/a GetWall n/a n/a SetWall n/a n/a ClearWall n/a n/a ListActiveUsersSince <code>fly active-users</code> n/a GetInfoCreds n/a n/a CheckResource <code>fly check-resource</code> check button on resource page CheckResourceType <code>fly check-resource-type</code> n/a CreateJobBuild <code>fly trigger-job</code> trigger button on job and build pages RerunJobBuild <code>fly rerun-build</code> rerun button on build page CreatePipelineBuild <code>fly execute</code> n/a DeletePipeline <code>fly destroy-pipeline</code> n/a DisableResourceVersion <code>fly disable-resource-version</code> version disable widget on resource page EnableResourceVersion <code>fly enable-resource-version</code> version enable widget on resource page PinResourceVersion <code>fly pin-resource</code> pin buttons on resource page UnpinResource fly unpin-resource pin buttons on resource page SetPinCommentOnResource <code>fly pin-resource</code> comment overlay on resource page GetConfig <code>fly get-pipeline</code> n/a GetCC n/a n/a GetVersionsDB n/a n/a ListJobInputs n/a n/a OrderPipelines <code>fly order-pipelines</code> drag and drop on dashboard OrderPipelinesWithinGroup <code>fly order-instanced-pipelines</code> drag and drop within instance group on dashboard PauseJob <code>fly pause-job</code> pause button on job page PausePipeline <code>fly pause-pipeline</code> pause button on pipeline or dashboard RenamePipeline <code>fly rename-pipeline</code> n/a UnpauseJob <code>fly unpause-job</code> play button on job page UnpausePipeline <code>fly unpause-pipeline</code> play button on pipeline or dashboard ExposePipeline <code>fly expose-pipeline</code> eyeball button on dashboard HidePipeline <code>fly hide-pipeline</code> slashed eyeball button on dashboard SaveConfig <code>fly set-pipeline</code> n/a ClearTaskCache <code>fly clear-task-cache</code> n/a CreateArtifact <code>fly execute</code> n/a GetArtifact <code>fly execute</code> n/a ClearResourceCache <code>fly clear-resource-cache</code> n/a"},{"location":"docs/auth-and-teams/user-roles/#configuring-rbac","title":"Configuring RBAC","text":"<p>Experimental Feature</p> <p>Configuring RBAC is experimental, and this may change in the future.</p> <p>It is possible to promote or demote the roles to which actions are assigned by passing the <code>--config-rbac</code> to the <code>concourse web</code> command with a path to a <code>.yml</code> file, like the following:</p> <pre><code>concourse web --config-rbac=/path/to/rbac/config.yml\n</code></pre> <p>This file should be a YAML map where the keys are role names (<code>owner</code>, <code>member</code>, <code>pipeline-operator</code>, and <code>viewer</code> are valid). For each role, the value should be a list of actions. On startup, Concourse will assign each role to its associated list of actions.</p> <p>For example, in the default configuration only pipeline-operators and above can abort builds. To restrict aborting builds to only members and above, you could pass this as a <code>--config-rbac</code> file:</p> <pre><code>member:\n  - AbortBuild\n</code></pre> <p>On the other hand, only members and above can order pipelines by default. To extend this privilege down to pipeline-operators, you can use a <code>--config-rbac</code> file like the following:</p> <pre><code>pipeline-operator:\n  - OrderPipelines\n</code></pre> <p>You do not need to specify a role for every possible action; if an action does not appear in the file, then the default role (as described in the sections above) will be assigned to that action. Also, please avoid specifying the same action under multiple roles in this file - it can have unpredictable results.</p>"},{"location":"docs/auth-and-teams/configuring/","title":"Auth & Teams","text":"<p>The very first thing to configure with Concourse is how users will log in, and what those users should be able to do.</p> <p>This is configured in two separate tiers:</p> <ul> <li>Authentication, how users identify themselves, is configured on the <code>web</code> node.</li> <li>Authorization, how user access is determined, is configured on each team.</li> </ul> <p>Concourse currently supports the following auth methods:</p> <ul> <li> <p> Local Auth</p> <p> Configure</p> </li> <li> <p> GitHub Auth</p> <p> Configure</p> </li> <li> <p> GitLab Auth</p> <p> Configure</p> </li> <li> <p> BitBucket Cloud Auth</p> <p> Configure</p> </li> <li> <p> CF / UAA Auth</p> <p> Configure</p> </li> <li> <p> LDAP Auth</p> <p> Configure</p> </li> <li> <p> Microsoft Auth</p> <p> Configure</p> </li> <li> <p> Generic OIDC Auth</p> <p> Configure</p> </li> <li> <p> Generic OAuth</p> <p> Configure</p> </li> <li> <p> Generic SAML Auth</p> <p> Configure</p> </li> </ul> <p>Any number of providers can be enabled at any one time. Users will be given a choice when logging in as to which one they would like to use.</p> <p>Concourse uses a fork of Dex for its authentication. You can find additional documentation on the supported auth providers in the Dex connectors documentation.</p> <p>Adding a new auth provider to Concourse is as simple as submitting a pull request to our fork of Dex and then adding a bit of configuration to the  <code>skymarshal</code> component.</p>"},{"location":"docs/auth-and-teams/configuring/bitbucket-cloud/","title":"BitBucket Cloud Auth","text":"<p>A Concourse server can authenticate against BitBucket Cloud to leverage its permission model.</p>"},{"location":"docs/auth-and-teams/configuring/bitbucket-cloud/#authentication","title":"Authentication","text":"<p>First, you'll need to create an OAuth consumer on Bitbucket Cloud.</p> <p>The consumer will need the following permissions:</p> <ul> <li>Account:<ul> <li>Email</li> <li>Read</li> </ul> </li> <li>Team membership:<ul> <li>Read</li> </ul> </li> </ul> <p>The \"Callback URL\" must be the URL of your Concourse server with <code>/sky/issuer/callback</code> appended. This address must be reachable by BitBucket Cloud - it can't be <code>localhost</code>.</p> <p>For example, Concourse's own CI server's callback URL would be:</p> <pre><code>https://ci.concourse-ci.org/sky/issuer/callback\n</code></pre> <p>You will be given a Client ID and a Client Secret for your new application. The client ID and secret must then be configured on the <code>web</code> node by setting the following env:</p> <pre><code>CONCOURSE_BITBUCKET_CLOUD_CLIENT_ID=myclientid\nCONCOURSE_BITBUCKET_CLOUD_CLIENT_SECRET=myclientsecret\n</code></pre>"},{"location":"docs/auth-and-teams/configuring/bitbucket-cloud/#authorization","title":"Authorization","text":"<p>BitBucket users and teams can be authorized for a team by passing the following flags to  <code>fly set-team</code>:</p> <ul> <li><code>--bitbucket-cloud-user=LOGIN</code> - Authorize an individual user.</li> <li><code>--bitbucket-cloud-team=TEAM_NAME</code> - Authorize an entire organization's members.</li> </ul> <p>For example:</p> <pre><code>fly set-team -n my-team \\\n    --bitbucket-cloud-user my-bitbucket-login \\\n    --bitbucket-cloud-team my-bitbucket-team\n</code></pre> <p>... or via <code>--config</code> for setting user roles:</p> <pre><code>roles:\n  - name: member\n    bitbucket-cloud:\n      users: [ \"my-bitbucket-login\" ]\n      teams: [ \"my-bitbucket-team\" ]\n</code></pre>"},{"location":"docs/auth-and-teams/configuring/bitbucket-cloud/#configuring-main-team-authorization","title":"Configuring main Team Authorization","text":"<p>BitBucket users and teams can be added to the <code>main</code> team authorization config by setting the following env on the <code>web</code> node:</p> <pre><code>CONCOURSE_MAIN_TEAM_BITBUCKET_CLOUD_USER=my-bitbucket-login\nCONCOURSE_MAIN_TEAM_BITBUCKET_CLOUD_TEAM=my-bitbucket-team\n</code></pre> <p>Multiple teams and users may be specified by comma-separating them.</p>"},{"location":"docs/auth-and-teams/configuring/cf-uaa/","title":"CF / UAA Auth","text":"<p>Cloud Foundry (CF) auth can be used for operators who wish to authenticate their users configured against their Cloud Foundry instance via the UAA auth component.</p>"},{"location":"docs/auth-and-teams/configuring/cf-uaa/#authentication","title":"Authentication","text":"<p>You'll need to configure your UAA with a <code>concourse</code> client by setting the following under  <code>uaa.clients</code>:</p> <pre><code>concourse:\n  id: myclientid\n  secret: myclientsecret\n  scope: openid,cloud_controller.read\n  authorized-grant-types: \"authorization_code,refresh_token\"\n  access-token-validity: 3600\n  refresh-token-validity: 3600\n  redirect-uri: https://concourse.example.com/sky/issuer/callback\n</code></pre> <p>The value for <code>redirect-uri</code> must be the external URL of your Concourse server with <code>/sky/issuer/callback</code> appended.</p> <p>For example, Concourse's own CI server's callback URL would be:</p> <pre><code>https://ci.concourse-ci.org/sky/issuer/callback\n</code></pre> <p>Next, you'll need to take the same client ID and secret and configure it on the  <code>web</code> node by setting the following env:</p> <pre><code>CONCOURSE_CF_API_URL=http://mycf.example.com\nCONCOURSE_CF_CLIENT_ID=myclientid\nCONCOURSE_CF_CLIENT_SECRET=myclientsecret\n</code></pre> <p>Note: if you're integrating with Cloud Foundry, you're probably also deploying Concourse via BOSH - in which case you'll want to set the  <code>cf_auth.*</code> properties in your manifest instead of setting the above env.</p>"},{"location":"docs/auth-and-teams/configuring/cf-uaa/#authorization","title":"Authorization","text":"<p>CloudFoundry users and org/space members can be authorized for a team by passing the following flags to fly set-team:</p> <ul> <li><code>--cf-user=USERNAME</code> - Authorize an individual user.</li> <li><code>--cf-org=ORG_NAME</code> - Authorize an entire organization's members. Members will need to be part of a Space inside the   organization.</li> <li><code>--cf-space=ORG_NAME:SPACE_NAME</code> - Deprecated in favor of <code>--cf-space-with-developer-role</code>. Authorize the members with   <code>developer</code> role of a space within an organization.</li> <li><code>--cf-space-with-any-role=ORG_NAME:SPACE_NAME</code> - Authorize the members with any role of a space within an   organization.</li> <li><code>--cf-space-with-developer-role=ORG_NAME:SPACE_NAME</code> - Authorize the members with <code>developer</code> role of a space within   an organization.</li> <li><code>--cf-space-with-auditor-role=ORG_NAME:SPACE_NAME</code> - Authorize the members with <code>auditor</code> role of a space within an   organization.</li> <li><code>--cf-space-with-manager-role=ORG_NAME:SPACE_NAME</code> - Authorize the members with <code>manager</code> role of a space within an   organization.</li> <li><code>--cf-space-guid=SPACE_GUID</code> - Authorize the members with any role of a space within an organization by space GUID.</li> </ul> <p>For example:</p> <pre><code>fly set-team -n my-team \\\n    --cf-user my-username \\\n    --cf-org my-org \\\n    --cf-space my-other-org:my-space\n</code></pre> <p>... or via <code>--config</code> for setting user roles:</p> <pre><code>roles:\n  - name: member\n    cf:\n      users: [ \"my-username\" ]\n      orgs: [ \"my-org\" ]\n      spaces: [ \"my-other-org:my-space\" ]\n</code></pre>"},{"location":"docs/auth-and-teams/configuring/cf-uaa/#adding-cf-users-to-the-main-team","title":"Adding CF Users to the <code>main</code> Team","text":"<p>CloudFoundry users and org/space members can be added to the <code>main</code> team authorization config by setting the following env on the <code>web</code> node:</p> <pre><code>CONCOURSE_MAIN_TEAM_CF_USER=username\nCONCOURSE_MAIN_TEAM_CF_ORG=org-name\nCONCOURSE_MAIN_TEAM_CF_SPACE=org-name:space-name\nCONCOURSE_MAIN_TEAM_CF_SPACE_WITH_ANY_ROLE=org-name:space-name\nCONCOURSE_MAIN_TEAM_CF_SPACE_WITH_DEVELOPER_ROLE=org-name:space-name\nCONCOURSE_MAIN_TEAM_CF_SPACE_WITH_AUDITOR_ROLE=org-name:space-name\nCONCOURSE_MAIN_TEAM_CF_SPACE_WITH_MANAGER_ROLE=org-name:space-name\nCONCOURSE_MAIN_TEAM_CF_SPACE_GUID=SPACE_GUID\n</code></pre> <p>Multiple users, spaces, etc. may be specified by comma-separating them.</p>"},{"location":"docs/auth-and-teams/configuring/generic-oauth/","title":"Generic OAuth Auth","text":"<p>A Concourse server can authenticate against any valid OAuth auth provider, though it's a bit \"closer to the metal\" as you'll need to explicitly configure the auth, token, and user-info URLs. You may want to see if you can use Generic OIDC auth if your auth provider is compatible with OIDC.</p>"},{"location":"docs/auth-and-teams/configuring/generic-oauth/#authentication","title":"Authentication","text":"<p>First you'll need to create a client with your oAuth provider.</p> <p>The callback URL must be the URL of your Concourse server with <code>/sky/issuer/callback</code> appended. This address must be reachable by your oAuth provider - it can't be <code>localhost</code>.</p> <p>For example, Concourse's own CI server's callback URL would be:</p> <pre><code>https://ci.concourse-ci.org/sky/issuer/callback\n</code></pre> <p>The Generic oAuth provider has many values to set - for a full list consult <code>concourse web --help</code>.</p> <p>A typical web node env config may look something like this:</p> <pre><code>CONCOURSE_OAUTH_DISPLAY_NAME=Acme\nCONCOURSE_OAUTH_CLIENT_ID=myclientid\nCONCOURSE_OAUTH_CLIENT_SECRET=myclientsecret\nCONCOURSE_OAUTH_AUTH_URL=https://oauth.example.com/oauth2/auth\nCONCOURSE_OAUTH_TOKEN_URL=https://oauth.example.com/oauth2/token\nCONCOURSE_OAUTH_USERINFO_URL=https://oauth.example.com/oauth2/userinfo\n</code></pre> <p>Consult <code>concourse web --help</code> for a full list of flags with descriptions.</p>"},{"location":"docs/auth-and-teams/configuring/generic-oauth/#authorization","title":"Authorization","text":"<p>OAuth users and groups can be authorized for a team by passing the following flags to  <code>fly set-team</code>:</p> <ul> <li><code>--oauth-user=USERNAME</code> - Authorize an individual user.</li> <li><code>--oauth-group=GROUP_NAME</code> - Authorize anyone from the group.<ul> <li>You may only configure groups if the auth provider exposes this information in either the token itself, or in the   contents of the userinfo endpoint.</li> <li>You can configure which claim points to the groups information by specifying <code>CONCOURSE_OAUTH_GROUPS_KEY</code> on the  <code>web</code> node.</li> </ul> </li> </ul> <p>For example:</p> <pre><code>fly set-team -n my-team \\\n    --oauth-user my-username \\\n    --oauth-group my-group\n</code></pre> <p>... or via <code>--config</code> for setting user roles:</p> <pre><code>roles:\n  - name: member\n    oauth:\n      users: [ \"my-username\" ]\n      groups: [ \"my-group\" ]\n</code></pre>"},{"location":"docs/auth-and-teams/configuring/generic-oauth/#configuring-main-team-authorization","title":"Configuring <code>main</code> Team Authorization","text":"<p>OAuth users and groups can be added to the <code>main</code> team authorization config by setting the following env on the <code>web</code> node:</p> <pre><code>CONCOURSE_MAIN_TEAM_OAUTH_USER=my-user\nCONCOURSE_MAIN_TEAM_OAUTH_GROUP=my-group\n</code></pre> <p>Multiple users and groups may be specified by comma-separating them.</p>"},{"location":"docs/auth-and-teams/configuring/generic-oidc/","title":"Generic OIDC Auth","text":"<p>A Concourse server can authenticate against any valid OIDC auth provider. This provider is similar to Generic oAuth except it only requires an issuer URL rather than auth/token/userinfo URLs.</p>"},{"location":"docs/auth-and-teams/configuring/generic-oidc/#authentication","title":"Authentication","text":"<p>First you'll need to create a client with your oAuth provider.</p> <p>The callback URL must be the URL of your Concourse server with <code>/sky/issuer/callback</code> appended. This address must be reachable by your OIDC provider - it can't be <code>localhost</code>.</p> <p>For example, Concourse's own CI server's callback URL would be:</p> <pre><code>https://ci.concourse-ci.org/sky/issuer/callback\n</code></pre> <p>A typical <code>web</code> node env config may look something like this:</p> <pre><code>CONCOURSE_OIDC_DISPLAY_NAME=Acme\nCONCOURSE_OIDC_CLIENT_ID=myclientid\nCONCOURSE_OIDC_CLIENT_SECRET=myclientsecret\nCONCOURSE_OIDC_ISSUER=https://oidc.example.com\n</code></pre> <p>Consult <code>concourse web --help</code> for a full list of flags with descriptions.</p>"},{"location":"docs/auth-and-teams/configuring/generic-oidc/#a-note-about-user-lookup","title":"A note about user lookup","text":"<p>When determining the user identity, Concourse will first look at the <code>preferred_username</code> claim. If this claim is empty or missing, it will then look at the claim specified by <code>CONCOURSE_OIDC_USER_NAME_KEY</code> (which defaults to <code>username</code>).</p> <p>Let's say that you want to tie each user to their email by using <code>CONCOURSE_OIDC_USER_NAME_KEY=email</code>.</p> <p>If your OIDC provider returns the following claims, Concourse will still resolve the user to <code>Jane Doe</code>:</p> <pre><code>{\n  \"sub\": \"248289761001\",\n  \"username\": \"j.doe\",\n  \"preferred_username\": \"Jane Doe\",\n  \"email\": \"janedoe@example.com\"\n}\n</code></pre> <p>However, if the <code>preferred_username</code> claim is empty or missing, Concourse will respect the key and resolve the user to <code>janedoe@example.com</code>:</p> <pre><code>{\n  \"sub\": \"248289761001\",\n  \"username\": \"j.doe\",\n  \"preferred_username\": \"\",\n  \"email\": \"janedoe@example.com\"\n}\n</code></pre>"},{"location":"docs/auth-and-teams/configuring/generic-oidc/#authorization","title":"Authorization","text":"<p>Warning</p> <p>When authorizing individual users, it's up to you to ensure that the <code>preferred_username</code> claim and/or the claim  specified by <code>CONCOURSE_OIDC_USER_NAME_KEY</code> is unique. If they're not, then it's possible for users to impersonate  each other</p> <p>OIDC users and groups can be authorized for a team by passing one or more of the following flags to fly set-team:</p> <ul> <li><code>--oidc-user=USERNAME</code> - Authorize an individual user.</li> <li><code>--oidc-group=GROUP_NAME</code> - Authorize anyone from the group.<ul> <li>You may only configure groups if the auth provider exposes this information in either the token itself, or in the   contents of the userinfo endpoint.</li> <li>You can configure which claim points to the groups information by specifying <code>CONCOURSE_OIDC_GROUPS_KEY</code> on the  <code>web</code> node.</li> </ul> </li> </ul> <p>For example:</p> <pre><code>fly set-team -n my-team \\\n    --oidc-user my-username \\\n    --oidc-user another-username \\\n    --oidc-group my-group \\\n    --oidc-group my-other-group\n</code></pre> <p>...or via <code>--config</code> for setting user roles:</p> <pre><code>roles:\n  - name: member\n    oidc:\n      users: [ \"my-username\", \"another-username\" ]\n      groups: [ \"my-group\", \"my-other-group\" ]\n</code></pre> <p>Both users and groups are optional. You may opt to only provide privileges based on membership to a group and not to any user explicitly and vice versa.</p>"},{"location":"docs/auth-and-teams/configuring/generic-oidc/#configuring-main-team-authorization","title":"Configuring <code>main</code> Team Authorization","text":"<p>OIDC users and groups can be added to the <code>main</code> team authorization config by setting the following env on the <code>web</code> node:</p> <pre><code>CONCOURSE_MAIN_TEAM_OIDC_USER=my-user\nCONCOURSE_MAIN_TEAM_OIDC_GROUP=my-group\n</code></pre> <p>Multiple users and groups may be specified by comma-separating them.</p>"},{"location":"docs/auth-and-teams/configuring/generic-saml/","title":"Generic SAML Auth","text":"<p>A Concourse server can authenticate against any valid SAML auth provider.</p>"},{"location":"docs/auth-and-teams/configuring/generic-saml/#authentication","title":"Authentication","text":"<p>First you'll need to create an application with your SAML provider. Note that the terminology used for configuring an application may vary between SAML providers - this document uses Okta's terminology.</p> <p>SAML Assertion Consumer Service (ACS) URL must be the URL of your Concourse server with <code>/sky/issuer/callback</code> appended.</p> <p>For example, Concourse's own CI server's callback URL would be:</p> <pre><code>https://ci.concourse-ci.org/sky/issuer/callback\n</code></pre> <p>Audience URI (SP Entity ID) must match <code>CONCOURSE_SAML_ENTITY_ISSUER</code>, which defaults to the URL of your Concourse server with <code>/sky/issuer/callback</code> appended.</p> <p>Attribute statements that you define in the SAML provider can be remapped in Concourse:</p> <pre><code>CONCOURSE_SAML_USERNAME_ATTR=name   # default\nCONCOURSE_SAML_EMAIL_ATTR=email     # default\nCONCOURSE_SAML_GROUPS_ATTR=groups   # default\n</code></pre> <p>Finally, the SAML provider will generate a SSO URL, a CA certificate, and an Identity Provider Issuer. These values correspond with <code>CONCOURSE_SAML_SSO_URL</code>, <code>CONCOURSE_SAML_CA_CERT</code>, and <code>CONCOURSE_SAML_SSO_ISSUER</code> respectively.</p> <p>A typical web node env config may look something like this:</p> <pre><code>CONCOURSE_SAML_DISPLAY_NAME=Okta\nCONCOURSE_SAML_SSO_URL=https://acme.okta.com/app/Y/Z/sso/saml\nCONCOURSE_SAML_CA_CERT=/path/to/ca_cert\nCONCOURSE_SAML_SSO_ISSUER=http://www.okta.com/X\n</code></pre> <p>Consult <code>concourse web --help</code> for a full list of flags with descriptions.</p>"},{"location":"docs/auth-and-teams/configuring/generic-saml/#authorization","title":"Authorization","text":"<p>OAuth users and groups can be authorized for a team by passing the following flags to  <code>fly set-team</code>:</p> <ul> <li><code>--saml-user=USERNAME</code> - Authorize an individual user.</li> <li><code>--saml-group=GROUP_NAME</code> - Authorize anyone from the group.<ul> <li>You may only configure groups if the auth provider exposes this information in either the token itself, or in the   contents of the userinfo endpoint.</li> <li>You can configure which claim points to the groups information by specifying <code>CONCOURSE_SAML_GROUPS_ATTR</code> on the  <code>web</code> node.</li> </ul> </li> </ul> <p>For example:</p> <pre><code>fly set-team -n my-team \\\n    --saml-user my-username \\\n    --saml-group my-group\n</code></pre> <p>... or via <code>--config</code> for setting user roles:</p> <pre><code>roles:\n  - name: member\n    saml:\n      users: [ \"my-username\" ]\n      groups: [ \"my-groups\" ]\n</code></pre>"},{"location":"docs/auth-and-teams/configuring/generic-saml/#configuring-main-team-authorization","title":"Configuring <code>main</code> Team Authorization","text":"<p>SAML users and groups can be added to the <code>main</code> team authorization config by setting the following env on the <code>web</code> node:</p> <pre><code>CONCOURSE_MAIN_TEAM_SAML_USER=my-user\nCONCOURSE_MAIN_TEAM_SAML_GROUP=my-group\n</code></pre> <p>Multiple users and groups may be specified by comma-separating them.</p>"},{"location":"docs/auth-and-teams/configuring/github/","title":"GitHub Auth","text":"<p>A Concourse server can authenticate against GitHub to leverage their permission model and other security improvements in their infrastructure.</p>"},{"location":"docs/auth-and-teams/configuring/github/#authentication","title":"Authentication","text":"<p>First, you'll need to create an OAuth application on GitHub.</p> <p>The \"Authorization callback URL\" must be the URL of your Concourse server. This address must be reachable by GitHub - it can't be <code>localhost</code>.</p> <p>For example, Concourse's own CI server's callback URL would be:</p> <pre><code>https://ci.concourse-ci.org/sky/issuer/callback\n</code></pre> <p>You will be given a Client ID and a Client Secret for your new application. The client ID and secret must then be configured on the <code>web</code> node by setting the following env:</p> <pre><code>CONCOURSE_GITHUB_CLIENT_ID=myclientid\nCONCOURSE_GITHUB_CLIENT_SECRET=myclientsecret\n</code></pre> <p>Note that the client must be created under an organization if you want to authorize users based on organization/team membership. In addition, the GitHub application must have at least read access on the organization's members. If the client is created under a personal account, only individual users can be authorized.</p> <p>If you're configuring GitHub Enterprise, you'll also need to set the following env:</p> <pre><code>CONCOURSE_GITHUB_HOST=github.example.com\nCONCOURSE_GITHUB_CA_CERT=/path/to/ca_cert\n</code></pre> <p>The GitHub Enterprise host must not contain a scheme, or a trailing slash.</p>"},{"location":"docs/auth-and-teams/configuring/github/#authorization","title":"Authorization","text":"<p>Users, teams, and entire organizations can be authorized for a team by passing the following flags to  <code>fly set-team</code>:</p> <ul> <li><code>--github-user=LOGIN</code> - Authorize an individual user.</li> <li><code>--github-org=ORG_NAME</code> - Authorize an entire organization's members.</li> <li><code>--github-team=ORG_NAME:TEAM_NAME</code> - Authorize a team's members within an organization.</li> </ul> <pre><code>fly set-team -n my-team \\\n    --github-user my-github-login \\\n    --github-org my-org \\\n    --github-team my-other-org:my-team\n</code></pre> <p>... or via <code>--config</code> for setting user roles:</p> <pre><code>roles:\n  - name: member\n    github:\n      users: [ \"my-github-login\" ]\n      orgs: [ \"my-org\" ]\n      teams: [ \"my-other-org:my-team\" ]\n</code></pre>"},{"location":"docs/auth-and-teams/configuring/github/#configuring-main-team-authorization","title":"Configuring <code>main</code> Team Authorization","text":"<p>GitHub users, teams, and organizations can be added to the <code>main</code> team authorization config by setting the following env on the <code>web</code> node:</p> <pre><code>CONCOURSE_MAIN_TEAM_GITHUB_ORG=org-name\nCONCOURSE_MAIN_TEAM_GITHUB_TEAM=org-name:team-name\nCONCOURSE_MAIN_TEAM_GITHUB_USER=some-user\n</code></pre> <p>Multiple orgs, teams, and users may be specified by comma-separating them.</p>"},{"location":"docs/auth-and-teams/configuring/gitlab/","title":"GitLab Auth","text":"<p>A Concourse server can authenticate against GitLab to leverage their permission model.</p>"},{"location":"docs/auth-and-teams/configuring/gitlab/#authentication","title":"Authentication","text":"<p>First you need to create an OAuth application on GitLab with the following scopes:</p> <ul> <li>read_user</li> <li>openid</li> </ul> <p>The \"Authorization callback URL\" must be the URL of your Concourse server with <code>/sky/issuer/callback</code> appended. This address must be reachable by GitLab - it can't be <code>localhost</code>.</p> <p>For example, Concourse's own CI server's callback URL would be:</p> <pre><code>https://ci.concourse-ci.org/sky/issuer/callback\n</code></pre> <p>You will be given a Client ID and a Client Secret for your new application. The client ID and secret must then be configured on the <code>web</code> node by setting the following env:</p> <pre><code>CONCOURSE_GITLAB_CLIENT_ID=myclientid\nCONCOURSE_GITLAB_CLIENT_SECRET=myclientsecret\n</code></pre> <p>If you're configuring a self-hosted GitLab instance, you'll also need to set the following flag:</p> <pre><code>CONCOURSE_GITLAB_HOST=https://gitlab.example.com\n</code></pre> <p>The GitLab host must contain a scheme and not a trailing slash.</p>"},{"location":"docs/auth-and-teams/configuring/gitlab/#authorization","title":"Authorization","text":"<p>Users and groups can be authorized for a team by passing the following flags to fly set-team:</p> <ul> <li><code>--gitlab-user=USERNAME</code> - Authorize an individual user.</li> <li><code>--gitlab-group=GROUP_NAME</code> - Authorize an entire group's members.</li> </ul> <p>For example:</p> <pre><code>fly set-team -n my-team \\\n    --gitlab-user my-gitlab-user \\\n    --gitlab-group my-group\n</code></pre> <p>... or via <code>--config</code> for setting user roles:</p> <pre><code>roles:\n  - name: member\n    gitlab:\n      users: [ \"my-gitlab-login\" ]\n      groups: [ \"my-gitlab-group\" ]\n</code></pre>"},{"location":"docs/auth-and-teams/configuring/gitlab/#configuring-main-team-authorization","title":"Configuring <code>main</code> Team Authorization","text":"<p>GitLab users and groups can be added to the <code>main</code> team authorization config by setting the following env on the <code>web</code> node:</p> <pre><code>CONCOURSE_MAIN_TEAM_GITLAB_GROUP=group-name\nCONCOURSE_MAIN_TEAM_GITLAB_USER=some-user\n</code></pre> <p>Multiple groups and users may be specified by comma-separating them.</p>"},{"location":"docs/auth-and-teams/configuring/ldap/","title":"LDAP Auth","text":"<p>The LDAP provider can be used for operators who wish to authenticate their users against an LDAP server.</p>"},{"location":"docs/auth-and-teams/configuring/ldap/#authentication","title":"Authentication","text":"<p>The LDAP provider is configured by pointing it to an LDAP host with a read-only bind DN and password. This bind DN and password is used for authenticating with the LDAP host and querying the users.</p> <p>Additionally, the base DN under which users are searched as well as the attribute of the users to associate to ' usernames' must also be configured.</p> <p>These can be specified via env to the <code>web</code> node like so:</p> <pre><code>CONCOURSE_LDAP_DISPLAY_NAME=Acme # optional; default \"LDAP\"\nCONCOURSE_LDAP_HOST=ldap.example.com # port defaults to 389 or 636\nCONCOURSE_LDAP_BIND_DN='cn=read-only-admin,dc=example,dc=com'\nCONCOURSE_LDAP_BIND_PW=read-only-admin-password\nCONCOURSE_LDAP_USER_SEARCH_BASE_DN='cn=users,dc=example,dc=com'\nCONCOURSE_LDAP_USER_SEARCH_USERNAME=uid\n</code></pre> <p>To configure TLS, you may need to set a CA cert:</p> <pre><code>CONCOURSE_LDAP_CA_CERT=/path/to/ca_cert\n</code></pre> <p>If your LDAP host does not use TLS, you must set:</p> <pre><code>CONCOURSE_LDAP_INSECURE_NO_SSL=true\n</code></pre> <p>To fine-tune which users are queried, you can specify a user search filter like so:</p> <pre><code>CONCOURSE_LDAP_USER_SEARCH_FILTER='(objectClass=person)'\n</code></pre> <p>To set which user attributes map to the token claims, you can set the following:</p> <pre><code>CONCOURSE_LDAP_USER_SEARCH_ID_ATTR=uid         # default\nCONCOURSE_LDAP_USER_SEARCH_EMAIL_ATTR=mail     # default\nCONCOURSE_LDAP_USER_SEARCH_NAME_ATTR=some-attr # no default\n</code></pre>"},{"location":"docs/auth-and-teams/configuring/ldap/#configuring-ldap-group-search","title":"Configuring LDAP group search","text":"<p>The LDAP provider can also be configured with group search configuration, so that users can be configured for team authorization by their 'group' in LDAP.</p> <p>For example, to find groups and identify them by their <code>ou</code> attribute, you would configure:</p> <pre><code>CONCOURSE_LDAP_GROUP_SEARCH_BASE_DN='cn=groups,dc=example,dc=com'\nCONCOURSE_LDAP_GROUP_SEARCH_NAME_ATTR=ou\n</code></pre> <p>The attributes correlating a user to a group must be specified like so:</p> <pre><code>CONCOURSE_LDAP_GROUP_SEARCH_USER_ATTR=uid\nCONCOURSE_LDAP_GROUP_SEARCH_GROUP_ATTR=members\n</code></pre> <p>This specifies that the <code>uid</code> attribute of the user must be present in the <code>members</code> attribute of the group.</p> <p>An additional filter may be specified, just like with users:</p> <pre><code>CONCOURSE_LDAP_GROUP_SEARCH_FILTER='(objectClass=posixGroup)'\n</code></pre>"},{"location":"docs/auth-and-teams/configuring/ldap/#authorization","title":"Authorization","text":"<p>LDAP users and groups can be authorized for a team by passing the following flags to  <code>fly set-team</code>:</p> <ul> <li><code>--ldap-user=USERNAME</code> - Authorize an individual user.</li> <li><code>--ldap-group=GROUP_NAME</code> - Authorize anyone from the group.</li> </ul> <p>For example:</p> <pre><code>fly set-team -n my-team \\\n    --ldap-user my-username \\\n    --ldap-group my-group\n</code></pre> <p>... or via <code>--config</code> for setting user roles:</p> <pre><code>roles:\n  - name: member\n    ldap:\n      users: [ \"my-username\" ]\n      groups: [ \"my-groups\" ]\n</code></pre>"},{"location":"docs/auth-and-teams/configuring/ldap/#configuring-main-team-authorization","title":"Configuring <code>main</code> Team Authorization","text":"<p>LDAP users and groups can be added to the <code>main</code> team authorization config by setting the following env on the <code>web</code> node:</p> <pre><code>CONCOURSE_MAIN_TEAM_LDAP_USER=my-user\nCONCOURSE_MAIN_TEAM_LDAP_GROUP=my-group\n</code></pre> <p>Multiple users and groups may be specified by comma-separating them.</p>"},{"location":"docs/auth-and-teams/configuring/local-user/","title":"Local User Auth","text":"<p>Local User auth is a primitive username/password-based auth mechanism. All users and passwords are configured statically.</p> <p>In general, we recommend configuring one of the other providers instead, but for small deployments with only a few users, local user auth may be all you need.</p>"},{"location":"docs/auth-and-teams/configuring/local-user/#authentication","title":"Authentication","text":"<p>Local users are configured on the <code>web</code> node by setting the following env:</p> <pre><code>CONCOURSE_ADD_LOCAL_USER=myuser:mypass,anotheruser:anotherpass\n</code></pre> <p>This configures two users, <code>myuser</code> and <code>anotheruser</code>, with their corresponding passwords. The literal password can be provided, or a bcrypt hash of the password.</p> <p>When local users are configured, the log-in page in the web UI will show a username/password prompt.</p> <p>Local users can also log in via <code>fly login</code> with the <code>--username</code> and <code>--password</code> flags.</p>"},{"location":"docs/auth-and-teams/configuring/local-user/#bcrypt-hashing-passwords","title":"Bcrypt Hashing Passwords","text":"<p>Instead of passing in user passwords in plaintext, you can provide Concourse with a bcrypt hash of the passwords.</p> <p>There aren't any great CLI tools for quickly hashing passwords with bcrypt. Here's a simple Go program that can do the hashing for you.</p> <pre><code>package main\n\nimport (\n    \"fmt\"\n\n    \"golang.org/x/crypto/bcrypt\"\n)\n\nfunc main() {\n    password := []byte(\"mypass\")\n    hash, _ := bcrypt.GenerateFromPassword(password, 12)\n    fmt.Println(string(hash))\n}\n</code></pre> <p>Put that in a <code>main.go</code> then run go run <code>main.go</code> and it will output a hash for your password. You can run this program in the Go Playground if you want to avoid installing Go.</p> <p>Hashing the passwords for the previous example, you would then set <code>CONCOURSE_ADD_LOCAL_USER</code> to the following:</p> <pre><code>CONCOURSE_ADD_LOCAL_USER='myuser:$2a$12$L8Co5QYhD..S1l9mIIVHlucvRjfte4tuymMCk9quln0H/eol16d5W,anotheruser:$2a$12$VWSSfrsTIisf96q7UVsvyOBbrcP88kh5CLtuXYSXGwnSnM3ClKxXu'\n</code></pre>"},{"location":"docs/auth-and-teams/configuring/local-user/#authorization","title":"Authorization","text":"<p>Local users are granted access to teams via <code>fly set-team</code>, using the <code>--local-user</code> flag:</p> <pre><code>fly set-team -n my-team --local-user some_username\n</code></pre> <p>...or via --config for setting user roles:</p> <pre><code>roles:\n  - name: member\n    local:\n      users: [ \"some_username\" ]\n</code></pre>"},{"location":"docs/auth-and-teams/configuring/local-user/#configuring-main-team-authorization","title":"Configuring <code>main</code> Team Authorization","text":"<p>Local users can be added to the <code>main</code> team authorization config by setting the following env on the <code>web</code> node:</p> <pre><code>CONCOURSE_MAIN_TEAM_LOCAL_USER=myuser\n</code></pre> <p>Multiple users may be specified by comma-separating them.</p>"},{"location":"docs/auth-and-teams/configuring/microsoft/","title":"Microsoft Auth","text":"<p>A Concourse server can authenticate against Microsoft Azure AD to leverage its permission model.</p>"},{"location":"docs/auth-and-teams/configuring/microsoft/#authentication","title":"Authentication","text":"<p>You'll need to register a new application on Azure.</p> <p>The \"Callback URL\" must be the URL of your Concourse server with <code>/sky/issuer/callback</code> appended. This address must be reachable by Microsoft - it can't be <code>localhost</code>.</p> <p>For example, Concourse's own CI server's callback URL would be:</p> <pre><code>https://ci.concourse-ci.org/sky/issuer/callback\n</code></pre> <p>You will be given a Client ID and a Client Secret for your new application. The client ID and secret must then be configured on the <code>web</code> node by setting the following env:</p> <pre><code>CONCOURSE_MICROSOFT_CLIENT_ID=myclientid\nCONCOURSE_MICROSOFT_CLIENT_SECRET=myclientsecret\n</code></pre> <p>Consult <code>concourse web --help</code> for a full list of flags with descriptions.</p>"},{"location":"docs/auth-and-teams/configuring/microsoft/#authorization","title":"Authorization","text":"<p>Warning</p> <p>Individual user auth is disabled due to a quirk with with Microsoft returning unique IDs but non-unique usernames</p> <p>Groups can be authorized for a team by passing the following flags to fly set-team:</p> <ul> <li><code>--microsoft-group=GROUP_NAME</code> - Authorize an entire group's members.</li> </ul> <p>For example:</p> <pre><code>fly set-team -n my-team \\\n    --microsoft-group my-group\n</code></pre> <p>...or via <code>--config</code> for setting user roles:</p> <pre><code>roles:\n  - name: member\n    microsoft:\n      groups: [ \"my-groups\" ]\n</code></pre>"},{"location":"docs/auth-and-teams/configuring/microsoft/#configuring-main-team-authorization","title":"Configuring <code>main</code> Team Authorization","text":"<p>Microsoft groups can be added to the <code>main</code> team authorization config by setting the following env on the <code>web</code> node:</p> <pre><code>CONCOURSE_MAIN_TEAM_MICROSOFT_GROUP=my-group\n</code></pre> <p>Multiple teams may be specified by comma-separating them.</p>"},{"location":"docs/getting-started/","title":"Getting Started","text":"<p>This tutorial will guide you through the basics of creating Concourse pipelines. You will use a local instance of Concourse running on your machine to run pipelines.</p> <p>Before getting started you should have the following installed:</p> <ul> <li>Docker</li> <li>Docker-compose</li> </ul> <p>This tutorial assumes you understand what Linux containers are and how to work with them. If you know what a Dockerfile is and how to make your own then you're probably good to jump into this tutorial. If you're not familiar with Linux containers then you may want to get started with Docker first before diving into this tutorial.</p> <p>It will also help if you know how to read YAML. We have a quick Intro to YAML if you're not familiar with the syntax.</p> <p>Note</p> <p>If you have any feedback for this tutorial please share it in  this GitHub discussion.</p> <p>If you get stuck at any point, you can try asking for help on our Discord server  in the #need-help channel.</p>"},{"location":"docs/getting-started/hello-world/","title":"Hello World Pipeline","text":""},{"location":"docs/getting-started/hello-world/#creating-a-pipeline","title":"Creating a Pipeline","text":"<p>Let's start where all tutorials start, with a <code>Hello World!</code> example!</p> <p>In this section you're going to create a pipeline that simply prints <code>Hello world!</code> to the console. While building up the pipeline we will pause to explain the core pieces of the pipeline.</p> <p>Let's first answer: what is a pipeline made up from?</p> <p>The simplest Concourse pipeline is made of two objects:</p> <ul> <li>An unordered list of Jobs which contains...</li> <li>An ordered list of Steps</li> </ul> <p>If you've used other pipeline building tools in the past, then what you think of as a pipeline is probably most similar to a job in Concourse.</p> <p>For our <code>Hello World!</code> pipeline we will need one job with one step. This is the smallest pipeline you can make in Concourse. The single step is what will print <code>Hello World!</code> to the console.</p> <p>Create and open a new file called <code>hello-world.yml</code>. Inside that file let's add the first top-level key, jobs.</p> <pre><code>jobs:\n</code></pre> <p>The jobs key is where we define the list of jobs that should make up our pipeline. The order of the jobs does not matter. The order of jobs does not define the structure of the pipeline. We'll get into pipeline structure and job ordering later when we talk about Resources and passed constraints.</p>"},{"location":"docs/getting-started/hello-world/#add-a-job","title":"Add a job","text":"<p>We only need one job right now so let's add a single job named <code>hello-world-job</code>.</p> <pre><code>jobs:\n  - name: hello-world-job\n</code></pre> <p>Awesome, we have a job named <code>hello-world-job</code>! Now we need to add a <code>step</code> to our job. To define a list of steps a job should execute, we need to add the plan key to our job.</p> <pre><code>jobs:\n  - name: hello-world-job\n    plan:\n</code></pre>"},{"location":"docs/getting-started/hello-world/#add-a-step","title":"Add a Step","text":"<p>Unlike jobs, the order of steps does matter! Concourse will run the steps in the order that they are listed. Let's carefully place a task step as the first (and only) step in our job.</p> <pre><code>jobs:\n  - name: hello-world-job\n    plan:\n      - task: hello-world-task\n</code></pre> <p>Fantastic! Now we need to tell Concourse how to run our task step. We do that by providing a task config.</p> <pre><code>jobs:\n  - name: hello-world-job\n    plan:\n      - task: hello-world-task\n        config:\n</code></pre> <p>At this point we are going to pause to explain steps a bit more.</p>"},{"location":"docs/getting-started/hello-world/#what-is-a-step","title":"What is a step?","text":"<p>A step is a single container running on a Concourse worker. Each step in a job plan runs in its own container. You can run anything you want inside the container (i.e. run my tests, run this bash script, build this image, etc.).</p> <p>So if you have a job with five steps Concourse will create five containers, one for each step. Therefore, we need to tell Concourse the following about each step:</p> <ul> <li>What type of worker to run the task on (linux/windows/darwin)</li> <li>What container image to use (<code>Linux only</code>)</li> <li>What command to run inside the container</li> </ul> <p>Info</p> <p>Concourse currently only supports Linux containers. Concourse does not yet run Windows containers.  Darwin does not have native containers.</p>"},{"location":"docs/getting-started/hello-world/#fill-in-the-task-config","title":"Fill in the Task Config","text":"<p>Let's answer the previous three questions for our <code>hello-world-task</code>:</p> <ul> <li>What type of worker to run the task on (linux/windows/darwin)<ul> <li>Linux, because our docker-composed Concourse only has one linux worker. You can verify this by   running <code>fly -t tutorial workers</code></li> </ul> </li> <li>What container image to use (Linux only)<ul> <li>We'll use the super small busybox image</li> </ul> </li> <li>What command to run inside the container<ul> <li><code>echo \"Hello world!\"</code></li> </ul> </li> </ul> <p>You can view the task documentation to see all configurable options for tasks. For now, you can add the following task config to the step.</p> <pre><code>jobs:\n  - name: hello-world-job\n    plan:\n      - task: hello-world-task\n        config:\n          # Tells Concourse which type of worker this task should run on\n          platform: linux\n          # This is one way of telling Concourse which container image to use for a\n          # task. We'll explain this more when talking about resources\n          image_resource:\n            type: registry-image\n            source:\n              repository: busybox # images are pulled from docker hub by default\n              tag: latest\n          # The command Concourse will run inside the container\n          # echo \"Hello world!\"\n          run:\n            path: echo\n            args: [ \"Hello world!\" ]\n</code></pre>"},{"location":"docs/getting-started/hello-world/#run-the-pipeline","title":"Run the pipeline","text":"<p>That's the whole pipeline! You can now set it, unpause, and trigger it using the fly cli. You can then view it from the web ui.</p> <pre><code>fly -t tutorial set-pipeline -p hello-world -c hello-world.yml\n# pipelines are paused when first created\nfly -t tutorial unpause-pipeline -p hello-world\n# trigger the job and watch it run to completion\nfly -t tutorial trigger-job --job hello-world/hello-world-job --watch\n</code></pre> <p>You'll see extra output than what we're showing below (the busybox image being downloaded) but the last four lines will be the task executing.</p> <pre><code>selected worker: 701785fa43a1\nrunning echo Hello world!\nHello world!\nsucceeded\n</code></pre> <p>You can also view the build from the web UI by clicking on the job and expanding the <code>hello-world-task</code> step.</p> <p></p> <p>Congratulations on building your first Concourse pipeline!</p> <p>In the next section we will build upon what we have learned about tasks and introduce inputs and outputs, which allow you to pass files between tasks.</p> <p>Note</p> <p>If you have any feedback for this tutorial please share it in  this GitHub discussion.</p>"},{"location":"docs/getting-started/inputs-outputs/","title":"Inputs and Outputs","text":""},{"location":"docs/getting-started/inputs-outputs/#overview","title":"Overview","text":"<p>This section is going to go over how to pass data between different steps in a job. We'll continue building on our <code>hello-world.yml</code> pipeline.</p> <p>In the previous section we learned that steps are where we tell Concourse what to run (i.e. run my tests, run this bash script, build this image, etc.). We are going to expand on the concept of steps and show you how to pass artifacts/files between tasks using <code>inputs</code> and <code>outputs</code>.</p>"},{"location":"docs/getting-started/inputs-outputs/#what-are-inputs-and-outputs","title":"What are inputs and outputs","text":"<p>The simple answer is that inputs and outputs are directories that get passed between steps. We'll refer to both inputs and outputs as artifacts.</p> <p>Let's start exploring how artifacts work by adding a <code>task-config.outputs</code> to our <code>hello-world-task</code>.</p> <pre><code>jobs:\n  - name: hello-world-job\n    plan:\n      - task: hello-world-task\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source:\n              repository: busybox\n              tag: latest\n          # Adds a \"the-artifact\" directory to our task\n          outputs:\n            - name: the-artifact\n          run:\n            # Change the command to `ls -lF` to see\n            # what the task sees in its working directory\n            path: ls\n            args: [ \"-lF\" ]\n</code></pre> <p>Update the pipeline and trigger the job:</p> <pre><code>$ fly -t tutorial set-pipeline -p hello-world -c hello-world.yml\n$ fly -t tutorial trigger-job --job hello-world/hello-world-job --watch\n...\nselected worker: 57d7419112ca\nrunning ls -lF\ntotal 4\ndrwxr-xr-x    2 root     root          4096 Apr  8 16:42 the-artifact/\nsucceeded\n</code></pre> <p>We can see that in the task's current working directory there is now a folder called <code>the-artifact</code>. Concourse makes output directories for you and will pass any contents inside the folder onto later steps. Let's see how that works next.</p>"},{"location":"docs/getting-started/inputs-outputs/#passing-outputs-to-another-task","title":"Passing outputs to another task","text":"<p>To pass artifacts from one task to another, the first task must declare an output. The second task must then declare an input with the exact same name. Let's update the pipeline to do the following:</p> <ul> <li>Have the first task create a file inside <code>the-artifact</code></li> <li>Create a second task to read the file inside <code>the-artifact</code> from the previous step</li> </ul> <pre><code>jobs:\n  - name: hello-world-job\n    plan:\n      - task: hello-world-task\n        config:\n          platform: linux\n          image_resource: &amp;image # Declaring a YAML anchor\n            type: registry-image\n            source:\n              repository: busybox\n              tag: latest\n          outputs:\n            - name: the-artifact\n          run:\n            # This is a neat way of embedding a script into a task\n            path: sh\n            args:\n              - -cx\n              - |\n                ls -l .\n                echo \"hello from another step!\" &gt; the-artifact/message\n      # Add a second task that reads the contents of the-artifact/message\n      - task: read-the-artifact\n        config:\n          platform: linux\n          image_resource: *image\n          # To receive \"the-artifact\", specify it as an input\n          inputs:\n            - name: the-artifact\n          run:\n            path: sh\n            args:\n              - -cx\n              - |\n                ls -l .\n                cat the-artifact/message\n</code></pre> <p>Update the pipeline and trigger the job:</p> <pre><code>$ fly -t tutorial set-pipeline -p hello-world -c hello-world.yml\n$ fly -t tutorial trigger-job --job hello-world/hello-world-job --watch\n\ninitializing\nselected worker: 57d7419112ca\nrunning sh -cx ls -l .\necho \"hello from another step!\" &gt; the-artifact/message\n\n+ ls -l .\ntotal 4\ndrwxr-xr-x    2 root     root          4096 Feb 26 19:09 the-artifact\n+ echo 'hello from another step!'\ninitializing\nselected worker: 57d7419112ca\nrunning sh -cx ls -l .\ncat the-artifact/message\n\n+ ls -l .\ntotal 4\ndrwxr-xr-x    1 root     root          4096 Feb 26 19:09 the-artifact\n+ cat the-artifact/message\nhello from another step!\nsucceeded\n</code></pre> <p>It's a bit hard to see when the first task stops and the second one starts in the terminal. Looking at the build from the web UI makes this clearer:</p> <p></p> <p>With the above pipeline we can see that the file made in the first step is made available in the second step via the <code>the-artifact</code>.</p>"},{"location":"docs/getting-started/inputs-outputs/#how-does-concourse-track-artifacts","title":"How does Concourse track artifacts?","text":"<p>As Concourse is running the steps in your job, it is creating a list of named artifacts. Let's see what that looks like for the pipeline we just ran.</p> <ul> <li>Concourse runs the task step <code>hello-world-task</code>   with output <code>the-artifact</code></li> </ul> <p>Concourse creates an empty artifact, assigns it the name <code>the-artifact</code>, and mounts it inside the task container.</p> <ul> <li>Concourse runs the task step <code>read-the-artifact</code>   with input <code>the-artifact</code></li> </ul> <p>Concourse looks up, in its list of artifacts for the build, for an artifact named <code>the-artifact</code>, and mounts  it inside the task container. If no input with that name is found then the build would fail.</p> <p>The next section will introduce you to the concept of Resources.</p> <p>Note</p> <p>If you have any feedback for this tutorial please share it in  this GitHub discussion.</p>"},{"location":"docs/getting-started/quick-start/","title":"Quick Start","text":""},{"location":"docs/getting-started/quick-start/#docker-compose-concourse","title":"Docker Compose Concourse","text":"<p>Concourse is distributed as a single concourse binary, making it easy to run just about anywhere, especially with Docker.</p> <p>If you'd like to get Concourse running somewhere quickly so you can start to kick the tires, the easiest way is to use our docker-compose.yml:</p> <pre><code>$ curl -O https://concourse-ci.org/docker-compose.yml\n$ docker-compose up -d\nCreating docs_concourse-db_1 ...\nCreating docs_concourse-db_1 ... done\nCreating docs_concourse_1 ...\nCreating docs_concourse_1 ... done\n</code></pre> <p>Concourse will be running at localhost:8080 on your machine. You can log in with the username/password as <code>test</code>/<code>test</code>.</p> <p></p>"},{"location":"docs/getting-started/quick-start/#install-fly","title":"Install Fly","text":"<p>Next, install the <code>fly</code> CLI by downloading it from the web UI. If you're on version &gt;=v7.14.0 of Concourse, you can visit http://localhost:8080/download-fly.</p> <p>Otherwise, you can follow these steps to install fly for your OS:</p> LinuxMacOSWindows (Powershell) <pre><code>curl 'http://localhost:8080/api/v1/cli?arch=amd64&amp;platform=linux' -o fly\nchmod +x ./fly\nmv ./fly /usr/local/bin/\n</code></pre> <pre><code>curl 'http://localhost:8080/api/v1/cli?arch=amd64&amp;platform=darwin' -o fly\nchmod +x ./fly\nmv ./fly /usr/local/bin/\n</code></pre> <pre><code>$concoursePath = 'C:\\concourse\\'\nmkdir $concoursePath\n[Environment]::SetEnvironmentVariable('PATH', \"$ENV:PATH;${concoursePath}\", 'USER')\n$concourseURL = 'http://localhost:8080/api/v1/cli?arch=amd64&amp;platform=windows'\nInvoke-WebRequest $concourseURL -OutFile \"${concoursePath}\\fly.exe\"\n</code></pre> <p>Use fly login to log into your local Concourse as the <code>test</code> user:</p> <pre><code>fly -t tutorial login -c http://localhost:8080 -u test -p test\n</code></pre> <p>You've successfully logged in if you see the following output:</p> <pre><code>logging in to team 'main'\n\ntarget saved\n</code></pre> <p>You'll notice that every fly command in this tutorial has to have the target (-t tutorial) specified. This is annoying when you only have one Concourse to target, but it helps ensure you don't trigger a job on the wrong Concourse instance. It will save you from hurting yourself!</p> <p>Once you've confirmed everything is up and running by logging in through fly and the web UI, you can move onto the next section.</p> <p>Note</p> <p>If you have any feedback for this tutorial please share it in this  GitHub discussion</p>"},{"location":"docs/getting-started/resources/","title":"Resources","text":""},{"location":"docs/getting-started/resources/#the-heart-of-concourse","title":"The Heart of Concourse","text":"<p>Resources are the heart of Concourse. Resources make Concourse tick and are the source of automation within all Concourse pipelines. Resources are how Concourse interacts with the outside world. Here's a short list of things that resources can do:</p> <ul> <li>Run a job every five minutes: Time resource.</li> <li>Run tests on new commits to the main branch: Git resource.</li> <li>Publish a new release of your app on   Github: GitHub Release resource.</li> <li>Pull or push the latest image of your   app: Registry-image resource</li> </ul> <p>Resources can do a lot of things! The main goal of resources is to represent some external system or object in your pipeline. That external thing can then be used as a trigger for your Jobs or your Jobs can push back and modify the external system or object. It all depends on the resource you use and what features its author has implemented.</p> <p>Resources are also how Concourse tries to stay as technology agnostic as possible. For example: Concourse doesn't care what version control system you store your code in, if you deploy apps with Helm or Terraform, or what language your apps are built in. If you can put your latest and hottest tech behind the resource interface then Concourse can understand your workflow.</p> <p>The Concourse team bundles a few basic resource types that come with the Linux release that you can download from GitHub. You'll notice that the Linux tarball is much larger than the macOS or Windows tarball because of all the bundled resources.</p> <p>Note</p> <p>You can find out which resources a worker has by running:</p> <pre><code>fly -t tutorial workers --details\n</code></pre> <p>Resources only run on Linux workers because resources are distributed as Linux container images. There are currently no resources for macOS or Windows. Only task steps can run on macOS or Windows workers.</p>"},{"location":"docs/getting-started/resources/#versions","title":"Versions","text":"<p>Resources represent the external system or object to Concourse by emitting versions. When a new version is emitted by a resource, that is how Concourse knows to start jobs connected to the resource.</p> <p>A version is a map of key-value strings that a resource generates to uniquely identify the state of the external system or object.</p> <p>For example, the git resource emits versions based on the SHA of new commits it finds. A single version from the git resource will look like this to Concourse.</p> <pre><code>{\n  \"ref\": \"ce63af135a85029153ebd0f5dfe42c5481641b74\"\n}\n</code></pre> <p>Which looks like this in the web UI:</p> <p></p> <p>Let's start digging into resources a bit more by going over the resource interface.</p>"},{"location":"docs/getting-started/resources/#resource-interface","title":"Resource Interface","text":"<p>Resources are container images that contain three executables. Each executable is run by a different type of step within a pipeline:</p> <ul> <li><code>/opt/resource/check</code> - implicitly run when a job contains   a get step. Should return the latest version from the external system or   object. Its responsibility is to find new versions. Is never part of a Job's build plan.</li> <li><code>/opt/resource/in</code> - run in a get step. in is given a specific version (   generated by a <code>check</code> or <code>put</code> step) and retrieves the files and   information representing that version from the external system or object.</li> <li><code>/opt/resource/out</code> - run in a put step. Generates a new version, usually   based on some input generated by another step in the job. Depending on the resource, this may mean sending something   to the external system. For the git resource, this means pushing commits to the external git repository.</li> </ul> <p>That's a high-level overview of the resource interface, which should help you understand what's going on with resources when we start using them in the next section.</p>"},{"location":"docs/getting-started/resources/#automatically-triggering-jobs-with-get-steps","title":"Automatically Triggering Jobs With Get Steps","text":"<p>We're going to create a new pipeline now. This pipeline is going to:</p> <ul> <li>Fetch commits from a Git repository that contains an app</li> <li>Run some unit tests for that app</li> <li>Publish our app to GitHub</li> </ul> <p>We have a very basic app in our github.com/concourse/examples repo that we'll use in your pipeline. You should fork this repository so you can continue following along. We're going to build the Go app under the <code>apps/golang/</code> directory.</p> <p>When creating a new Job or Pipeline, it can be helpful to think of all the external things the job will need in order to run, and declare them as Resources in our pipeline. We know we'll need our Git repository with our app's code, so we'll declare that as a resource first.</p> <p>We will use the git resource to represent our Git repository. The <code>README.md</code> contains the documentation for how to use the resource.</p> <pre><code>resources:\n  - name: repo\n    type: git\n    source:\n      uri: https://github.com/concourse/examples.git\n      username: &lt;user&gt;\n      password: github_pat_...\n</code></pre> <p>Note</p> <p>You'll need to generate a Personal Access Token for GitHub in order to complete this tutorial. You can make a fine-grained access token on this page. The only permission required is <code>read-write</code> access to <code>content</code>. You may scope the token to your fork of the <code>examples</code> repository.</p> <p>We've added a top-level key to our pipeline called resources, which takes an unordered list of resouces that can be referenced by jobs in our pipeline.</p> <p>When declaring a resource, Concourse only requires you to declare the <code>name</code> and <code>type</code>. The <code>name</code> is how jobs will reference the resource.</p> <p>Depending on the resource type you're using, the <code>source</code> will likely have one or more required fields. This is specific to each resource type, so refer to the documentation of the resource type to find out what fields are required.</p> <p>Next, we can add a job that references our resource. Let's add a job to our pipeline that, for now, downloads our git repo. We'll use the <code>get</code> step to do this.</p> <pre><code>resources:\n  - name: repo\n    type: git\n    source:\n      uri: https://github.com/concourse/examples.git\n      username: &lt;user&gt;\n      password: github_pat_...\n\njobs:\n  - name: tests\n    plan:\n      - get: repo\n</code></pre> <p>Let's set and run this pipeline.</p> <pre><code>fly -t tutorial set-pipeline --pipeline go-app --config pipeline.yml\nfly -t tutorial unpause-pipeline --pipeline go-app\n</code></pre> <p>To change things up, let's trigger our <code>tests</code> job from the web UI. From the dashboard you can click on the pipeline header to see the entire pipeline. You'll see two boxes, the left box representing our repo resource, and the right box representing our <code>tests</code> job.</p> <p>Clicking on the <code>tests</code> job will take you to the Builds page of the job. In the top-right corner there will be a plus-sign button you can click to trigger the job. Click that button and wait for the job to start and complete. You can click the <code>get</code> step to expand it and see the metadata fetched by the <code>git</code> resource.</p> <p></p> <pre><code>resources:\n  - name: repo\n    type: git\n    source:\n      uri: https://github.com/concourse/examples.git\n      username: &lt;user&gt;\n      password: github_pat_...\n\njobs:\n  - name: tests\n    plan:\n      - get: repo\n      - task: tests\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: # Use the Golang image from Docker Hub\n              repository: golang\n              tag: latest\n          inputs:\n            - name: repo\n          run:\n            path: sh\n            args:\n              - -c\n              - |\n                cd repo/apps/golang\n                go test -v .\n</code></pre> <p>There are a few things happening in this <code>task</code> step we added.</p> <p>First, we had to choose a container image to use to run our tests in. To run our Go tests we need an image with the <code>go</code> binary. The golang image from Docker Hub is an easy solution to reach for here, so we tell Concourse to use that image to run this task. Concourse uses the registry-image resource to download the Golang image.</p> <p>Next, we needed to provide our task with a copy of our git repo. The <code>get: repo</code> step added an artifact named <code>repo</code> that our task can reference as an input. Concourse will then take care of mounting a copy of our repo from the <code>get</code> step into our task's container.</p> <p>The last part is us writing a small shell script that changes to the directory of our Go tests and finally runs <code>go test -v .</code>. We added <code>-v</code> to get a little more output from the tests.</p> <p>Let's update our pipeline and trigger the job from the web UI again.</p> <pre><code>fly -t tutorial set-pipeline --pipeline go-app --config pipeline.yml\n</code></pre> <p></p> <p>Our tests run successfully! Let's update the job so it will run on every new commit instead of waiting for us to manually start the job. We do this by adding <code>trigger: true</code> to the <code>get</code> step.</p> <pre><code>resources:\n  - name: repo\n    type: git\n    source:\n      uri: https://github.com/concourse/examples.git\n      username: &lt;user&gt;\n      password: github_pat_...\n\njobs:\n  - name: tests\n    plan:\n      - get: repo\n        # Cause job to run on new commits\n        trigger: true\n      - task: tests\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: # Use the Golang image from Docker Hub\n              repository: golang\n              tag: latest\n          inputs:\n            - name: repo\n          run:\n            path: sh\n            args:\n              - -c\n              - |\n                cd repo/apps/golang\n                go test -v .\n</code></pre> <pre><code>fly -t tutorial set-pipeline --pipeline go-app --config pipeline.yml\n</code></pre> <p>This change is also visually represented in the web view of the pipeline. The line connecting the resource to the job changes from a dashed line:</p> <p></p> <p>To a solid line:</p> <p></p> <p>Let's test this out by making a commit. In the <code>examples</code> repo, open <code>apps/golang/main.go</code>. Let's break the tests by changing the <code>AddSix()</code> function to add seven instead of six.</p> <pre><code>func AddSix(i float64) float64 {\n    return i + 7\n}\n</code></pre> <p>Commit the change and then wait for the pipeline to pick it up and run the <code>tests</code> job. You can click on the resource to see when Concourse finds the commit. You can then back out to the overview of the pipeline and see the job start on its own.</p> <p></p> <p>Note</p> <p>By default, Concourse runs the <code>check</code> script of a resource every ~1 minute. You can click on the resource to see when it was last checked. You can also press the refresh button to force a check to run.</p> <p>Let's fix the tests by undoing our change.</p> <pre><code>func AddSix(i float64) float64 {\n    return i + 6\n}\n</code></pre> <p></p> <p>In the next section we'll add a job to publish our app as a release on GitHub.</p>"},{"location":"docs/getting-started/resources/#publishing-with-put-steps","title":"Publishing with Put Steps","text":"<p>We're going to add another job now that will publish our little Go app as a GitHub release using the GitHub release resource.</p> <p>This job will need two pieces of information in order to create a GitHub release:</p> <ul> <li>The git commit to publish as the release</li> <li>What we want the tag to be (e.g. v0.0.1)</li> </ul> <p>The git commit is already represented by the <code>repo</code> resource defined in our pipeline. We need to add another resource to represent the tag we want to publish.</p> <p>There are many different ways one could represent the tag value, but since we've already got a git repository setup, we'll continue to leverage that.</p> <p>Let's create a new branch in our <code>examples</code> repository called <code>version</code>. We'll create a file in there that will contain the name of the next tag we want to publish our app under. You can run the following commands to do this:</p> <pre><code># Make a new, empty branch called \"version\"\ngit switch --orphan version\n# You can make the initial version whatever you want\necho \"v0.0.1\" &gt; next-version\ngit add next-version\ngit commit -m \"initial version\"\ngit push -u origin version\n</code></pre> <p>Now we can add this as a resource in our pipeline, so our <code>resources</code> look like this:</p> <pre><code>resources:\n  - name: repo\n    type: git\n    source:\n      uri: https://github.com/concourse/examples.git\n      username: &lt;user&gt;\n      password: github_pat_...\n\n  - name: version\n    type: git\n    source:\n      uri: https://github.com/concourse/examples.git\n      username: &lt;user&gt;\n      password: github_pat_...\n      branch: version\n</code></pre> <p>Publishing to GitHub is also going to need another resource because it represents something external to Concourse. Let's add a third resource that will represent our release on GitHub.</p> <pre><code>resources:\n  - name: repo\n    type: git\n    source:\n      uri: https://github.com/concourse/examples.git\n      username: &lt;user&gt;\n      password: github_pat_...\n\n  - name: version\n    type: git\n    source:\n      uri: https://github.com/concourse/examples.git\n      username: &lt;user&gt;\n      password: github_pat_...\n      branch: version\n\n  - name: release\n    type: github-release\n    source:\n      owner: concourse\n      repository: examples\n      access_token: github_pat_...\n</code></pre> <p>Now we can tie these resources together in a job. We'll create a job called <code>publish</code> that will:</p> <ul> <li>Get the last commit that passed the <code>tests</code> job.</li> <li>Get the <code>next-version</code> file from our <code>version</code> branch.</li> <li>Compile our Go app into a binary to publish alongside our release. We'll write a  <code>task</code> step to do this.</li> <li>Publish a new GitHub release, uploading the binary, and tagging the commit that last passed <code>tests</code>.</li> </ul> <p>Add this job under the <code>jobs</code> key in your pipeline:</p> <pre><code>- name: publish\n  plan:\n    - get: repo\n      passed: [ tests ] # Only use commits that passed the 'tests' job\n    - get: version\n    - task: build-binary\n      config:\n        platform: linux\n        image_resource:\n          type: registry-image\n          source:\n            repository: golang\n            tag: latest\n        inputs:\n          - name: repo\n        outputs: # Declare an output so the put step can upload our binary\n          - name: final-build\n        run:\n          path: sh\n          args:\n            - -c\n            - |\n              output=\"$(pwd)/final-build\"\n              cd repo/apps/golang\n              go build -o \"${output}/addsix\" .\n    - put: release\n      params:\n        # Comes from the 'get: version' step\n        name: version/next-version\n        tag: version/next-version\n        # Comes from the 'get: repo' step\n        commitish: repo/.git/ref #refer to the git-resource README\n        # Comes from the output of our 'task: build-binary' step\n        globs: final-build/addsix\n</code></pre> <p>Here's the entire pipeline put together:</p> <pre><code>resources:\n  - name: repo\n    type: git\n    source:\n      uri: https://github.com/concourse/examples.git\n      username: &lt;user&gt;\n      password: github_pat_...\n\n  - name: version\n    type: git\n    source:\n      uri: https://github.com/concourse/examples.git\n      username: &lt;user&gt;\n      password: github_pat_...\n      branch: version\n\n  - name: release\n    type: github-release\n    source:\n      owner: concourse\n      repository: examples\n      access_token: github_pat_...\n\njobs:\n  - name: tests\n    plan:\n      - get: repo\n        trigger: true\n      - task: tests\n        config:\n          platform: linux\n          image_resource: &amp;image #YAML anchor, kind of like a variable\n            type: registry-image\n            source:\n              repository: golang\n              tag: latest\n          inputs:\n            - name: repo\n          run:\n            path: sh\n            args:\n              - -c\n              - |\n                cd repo/apps/golang\n                go test -v .\n\n  - name: publish\n    plan:\n      - get: repo\n        passed: [ tests ]\n      - get: version\n      - task: build-binary\n        config:\n          platform: linux\n          image_resource: *image\n          inputs:\n            - name: repo\n          outputs:\n            - name: final-build\n          run:\n            path: sh\n            args:\n              - -cx\n              - |\n                output=\"$(pwd)/final-build\"\n                cd repo/apps/golang\n                go build -o \"${output}/addsix\" .\n      - put: release\n        params:\n          name: version/next-version\n          tag: version/next-version\n          commitish: repo/.git/ref\n          globs: [ final-build/addsix ]\n</code></pre> <p>Let's update our pipeline:</p> <pre><code>fly -t tutorial set-pipeline --pipeline go-app --config pipeline.yml\n</code></pre> <p>The pipeline should look like this in the web UI:</p> <p></p> <p>Go ahead and manually trigger the publish job. It should complete successfully and the logs should look similar to this:</p> <p></p> <p>Note</p> <p>You'll notice that an extra <code>get</code> step snuck in there after  the <code>put</code> step at the end. Concourse does this automatically after  every <code>put</code> step because a <code>put</code> step has no outputs. So if you ran a <code>put</code> step in the middle of your job and  wanted to use whatever you just published/uploaded in a later step, you wouldn't have access to it. Concourse  resolves this by automatically adding and running a <code>get</code> step.</p> <p>This extra <code>get</code> is not always necessary of course. If you want to have Concourse skip adding this <code>get</code> step,  you can set <code>no_get</code> to <code>true</code> in the <code>put</code> step.  This will save a few seconds off of your builds.</p> <p>On GitHub, you should see your release published, along with the binary <code>addsix</code> attached to the release:</p> <p></p> <p>That's the whole pipeline! Congratulations on testing, building, and publishing a silly little Go app with a Concourse pipeline \ud83c\udf89</p> <p></p>"},{"location":"docs/getting-started/resources/#using-external-resource-types","title":"Using External Resource Types","text":"<p>Concourse comes bundled with a lot of resources that are enough for most people to start using Concourse with. However, users will want to extend Concourse to work with all sorts of systems and that means bringing your own Resource Types.</p> <p>Adding a resource type to your pipeline looks very similar to adding a resource. You can even override the bundled resource types by re-declaring them in your pipeline.</p> <p>Remember, a resource is a container image. So to pull in a new resource type you need to tell Concourse where to pull the image from. This is done by using the built-in registry-image resource. The process of adding a resource type is just like adding a regular resource, just under the top-level <code>resource_types</code> key instead.</p> <p>If you're looking for more resource types, there's a catalog of them at resource-types.concourse-ci.org.</p>"},{"location":"docs/getting-started/resources/#time-for-takeoff","title":"Time For Takeoff \u2708\ufe0f","text":"<p>This brings us to the end of the tutorial. You should have a basic understanding about how to read Concourse pipelines and start creating your own. Here are some other parts of the site to help you take off with Concourse:</p> <ul> <li>How-To Guides - Contains practical guides   for working with pipelines and examples of common pipeline workflows,   such as git   and container workflows.</li> <li>Check out all the reference documentation:<ul> <li>Jobs</li> <li>Tasks</li> <li>Resources</li> <li>Resource Types</li> </ul> </li> <li>Implement your own resource type</li> <li>Find other resources at resource-types.concourse-ci.org or put   <code>_something_ concourse resource</code> into your favorite search engine.</li> </ul> <p>Best of luck on your automation journey!</p> <p>Note</p> <p>If you have any feedback for this tutorial please share it in this  GitHub discussion</p>"},{"location":"docs/install/","title":"Install","text":"<p>A Concourse installation is composed of a <code>web</code> node, a <code>worker</code> node, and a PostgreSQL node.</p> <p>There are many ways to deploy Concourse, depending on your personal preference. The Quick Start guide shows how to get Concourse up and running quickly via Docker Compose, and there is also an official Concourse Helm chart.</p> <p>The documentation found here will primarily focus on the <code>concourse</code> CLI, which is the lowest common denominator, and can also be directly used if you want to just run Concourse yourself on real hardware or your own managed VMs.</p> <p>The high-level steps to follow for installing Concourse are:</p> <ol> <li>Setup a Postgres database</li> <li>Generate Secrets for the web and worker nodes</li> <li>Install the web node</li> <li>Install the worker node</li> </ol> <p>Note</p> <p>We don't document every configuration option for the <code>web</code> and <code>worker</code> commands. To view all flags you can  run the following <code>docker</code> commands.</p> <pre><code>docker run -t concourse/concourse web --help\ndocker run -t concourse/concourse worker --help\n</code></pre>"},{"location":"docs/install/concourse-cli/","title":"The <code>concourse</code> CLI","text":"<p>The <code>concourse</code> CLI can be downloaded from the latest GitHub release - make sure to grab the appropriate archive for your platform. Each <code>concourse-*</code> archive contains the following files:</p> <pre><code>concourse/bin/concourse\nconcourse/bin/gdn            # Linux only\nconcourse/fly-assets/...\nconcourse/resource-types/... # Linux only\n</code></pre> <p>The Linux release is the largest among all the platforms because it is prepackaged with a bundle of resource types like the git, time, and registry-image resources. Resources only run on Linux workers, that's why the other platforms are not bundled with resources; resources don't currently exist for non-linux platforms.</p> <p>When extracted, the <code>concourse</code> binary will auto-discover its sibling assets based on its file location, so you may extract it anywhere. On Linux a typical install location is <code>/usr/local/concourse</code>:</p> <pre><code>tar -zxf concourse-*.tgz -C /usr/local\n</code></pre> <p>From there, you can either add <code>/usr/local/concourse/bin</code> to your <code>$PATH</code>, or just execute <code>/usr/local/concourse/bin/concourse</code> directly.</p>"},{"location":"docs/install/concourse-cli/#configuring-concourse","title":"Configuring <code>concourse</code>","text":"<p>All Concourse <code>web</code> and <code>worker</code> node configuration is defined statically via flags. For a full list of flags, you can pass <code>--help</code> to any command.</p> CLI Commands<pre><code>concourse web --help\nconcourse worker --help\nconcourse quickstart --help\nconcourse migrate --help\nconcourse generate-key --help\nconcourse land-worker --help\nconcourse retire-worker --help\n</code></pre> <p>Each flag can also be set via an environment variable. The env var for each flag is based on the flag name uppercased, preceded with <code>CONCOURSE_</code> and dashes (<code>-</code>) replaced with underscores (<code>_</code>). These are also shown in <code>--help</code>.</p> <p>Various sections in documentation may refer to configuration via env vars rather than flags, but they are both equivalent and interchangeable. Env vars are simply easier to reference in isolation and are more useful to copy-paste.</p>"},{"location":"docs/install/generating-keys/","title":"Generating Keys","text":""},{"location":"docs/install/generating-keys/#generating-the-keys","title":"Generating the Keys","text":"<p>Concourse's various components use RSA keys to verify tokens and worker registration requests.</p> <p>A minimal deployment will require the following keys:</p> <ul> <li>Session Signing Key<ul> <li>Used by the <code>web</code> node for signing and verifying user session tokens.</li> </ul> </li> <li>TSA Host Key<ul> <li>Used by the <code>web</code> node for the SSH worker registration gateway server (\"TSA\").</li> <li>The public key is given to each <code>worker</code> node to verify the remote host when connecting via   SSH.</li> </ul> </li> <li>Worker Key<ul> <li>Each <code>worker</code> node verifies its registration with the <code>web</code> node via a SSH   key.</li> <li>The public key must be listed in the <code>web</code> node's authorized worker keys file in order for the   worker to register.</li> </ul> </li> </ul> <p>To generate these keys, run:</p> <pre><code>concourse generate-key -t rsa -f ./session_signing_key\nconcourse generate-key -t ssh -f ./tsa_host_key\nconcourse generate-key -t ssh -f ./worker_key\n</code></pre> <p>or use <code>ssh-keygen</code>:</p> <pre><code>ssh-keygen -t rsa -b 4096 -m PEM -f ./session_signing_key\nssh-keygen -t rsa -b 4096 -m PEM -f ./tsa_host_key\nssh-keygen -t rsa -b 4096 -m PEM -f ./worker_key\n</code></pre> <p>At this point you should have the following files:</p> <ul> <li><code>session_signing_key</code></li> <li><code>tsa_host_key</code></li> <li><code>tsa_host_key.pub</code></li> <li><code>worker_key</code></li> <li><code>worker_key.pub</code></li> </ul> <p>You can remove the <code>session_signing_key.pub</code> file if you have one, it is not needed by any process in Concourse.</p>"},{"location":"docs/install/generating-keys/#multiple-worker-keys","title":"Multiple Worker Keys","text":"<p>Currently you have one <code>worker_key</code>. You can use this one key-pair with multiple <code>worker</code> nodes. Another good strategy is to have each worker or group of workers use a key that's unique to that one worker or group of workers.</p> <p>In the second case you will end up with multiple private and public worker keys. The <code>web</code> node needs to know about all of the public worker keys. To pass all public worker keys to the <code>web</code> node create a file that contains all of the worker public keys. A common name for this file is <code>authorized_worker_keys.pub</code>. The file should look like this, with one public key per line.</p> <pre><code>$ cat authorized_worker_keys.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQCgKtVnbGRJ7Y63QKoO+loS...\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDU6lA4gSRYIc4MXzphJ2l5...\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDgNU7KBz/QQusPO52pNcea...\n</code></pre> <p>You should now have all the necessary keys needed to deploy Web and Worker nodes.</p>"},{"location":"docs/install/running-postgres/","title":"Running a PostgreSQL Node","text":"<p>Concourse uses PostgreSQL for storing all data and coordinating work in a multi- <code>web</code> node installation.</p>"},{"location":"docs/install/running-postgres/#prerequisites","title":"Prerequisites","text":"<p>PostgreSQL v11 or above is required, though the latest available version is recommended.</p>"},{"location":"docs/install/running-postgres/#running-postgresql","title":"Running PostgreSQL","text":"<p>How this node is managed is up to you; Concourse doesn't actually have much of an opinion on it, it just needs a database. By default Concourse will try connecting to a database named <code>atc</code>.</p> <p>How to install PostgreSQL is really dependent on your platform. Please refer to your Linux distribution or operating system's documentation.</p> <p>For the most part, the instruction on Linux should look something like this:</p> <pre><code>sudo apt install postgresql\nsudo su postgres -c \"createuser $(whoami)\"\nsudo su postgres -c \"createdb --owner=$(whoami) atc\"\n</code></pre> <p>This will install PostgreSQL (assuming your distro uses <code>apt</code>), create a user, and create a database that the current UNIX user can access, assuming this same user is going to be running the<code>web</code> node. This is a reasonable default for distros like Ubuntu and Debian which default PostgreSQL to <code>peer</code> auth.</p>"},{"location":"docs/install/running-postgres/#resource-utilization","title":"Resource utilization","text":"<p>CPU usage: this is one of the most volatile metrics, and one we try pretty hard to keep down. There will be near-constant database queries running, and while we try to keep them very simple, there is always more work to do. Expect to feed your database with at least a couple cores, ideally four to eight. Monitor this closely as the size of your deployment and the amount of traffic it's handling increases, and scale accordingly.</p> <p>Memory usage: similar to CPU usage, but not quite as volatile.</p> <p>Disk usage: pipeline configurations and various bookkeeping metadata for keeping track of jobs, builds, resources, containers, and volumes. In addition, all build logs are stored in the database. This is the primary source of disk usage. To mitigate this, log retention can be defined by pipeline authors by using  <code>job.build_log_retention</code>. Concourse operators can also configure a default Build log retention policy that applies to all pipelines.</p> <p>Bandwidth usage: well, it's a database, so it most definitely uses the network. Something important to consider here is the number of simultaneous connections that the database server itself will allow. Postgres exposes a  <code>max_connections</code> configuration variable, and depending on how many web nodes you are running and the size of their connection pool, you may need to tune these two numbers against each other.</p> <p>Highly available: Up to you. Clustered PostgreSQL is kind of new and probably tricky to deploy, but there are various cloud solutions for this.</p> <p>Outbound traffic: None</p> <p>Inbound traffic: Only ever from the <code>web</code> node</p>"},{"location":"docs/install/running-web/","title":"Running a <code>web</code> node","text":"<p>The <code>web</code> node is responsible for running the web UI, API, and as well as performing all pipeline scheduling. It's basically the brain of Concourse.</p>"},{"location":"docs/install/running-web/#prerequisites","title":"Prerequisites","text":"<p>Nothing special - the <code>web</code> node is a pretty simple Go application that can be run like a 12-factor app.</p>"},{"location":"docs/install/running-web/#running-concourse-web","title":"Running <code>concourse web</code>","text":"<p>The <code>concourse</code> CLI can run as a <code>web</code> node via the <code>web</code> subcommand.</p> <p>Before running it, let's configure a local user so we can log in:</p> <pre><code>CONCOURSE_ADD_LOCAL_USER=myuser:mypass\nCONCOURSE_MAIN_TEAM_LOCAL_USER=myuser\n</code></pre> <p>This will configure a single user, <code>myuser</code>, with the password <code>mypass</code>. You'll probably want to change those to sensible values, and later you may want to configure a proper auth provider - check out Auth &amp; Teams whenever you're ready.</p> <p>Next, you'll need to configure the session signing key, the SSH key for the worker gateway, and the authorized worker key. Check Generating Keys to learn what these are and how they are created.</p> <pre><code>CONCOURSE_SESSION_SIGNING_KEY=path/to/session_signing_key\nCONCOURSE_TSA_HOST_KEY=path/to/tsa_host_key\nCONCOURSE_TSA_AUTHORIZED_KEYS=path/to/authorized_worker_keys.pub\n</code></pre> <p>Finally, <code>web</code> needs to know how to reach your Postgres database. This can be set like so:</p> <pre><code>CONCOURSE_POSTGRES_HOST=127.0.0.1 # default\nCONCOURSE_POSTGRES_PORT=5432      # default\nCONCOURSE_POSTGRES_DATABASE=atc   # default\nCONCOURSE_POSTGRES_USER=my-user\nCONCOURSE_POSTGRES_PASSWORD=my-password\n</code></pre> <p>If you're running PostgreSQL locally, you can probably just point it to the socket and rely on the <code>peer</code> auth:</p> <pre><code>CONCOURSE_POSTGRES_SOCKET=/var/run/postgresql\n</code></pre> <p>Now that everything's set, run:</p> <pre><code>concourse web\n</code></pre> <p>All logs will be emitted to <code>stdout</code>, with any panics or lower-level errors being emitted to <code>stderr</code>.</p>"},{"location":"docs/install/running-web/#resource-utilization","title":"Resource utilization","text":"<p>CPU usage: peaks during pipeline scheduling, primarily when scheduling Jobs. Mitigated by adding more <code>web</code> nodes. In this regard, <code>web</code> nodes can be considered compute-heavy more than anything else at large scale.</p> <p>Memory usage: not very well classified at the moment as it's not generally a concern. Give it a few gigabytes and keep an eye on it.</p> <p>Disk usage: none</p> <p>Bandwidth usage: aside from handling external traffic, the <code>web</code> node will at times have to stream bits out from one worker and into another while executing Steps.</p> <p>Highly available: <code>yes</code>; web nodes can all be configured the same (aside from <code>--peer-address</code>) and placed behind a load balancer. Periodic tasks like garbage-collection will not be duplicated for each node.</p> <p>Horizontally scalable: yes; they will coordinate workloads using the database, resulting in less work for each node and thus lower CPU usage.</p> <p>Outbound traffic:</p> <ul> <li><code>db</code> on its configured port for persistence</li> <li><code>db</code> on its configured port for locking and coordinating in a multi-<code>web</code> node deployment</li> <li>other <code>web</code> nodes (possibly itself) on an ephemeral port when a worker   is forwarded through the web node's TSA</li> </ul> <p>Inbound traffic:</p> <ul> <li><code>worker</code> connects to the TSA on port <code>2222</code> for registration</li> <li><code>worker</code> downloads inputs from the ATC during <code>fly execute</code> via   its external URL</li> <li>external traffic to the ATC API via the web UI and <code>fly</code> CLI</li> </ul>"},{"location":"docs/install/running-web/#operating-a-web-node","title":"Operating a <code>web</code> node","text":"<p>The <code>web</code> nodes themselves are stateless - they don't store anything on disk, and coordinate entirely using the database.</p>"},{"location":"docs/install/running-web/#scaling","title":"Scaling","text":"<p>The <code>web</code> node can be scaled up for high availability. They'll also roughly share their scheduling workloads, using the database to synchronize. This is done by just running more <code>web</code> commands on different machines, and optionally putting them behind a load balancer.</p> <p>To run a cluster of <code>web</code> nodes, you'll first need to ensure they're all pointing to the same PostgreSQL server.</p> <p>Next, you'll need to configure a peer address. This is a DNS or IP address that can be used to reach this <code>web</code> node from other <code>web</code> nodes. Typically this uses a private IP, like so:</p> <pre><code>CONCOURSE_PEER_ADDRESS=10.10.0.1\n</code></pre> <p>This address will be used for forwarded worker connections, which listen on the ephemeral port range.</p> <p>Finally, if all of these nodes are going to be accessed through a load balancer, you'll need to configure the external URL that will be used to reach your Concourse cluster:</p> <pre><code>CONCOURSE_EXTERNAL_URL=https://ci.example.com\n</code></pre> <p>Aside from the peer URL, all configuration must be consistent across all <code>web</code> nodes in the cluster to ensure consistent results.</p>"},{"location":"docs/install/running-web/#database-connection-pooling","title":"Database connection pooling","text":"<p>You may wish to configure the max number of parallel database connections that each node makes. There are two pools to configure: one for serving API requests, and one used for all the backend work such as pipeline scheduling.</p> <pre><code>CONCOURSE_API_MAX_CONNS=10     # default\nCONCOURSE_BACKEND_MAX_CONNS=50 # default\n</code></pre> <p>There are some non-configurable connection pools. They take up the following number of connections per pool:</p> <ul> <li>Garbage Collection: 5</li> <li>Lock: 1</li> <li>Worker Registration: 1</li> </ul> <p>The sum of these numbers across all <code>web</code> nodes should not be greater than the maximum number of simultaneous connections your Postgres server will allow. See  <code>db</code> node resource utilization for more information.</p> <p>For example, if 3 <code>web</code> nodes are configured with the values shown above then your PostgreSQL server should be configured with a connection limit of at least 201: <code>(10 + 50 + 5 + 1 + 1) * 3 web nodes</code>.</p>"},{"location":"docs/install/running-web/#reloading-worker-authorized-key","title":"Reloading worker authorized key","text":"<p>While Running <code>concourse web</code>, the authorized worker key file, which contains all public keys for the workers, is loaded at startup. During the lifecycle of a  <code>web</code> node new <code>worker</code> keys might be added or old ones removed. To perform a live reload of this file you can send a <code>SIGHUP</code> signal to the <code>concourse web</code> process. The process will remain running and Concourse will reload the authorized worker key file.</p>"},{"location":"docs/install/running-web/#restarting-upgrading","title":"Restarting &amp; Upgrading","text":"<p>The <code>web</code> nodes can be killed and restarted willy-nilly. No draining is necessary; if the <code>web</code> node was orchestrating a build it will continue where it left off when it comes back, or the build will be picked up by one of the other <code>web</code> nodes.</p> <p>To upgrade a <code>web</code> node, stop its process and start a new one using the newly installed <code>concourse</code>. Any database migrations will be run automatically on start. If <code>web</code> nodes are started in parallel, only one will run the migrations.</p> <p>We don't currently guarantee a lack of funny-business if you're running mixed Concourse versions - database migrations can perform modifications that confuse other <code>web</code> nodes. So there may be some turbulence during a rolling upgrade, but everything should stabilize once all <code>web</code> nodes are running the latest version.</p> <p>If you want more control over when the database migrations happen and know if they were successful you can use the <code>concourse migrate</code> command. The <code>migrate</code> command accepts the same <code>CONCOURSE_POSTGRES_*</code> env vars as the <code>concourse web</code> command.</p>"},{"location":"docs/install/running-web/#downgrading","title":"Downgrading","text":"<p>If you're stuck in a pinch and need to downgrade from one version of Concourse to another, you can use the <code>concourse migrate</code> command.</p> <p>First, grab the desired migration version by running the following:</p> <pre><code># make sure this is the *old* Concourse binary\n$ concourse migrate --supported-db-version\n1551110547\n</code></pre> <p>That number (yours will be different) is the expected migration version for that version of Concourse.</p> <p>Next, run the following with the new Concourse binary:</p> <pre><code>concourse migrate --migrate-db-to-version=1551110547\n</code></pre> <p>This will need the same <code>CONCOURSE_POSTGRES_*</code> configuration described in Running <code>concourse web</code>.</p> <p>Once this completes, switch all <code>web</code> nodes back to the older <code>concourse</code> binary and you should be good to go.</p>"},{"location":"docs/install/running-web/#configuring-the-web-node","title":"Configuring the <code>web</code> node","text":""},{"location":"docs/install/running-web/#giving-your-cluster-a-name","title":"Giving your cluster a name","text":"<p>If you've got many Concourse clusters that you switch between, you can make it slightly easier to notice which one you're on by giving each cluster a name:</p> <pre><code>CONCOURSE_CLUSTER_NAME=production\n</code></pre> <p>When set, this name will be shown in the top bar when viewing the dashboard.</p>"},{"location":"docs/install/running-web/#configuring-ingress-traffic","title":"Configuring ingress traffic","text":"<p>If your web nodes are going to be accessed multiple network layers, you will need to set <code>CONCOURSE_EXTERNAL_URL</code> to a URL accessible by your Concourse users. If you don't set this property, logging in will incorrectly redirect to its default value of <code>127.0.0.1</code>.</p> <p>If your web node(s) will be behind a load balancer or reverse proxy then you will need to ensure connections made by  <code>fly intercept</code> are properly handled by upgrading the connection. Here is a sample nginx configuration that upgrades connections made by <code>fly intercept</code>.</p> <pre><code>server {\n  server_name ci.example.com;\n\n  add_header Strict-Transport-Security \"max-age=31536000\" always;\n  ssl_stapling on;\n  ssl_stapling_verify on;\n\n  # Proxy main concourse traffic\n  location / {\n      proxy_pass http://concourse.local:8080/;\n      proxy_set_header Host $host;\n      proxy_set_header X-Real-IP $remote_addr;\n      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n      proxy_set_header X-Forwarded-Proto $scheme;\n      proxy_set_header X-Forwarded-Protocol $scheme;\n      proxy_set_header X-Forwarded-Host $http_host;\n  }\n\n  # Proxy fly intercept traffic\n  location ~ /hijack$ {\n      proxy_pass http://concourse.local:8080;\n      proxy_set_header Host $host;\n      proxy_set_header X-Real-IP $remote_addr;\n      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n      proxy_set_header X-Forwarded-Proto $scheme;\n      proxy_set_header X-Forwarded-Protocol $scheme;\n      proxy_set_header X-Forwarded-Host $http_host;\n      # Upgrade connection\n      proxy_set_header Upgrade $http_upgrade;\n      proxy_set_header Connection \"upgrade\";\n  }\n}\n</code></pre>"},{"location":"docs/install/running-web/#tls-via-lets-encrypt","title":"TLS via Let's Encrypt","text":"<p>Concourse can be configured to automatically acquire a TLS certificate via Let's Encrypt:</p> <pre><code># Enable TLS\nCONCOURSE_TLS_BIND_PORT=443\n\n# Enable Let's Encrypt\nCONCOURSE_ENABLE_LETS_ENCRYPT=true\n</code></pre> <p>Warning</p> <p>Concourse's Let's Encrypt integration works by storing the TLS certificate and key in the database, so it is  imperative that you enable database encryption as well.</p> <p>By default, Concourse will reach out to Let's Encrypt's ACME CA directory. An alternative URL can be configured like so:</p> <pre><code>CONCOURSE_LETS_ENCRYPT_ACME_URL=https://acme.example.com/directory\n</code></pre> <p>In order to negotiate the certificate, your <code>web</code> node must be reachable by the ACME server. There are intentionally no publicly listed IP addresses to whitelist, so this typically means just making your <code>web</code> node publicly reachable.</p>"},{"location":"docs/install/running-web/#build-log-retention","title":"Build log retention","text":"<p>Build logs are stored in the DB - if they are not cleanup up every once in a while, the storage usage for build logs will continue to grow as more builds run. While this is usually fine for small Concourse instances, as you scale up, you may run into storage concerns.</p> <p>To clean up old build logs, you can configure Concourse to periodically scan for builds whose logs should be reaped based on a log retention policy, skipping over any paused pipelines and jobs. When a build's logs are reaped, they are no longer visible in the UI.</p> <p>Concourse can be configured with a default build log retention policy for all jobs:</p> <pre><code>CONCOURSE_DEFAULT_BUILD_LOGS_TO_RETAIN=50\nCONCOURSE_DEFAULT_DAYS_TO_RETAIN_BUILD_LOGS=14\n</code></pre> <p>With these settings, Concourse will keep the latest 50 builds for each job. If a job runs more than 50 builds in 14 days, all of those builds will be retained until 14 days after they ran.</p> <p>Some jobs have differing retention requirements - you can configure  <code>build_log_retention_policy</code> schema on a job-by-job basis.</p> <p>You can also configure Concourse with maximum values for build log retention policies to prevent jobs from retaining their build logs for too long:</p> <pre><code>CONCOURSE_MAX_BUILD_LOGS_TO_RETAIN=100\nCONCOURSE_MAX_DAYS_TO_RETAIN_BUILD_LOGS=30\n</code></pre> <p>With these settings,  <code>build_log_retention_policy.builds</code> is capped at 100, and  <code>build_log_retention_policy.days</code> is capped at 30.</p>"},{"location":"docs/install/running-web/#enabling-audit-logs","title":"Enabling audit logs","text":"<p>A very simplistic form of audit logging can be enabled with the following vars:</p> <pre><code># Enable auditing for all api requests connected to builds.\nCONCOURSE_ENABLE_BUILD_AUDITING=true\n\n# Enable auditing for all api requests connected to containers.\nCONCOURSE_ENABLE_CONTAINER_AUDITING=true\n\n# Enable auditing for all api requests connected to jobs.\nCONCOURSE_ENABLE_JOB_AUDITING=true\n\n# Enable auditing for all api requests connected to pipelines.\nCONCOURSE_ENABLE_PIPELINE_AUDITING=true\n\n# Enable auditing for all api requests connected to resources.\nCONCOURSE_ENABLE_RESOURCE_AUDITING=true\n\n# Enable auditing for all api requests connected to system transactions.\nCONCOURSE_ENABLE_SYSTEM_AUDITING=true\n\n# Enable auditing for all api requests connected to teams.\nCONCOURSE_ENABLE_TEAM_AUDITING=true\n\n# Enable auditing for all api requests connected to workers.\nCONCOURSE_ENABLE_WORKER_AUDITING=true\n\n# Enable auditing for all api requests connected to volumes.\nCONCOURSE_ENABLE_VOLUME_AUDITING=true\n</code></pre> <p>When enabled, API requests will result in an info-level log line like so:</p> <pre><code>{\"timestamp\":\"2019-05-09T14:41:54.880381537Z\",\"level\":\"info\",\"source\":\"atc\",\"message\":\"atc.audit\",\"data\":{\"action\":\"Info\",\"parameters\":{},\"user\":\"test\"}}\n{\"timestamp\":\"2019-05-09T14:42:36.704864093Z\",\"level\":\"info\",\"source\":\"atc\",\"message\":\"atc.audit\",\"data\":{\"action\":\"GetPipeline\",\"parameters\":{\":pipeline_name\":[\"booklit\"],\":team_name\":[\"main\"]},\"user\":\"test\"}}\n</code></pre>"},{"location":"docs/install/running-web/#configuring-defaults-for-resource-types","title":"Configuring defaults for resource types","text":"<p>Defaults for the \"core\" resource types (those that show up under the Concourse org) that comes with Concourse can be set cluster-wide by passing in a configuration file. The format of the file is the name of the resource type followed by an arbitrary configuration.</p> <p>Documentation for each resource type's configuration is in each implementation's <code>README</code>.</p> <pre><code>CONCOURSE_BASE_RESOURCE_TYPE_DEFAULTS=./defaults.yml\n</code></pre> <p>For example, a <code>defaults.yml</code> that configures the entire cluster to use a registry mirror would have:</p> <pre><code>registry-image:\n  registry_mirror:\n    host: https://registry.mirror.example.com\n</code></pre>"},{"location":"docs/install/running-worker/","title":"Running a <code>worker</code> node","text":"<p>The <code>worker</code> node registers with the <code>web</code> node and is then used for executing builds and performing resource <code>check</code>s. It doesn't really decide much on its own.</p>"},{"location":"docs/install/running-worker/#prerequisites","title":"Prerequisites","text":"<ul> <li>Linux:<ul> <li>We test and support the following distributions. Minimum kernel version tested is 5.15.<ul> <li>Ubuntu 22.04</li> <li>Ubuntu 24.04</li> </ul> </li> <li>Other Requirements:<ul> <li>User namespaces must be enabled.</li> <li>To enforce memory limits on tasks, memory + swap accounting must be enabled.</li> </ul> </li> </ul> </li> <li>Windows/Darwin:<ul> <li>no special requirements (that we know of).</li> </ul> </li> </ul> <p>Note</p> <p>Windows containers are currently not supported and Darwin does not have native containers. Steps will run inside  a temporary directory on the Windows/Darwin worker. Any dependencies needed for your tasks (e.g. git, .NET, golang,  ssh) should be pre-installed on the worker. Windows/Darwin workers do not come with any resource types.</p>"},{"location":"docs/install/running-worker/#running-concourse-worker","title":"Running <code>concourse worker</code>","text":"<p>The <code>concourse</code> CLI can run as a <code>worker</code> node via the <code>worker</code> subcommand.</p> <p>First, you'll need to configure a directory for the worker to store data:</p> <pre><code>CONCOURSE_WORK_DIR=/opt/concourse/worker\n</code></pre> <p>This is where all the builds run, and where all resources are fetched in to, so make sure it's backed by enough storage.</p> <p>Next, point the worker at your <code>web</code> node like so:</p> <pre><code>CONCOURSE_TSA_HOST=10.0.2.15:2222\nCONCOURSE_TSA_PUBLIC_KEY=path/to/tsa_host_key.pub\nCONCOURSE_TSA_WORKER_PRIVATE_KEY=path/to/worker_key\n</code></pre> <p>Finally start the worker:</p> <pre><code># run with -E to forward env config, or just set it all as root\nsudo -E concourse worker\n</code></pre> <p>Note that the worker must be run as <code>root</code> because it orchestrates containers.</p> <p>All logs will be emitted to <code>stdout</code>, with any panics or lower-level errors being emitted to <code>stderr</code>.</p>"},{"location":"docs/install/running-worker/#resource-utilization","title":"Resource utilization","text":"<p>CPU usage: almost entirely subject to pipeline workloads. More resources configured will result in more checking, and in-flight builds will use as much CPU as they want.</p> <p>Memory usage: also subject to pipeline workloads. Expect usage to increase with the number of containers on the worker and spike as builds run.</p> <p>Bandwidth usage: again, almost entirely subject to pipeline workloads. Expect spikes from periodic checking, though the intervals should spread out over enough time. Resource fetching and pushing will also use arbitrary bandwidth.</p> <p>Disk usage: arbitrary data will be written as builds run, and resource caches will be kept and garbage collected on their own life cycle. We suggest going for a larger disk size if it's not too much trouble. All state on disk must not outlive the worker itself; it is all ephemeral. If the worker is re-created (i.e. fresh VM/container and all processes were killed), it should be brought back with an empty disk.</p> <p>Highly available: not applicable. Workers are inherently singletons, as they're being used as drivers running entirely different workloads.</p> <p>Horizontally scalable: yes; workers directly correlate to your capacity required by however many pipelines, resources, and in-flight builds you want to run. It makes sense to scale them up and down with demand.</p> <p>Outbound traffic:</p> <ul> <li>External traffic to arbitrary locations as a result of periodic resource checking and running builds</li> <li>External traffic to the <code>web</code> node's configured external URL when downloading the inputs for a  <code>fly execute</code></li> <li>External traffic to the <code>web</code> node's TSA port (<code>2222</code>) for registering the worker</li> <li>If P2P streaming is enabled there will be traffic to other workers.</li> </ul> <p>Inbound traffic:</p> <ul> <li>From the <code>web</code> node on port <code>7777</code> (Garden) and <code>7788</code> (BaggageClaim). These ports do not need to be   exposed, they are forwarded to the web node via the ssh connection on port <code>2222</code>.</li> <li>If P2P streaming is enabled there will be traffic to other workers.</li> </ul>"},{"location":"docs/install/running-worker/#operating-a-worker-node","title":"Operating a <code>worker</code> node","text":"<p>The <code>worker</code> nodes are designed to be stateless and as interchangeable as possible. Tasks and Resources bring their own Docker images, so you should never have to install dependencies on the worker. Windows and Darwin workers are the exception to this. Any dependencies should be pre-installed on Windows and Darwin workers.</p> <p>In Concourse, all important data is represented by Resources, so the workers themselves are dispensable. Any data in the work-dir is ephemeral and should go away when the worker machine is removed - it should not be persisted between worker VM or container re-creates.</p>"},{"location":"docs/install/running-worker/#scaling-workers","title":"Scaling Workers","text":"<p>More workers should be added to accommodate more pipelines. To know when this is necessary you should probably set up Metrics and keep an eye on container counts. If average container count starts to approach 200 or so per worker, you should probably add another worker. Load average is another metric to keep an eye on.</p> <p>To add a worker, just create another machine for the worker and follow the Running <code>concourse worker</code> instructions again.</p> <p>Note</p> <p>It doesn't make sense to run multiple workers on one machine since they'll both be contending for the same  physical resources. Workers should be given their own VMs or physical machines to maximize resource usage.</p>"},{"location":"docs/install/running-worker/#horizontal-vs-vertical-scaling","title":"Horizontal vs Vertical Scaling","text":"<p>The answer to whether you should scale your workers horizontally or vertically depends heavily on what workloads your pipelines are running. Anecdotally though, we have seen that a lot of smaller workers (horizontal scaling) is usually better than a few large workers (vertical scaling).</p> <p>Again, this is not an absolute answer! You will have to test this out against the workloads your pipelines demand and adjust based on the Metrics that you are tracking.</p>"},{"location":"docs/install/running-worker/#worker-heartbeating-stalling","title":"Worker Heartbeating &amp; Stalling","text":"<p>Workers will continuously heartbeat to the Concourse cluster in order to remain registered and healthy. If a worker hasn't checked in after a while, possibly due to a network error, being overloaded, or having crashed, the web node will transition its state to <code>stalled</code> and new workloads will not be scheduled on that worker until it recovers.</p> <p>If the worker remains in this state and cannot be recovered, it can be removed using the  <code>fly prune-worker</code> command.</p>"},{"location":"docs/install/running-worker/#restarting-a-worker","title":"Restarting a Worker","text":"<p>Workers can be restarted in-place by sending <code>SIGTERM</code> to the worker process and starting it back up. Containers will remain running and Concourse will reattach to builds that were in flight.</p> <p>This is a pretty aggressive way to restart a worker, and may result in errored builds - there are a few moving parts involved and we're still working on making this airtight.</p> <p>A safer way to restart a worker is to land it by sending <code>SIGUSR1</code> to the <code>worker</code> process. This will switch the worker to the <code>landing</code> state and Concourse will stop scheduling new work on it. When all builds running on the worker have finished, the process will exit.</p> <p>You may want to enforce a timeout for draining - that way a stuck build won't prevent your workers from being upgraded. This can be enforced by common tools like <code>start-stop-daemon</code>:</p> <pre><code>start-stop-daemon \\\n  --pidfile worker.pid \\\n  --stop \\\n  --retry USR1/300/TERM/15/KILL\n</code></pre> <p>This will send <code>SIGUSR1</code>, wait up to 5 minutes, and then send <code>SIGTERM</code>. If it's still running, it will be killed after an additional 15 seconds.</p> <p>Once the timeout is enforced, there's still a chance that builds that were running will continue when the worker comes back.</p>"},{"location":"docs/install/running-worker/#gracefully-removing-a-worker","title":"Gracefully Removing a Worker","text":"<p>When a worker machine is going away, it should be retired. This is similar to landing, except at the end the worker is completely unregistered, along with its volumes and containers. This should be done when a worker's VM or container is being destroyed.</p> <p>To retire a worker, send <code>SIGUSR2</code> to the <code>worker</code> process. This will switch the worker to <code>retiring</code> state, and Concourse will stop scheduling new work on it. When all builds running on the worker have finished, the worker will be removed and the <code>worker</code> process will exit.</p> <p>Just like with landing, you may want to enforce a timeout for draining - that way a stuck build won't prevent your workers from being upgraded. This can be enforced by common tools like <code>start-stop-daemon</code>:</p> <pre><code>start-stop-daemon \\\n  --pidfile worker.pid \\\n  --stop \\\n  --retry USR2/300/TERM/15/KILL\n</code></pre> <p>This will send <code>SIGUSR2</code>, wait up to 5 minutes, and then send <code>SIGTERM</code>. If it's still running, it will be killed after an additional 15 seconds.</p>"},{"location":"docs/install/running-worker/#configuring-the-worker-node","title":"Configuring the <code>worker</code> node","text":""},{"location":"docs/install/running-worker/#tagging-workers","title":"Tagging Workers","text":"<p>If there's something special about your worker and you'd like to target builds at it specifically, you can configure tags like so:</p> <pre><code>CONCOURSE_TAG=\"tag-1,tag-2\"\n</code></pre> <p>A tagged worker is taken out of the default placement logic. Tagged workers will not be used for any untagged Steps.</p> <p>To run build steps on a tagged worker, specify the <code>tags</code> on any particular step in your job.</p> <p>To perform resource <code>check</code>s on a tagged worker, specify  <code>tags</code> on the resource declaration.</p>"},{"location":"docs/install/running-worker/#team-workers","title":"Team Workers","text":"<p>If you want to isolate **all workloads ** for a team then you can configure a worker to belong to a single team like so:</p> <pre><code>CONCOURSE_TEAM=\"lightweavers\"\n</code></pre> <p>Once an untagged team worker is registered Concourse will schedule all untagged builds for that team on its team worker( s). Builds for this team will no longer be scheduled on any untagged, non-team workers.</p> <p>It is possible to have a Concourse cluster made up of only team workers and have zero non-team workers, though this is not a common setup because resource utilization across all workers ends up underutilized. It is useful though if you have a particular team with heavy workloads that usually bothers other teams pipelines.</p>"},{"location":"docs/install/running-worker/#tags-and-team-workers","title":"Tags and Team Workers","text":"<p>When you have a worker configured with tag(s) and a team like so:</p> <pre><code>CONCOURSE_TAG=\"tag-1,tag-2\"\nCONCOURSE_TEAM=\"lightweavers\"\n</code></pre> <p>Only steps that are tagged and from the specified team will be scheduled on such a worker. Any untagged work the team has will land on either:</p> <ol> <li>Untagged team workers belonging to the team, or</li> <li>Untagged workers not configured to a specific team</li> </ol>"},{"location":"docs/install/running-worker/#healthcheck-endpoint","title":"Healthcheck Endpoint","text":"<p>The worker will automatically listen on port <code>8888</code> as its healthcheck endpoint. It will return a <code>HTTP 200</code> status code with an empty body on a successful check. A successful check means the worker can reach the Garden and BaggageClaim servers.</p> <p>The healthcheck endpoint is configurable through three variables:</p> <pre><code>concourse worker --healthcheck-bind-ip=\n# IP address on which to listen for health checking requests. (default: 0.0.0.0)\n\nconcourse worker --healthcheck-bind-port\n# Port on which to listen for health checking requests. (default: 8888)\n\nconcourse worker --healthcheck-timeout\n# HTTP timeout for the full duration of health checking. (default: 5s)\n</code></pre>"},{"location":"docs/install/running-worker/#resource-types","title":"Resource Types","text":"<p>Note</p> <p>The following section only applies to Linux workers. Resource types are simply Linux container images and therefore  can't be run on Windows or Darwin workers.</p>"},{"location":"docs/install/running-worker/#bundled-resource-types","title":"Bundled Resource Types","text":"<p>Workers come prepackaged with a bundle of resource types. They are included in the tarball from the GitHub release page and are part of the concourse/concourse image.</p> <p>To view the resource types available on a worker run:</p> <pre><code>fly workers --details\n</code></pre> <p>If you want more details, like the version number of each resource, you can run:</p> <pre><code>fly curl api/v1/workers\n</code></pre>"},{"location":"docs/install/running-worker/#installing-or-upgrading-bundled-resource-types","title":"Installing or Upgrading Bundled Resource Types","text":"<p>You may want to upgrade the bundled resource types outside of Concourse upgrades or even install additional resource types on your workers to reduce the polling on some external image repository like Docker Hub.</p> <p>We will use the git resource as our example. We will assume your Concourse installation is at <code>/usr/local/concourse</code>.</p> <p>First, pull and create a container of the resource you're installing/upgrading. Grab the ID of the container that Docker creates.</p> <pre><code>$ docker run -d concourse/git-resource\nb253417142565cd5eb43902e94a2cf355d5354b583fbc686488c9a153584c6ba\n</code></pre> <p>Export the containers file system into a gzip compressed tar archive named <code>rootfs.tgz</code></p> <pre><code>docker export b253417142 | gzip &gt; rootfs.tgz\n</code></pre> <p>Create a file called <code>resource_metadata.json</code> and populate it with the following contents. Make sure the <code>type</code> does not conflict with an existing resource type when you're installing a new resource type. In our example here we're calling the type <code>gitv2</code> to avoid conflicting with the pre-existing <code>git</code> resource.</p> <pre><code>{\n  \"type\": \"gitv2\",\n  \"version\": \"1.13.0\",\n  \"privileged\": false,\n  \"unique_version_history\": false\n}\n</code></pre> <p>At this point you should have two files: <code>rootfs.tgz</code> and <code>resource_metadata.json</code>.</p> <p>Create a new directory under the <code>resource-types</code> folder in your Concourse installation directory. By convention, it should be the same name as the <code>type</code>.</p> <pre><code>mkdir /usr/local/concourse/resource-types/gitv2\n</code></pre> <p>Place the <code>rootfs.tgz</code> and <code>resource_metadata.json</code> inside the folder. Restart your worker and verify the new resource type is on there by running one of the following commands:</p> <pre><code>fly workers --details\n# or\nfly curl api/v1/workers\n</code></pre> <p>You can also verify that Concourse can create a container with the <code>rootfs.tgz</code> you made by running a simple pipeline:</p> <pre><code>resources:\n  - name: some-resource\n    type: gitv2 #change to your resource type\n    source:\n      uri: https://github.com/concourse/git-resource.git\n\njobs:\n  - name: simple-job\n    plan:\n      - get: some-resource\n</code></pre>"},{"location":"docs/install/running-worker/#configuring-runtimes","title":"Configuring Runtimes","text":"<p>The worker can be run with multiple container runtimes - containerd, Guardian, and Houdini (an experimental and the only runtime for Darwin and Windows). Only <code>containerd</code> and <code>Guardian</code> are meant for production use. <code>Guardian</code> is the default runtime for Concourse.</p> <p>Note about Architecture</p> <p>The web node (ATC) talks to all 3 runtimes via a single interface called the  Garden server. While Guardian comes packaged with a Garden server and  its flags in Concourse are unfortunately prefixed with <code>--garden-*</code>, Guardian (a runtime) and Garden  (an interface and server) are two separate tools. An analogy for Garden would be the Container Runtime  Interface (CRI) used in  Kubernetes. Kubernetes uses containerd via CRI. Concourse uses containerd via Garden.</p>"},{"location":"docs/install/running-worker/#containerd-runtime","title":"<code>containerd</code> runtime","text":"<p>To use the <code>containerd</code> runtime manually set the <code>--runtime</code> (<code>CONCOURSE_RUNTIME</code>) to <code>containerd</code> on the <code>concourse worker</code> command.</p> <p>The following is a list of the <code>containerd</code> runtime specific flags for Concourse that can be set. They are all optional and have default values.</p> <pre><code>Containerd Configuration:\n  --containerd-config=                               Path to a config file to use for the Containerd daemon. [$CONCOURSE_CONTAINERD_CONFIG]\n  --containerd-bin=                                  Path to a containerd executable (non-absolute names get resolved from $PATH). [$CONCOURSE_CONTAINERD_BIN]\n  --containerd-init-bin=                             Path to an init executable (non-absolute names get resolved from $PATH). (default: /usr/local/concourse/bin/init) [$CONCOURSE_CONTAINERD_INIT_BIN]\n  --containerd-cni-plugins-dir=                      Path to CNI network plugins. (default: /usr/local/concourse/bin) [$CONCOURSE_CONTAINERD_CNI_PLUGINS_DIR]\n  --containerd-request-timeout=                      How long to wait for requests to Containerd to complete. 0 means no timeout. (default: 5m) [$CONCOURSE_CONTAINERD_REQUEST_TIMEOUT]\n  --containerd-max-containers=                       Max container capacity. 0 means no limit. (default: 250) [$CONCOURSE_CONTAINERD_MAX_CONTAINERS]\n  --containerd-privileged-mode=                      How many privileges privileged containers get. full is equivalent to root on host. ignore means no extra privileges. fuse-only means enough to use fuse-overlayfs. (default: full) [$CONCOURSE_CONTAINERD_PRIVILEGED_MODE]\n\nContainerd Container Networking:\n  --containerd-external-ip=                          IP address to use to reach container's mapped ports. Autodetected if not specified. [$CONCOURSE_CONTAINERD_EXTERNAL_IP]\n  --containerd-dns-server=                           DNS server IP address to use instead of automatically determined servers. Can be specified multiple times. [$CONCOURSE_CONTAINERD_DNS_SERVER]\n  --containerd-restricted-network=                   Network ranges to which traffic from containers will be restricted. Can be specified multiple times. [$CONCOURSE_CONTAINERD_RESTRICTED_NETWORK]\n  --containerd-additional-hosts=                     Additional entries to add to /etc/hosts in containers. [$CONCOURSE_CONTAINERD_ADDITIONAL_HOSTS]\n  --containerd-network-pool=                         Network range to use for dynamically allocated container subnets. (default: 10.80.0.0/16) [$CONCOURSE_CONTAINERD_NETWORK_POOL]\n  --containerd-mtu=                                  MTU size for container network interfaces. Defaults to the MTU of the interface used for outbound access by the host. [$CONCOURSE_CONTAINERD_MTU]\n  --containerd-allow-host-access                     Allow containers to reach the host's network. This is turned off by default. [$CONCOURSE_CONTAINERD_ALLOW_HOST_ACCESS]\n\nDNS Proxy Configuration:\n  --containerd-dns-proxy-enable                      Enable proxy DNS server. Note: this will enable containers to access the host network. [$CONCOURSE_CONTAINERD_DNS_PROXY_ENABLE]\n</code></pre> <p>Warning</p> <p>Make sure to read A note on allowing host access  and DNS proxy to understand the implications of using <code>--containerd-allow-host-access</code> and  <code>--containerd-dns-proxy-enable</code></p>"},{"location":"docs/install/running-worker/#transitioning-from-guardian-to-containerd","title":"Transitioning from Guardian to containerd","text":"<p>If you are transitioning from <code>Guardian</code> to <code>containerd</code> you will need to convert any <code>--garden-*</code> ( <code>CONCOURSE_GARDEN_*</code>) flags to their <code>containerd</code> (<code>CONCOURSE_CONTAINERD_*</code>) counterparts:</p> Guardian Flags Containerd Flags <code>--garden-request-timeout</code><code>CONCOURSE_GARDEN_REQUEST_TIMEOUT</code> <code>--containerd-request-timeout</code><code>CONCOURSE_CONTAINERD_REQUEST_TIMEOUT</code> <code>--garden-dns-proxy-enable</code><code>CONCOURSE_GARDEN_DNS_PROXY_ENABLE</code> -<code>-containerd-dns-proxy-enable</code><code>CONCOURSE_CONTAINERD_DNS_PROXY_ENABLE</code> No equivalent CLI flag<code>CONCOURSE_GARDEN_ALLOW_HOST_ACCESS</code> <code>--containerd-allow-host-access</code><code>CONCOURSE_CONTAINERD_ALLOW_HOST_ACCESS</code> <code>--garden-network-pool</code><code>CONCOURSE_GARDEN_NETWORK_POOL</code> <code>--containerd-network-pool</code><code>CONCOURSE_CONTAINERD_NETWORK_POOL</code> <code>--garden-max-containers</code><code>CONCOURSE_GARDEN_MAX_CONTAINERS</code> <code>--containerd-max-containers</code><code>CONCOURSE_CONTAINERD_MAX_CONTAINERS</code> No equivalent CLI flag<code>CONCOURSE_GARDEN_DENY_NETWORKS</code> <code>--containerd-restricted-network</code><code>CONCOURSE_CONTAINERD_RESTRICTED_NETWORK</code> No equivalent CLI flag or ENV option.Configured through <code>garden_config.ini</code> <code>--containerd-additional-hosts</code><code>CONCOURSE_CONTAINERD_ADDITIONAL_HOSTS</code> No equivalent CLI flag<code>CONCOURSE_GARDEN_DNS_SERVER</code> <code>--containerd-dns-server</code><code>CONCOURSE_CONTAINERD_DNS_SERVER</code> No equivalent CLI flag<code>CONCOURSE_GARDEN_EXTERNAL_IP</code> <code>--containerd-external-ip</code><code>CONCOURSE_CONTAINERD_EXTERNAL_IP</code> No equivalent CLI flag<code>CONCOURSE_GARDEN_MTU</code> <code>--containerd-mtu</code><code>CONCOURSE_CONTAINERD_MTU</code>"},{"location":"docs/install/running-worker/#guardian-runtime","title":"<code>Guardian</code> runtime","text":"<p>Guardian is currently the default runtime for Concourse. It can also be set by setting the <code>--runtime</code> flag to <code>guardian</code> on the <code>concourse worker</code> command.</p> <p>The <code>concourse worker</code> command automatically configures and runs <code>Guardian</code> using the <code>gdn</code> binary, but depending on the environment you're running Concourse in, you may need to pop open the hood and configure a few things.</p> <p>The <code>gdn</code> server can be configured in two ways:</p> <ol> <li> <p>By creating a <code>config.ini</code> file and passing it as <code>--garden-config</code> (or <code>CONCOURSE_GARDEN_CONFIG</code>). The .ini file    should look something like this:     <pre><code>[server]\nflag-name=flag-value \n</code></pre>    To learn which flags can be set, consult <code>gdn server --help</code>. Each flag listed can be set under the <code>[server]</code>    heading.</p> </li> <li> <p>By setting <code>CONCOURSE_GARDEN_*</code> environment variables. This is primarily supported for backwards compatibility, and    these variables are not present in <code>concourse worker --help</code>. They are translated to flags passed to <code>gdn server</code> by    lower-casing the <code>*</code> portion and replacing underscores with hyphens.</p> </li> </ol>"},{"location":"docs/install/running-worker/#troubleshooting-and-fixing-dns-resolution","title":"Troubleshooting and fixing DNS resolution","text":"<p>Note</p> <p>The Guardian runtime took care of a lot of container creation operations for Concourse in the past. It was very  user-friendly for the project to use as a container runtime. While implementing the containerd runtime most  reported bugs were actually a difference in containerd's default behaviour compared to Guardian's. Currently  Concourse's containerd runtime mostly behaves like the Guardian runtime did. Most of the following DNS section  should apply to both runtimes.</p> <p>By default, containers created by the Guardian or containerd (will refer to both as runtime) runtime will carry over the <code>/etc/resolv.conf</code> from the host into the container. This is often fine, but some Linux distributions configure a special <code>127.x.x.x</code> DNS resolver (e.g. <code>systemd-resolved</code>).</p> <p>When the runtime copies the <code>resolv.conf</code> over, it removes these entries as they won't be reachable from the container's network namespace. As a result, your containers may not have any valid nameservers configured.</p> <p>To diagnose this problem you can <code>fly intercept</code> into a failing container and check which nameservers are in <code>/etc/resolv.conf</code>:</p> <pre><code>$ fly -t ci intercept -j concourse/concourse\nbash-5.0$ grep nameserver /etc/resolv.conf\nbash-5.0$\n</code></pre> <p>In this case it is empty, as the host only listed a single <code>127.0.0.53</code> address which was then stripped out. To fix this you'll need to explicitly configure DNS instead of relying on the default runtime behavior.</p>"},{"location":"docs/install/running-worker/#pointing-to-external-dns-servers","title":"Pointing to external DNS servers","text":"<p>If you have no need for special DNS resolution within your Concourse containers, you can configure your containers to use specific DNS server addresses external to the VM.</p> <p>The Guardian and containerd runtimes can have their DNS servers configured with flags or envs vars.</p> DNS via flags (containerd)DNS via env vars<code>config.ini</code> (Guardian) <pre><code>concourse worker --containerd-dns-server=\"1.1.1.1\" --containerd-dns-server=\"8.8.8.8\"\n</code></pre> <pre><code># containerd runtime\nCONCOURSE_CONTAINERD_DNS_SERVER=\"1.1.1.1,8.8.8.8\"\n# Guardian runtime\nCONCOURSE_GARDEN_DNS_SERVER=\"1.1.1.1,8.8.8.8\"\n</code></pre> <pre><code>[server]\n; configure Google DNS\ndns-server = 8.8.8.8\ndns-server = 8.8.4.4\n</code></pre> <p>To verify this solves your problem you can <code>fly intercept</code> into a container and check which nameservers are in <code>/etc/resolv.conf</code>:</p> <pre><code>$ fly -t ci intercept -j my-pipeline/the-job\nbash-5.0$ cat /etc/resolv.conf\nnameserver 1.1.1.1\nnameserver 8.8.8.8\nbash-5.0$ ping google.com\nPING google.com (108.177.111.139): 56 data bytes\n64 bytes from 108.177.111.139: seq=0 ttl=47 time=2.672 ms\n64 bytes from 108.177.111.139: seq=1 ttl=47 time=0.911 ms\n</code></pre>"},{"location":"docs/install/running-worker/#using-a-local-dns-server","title":"Using a local DNS server","text":"<p>If you would like to use Consul, <code>dnsmasq</code>, or some other DNS server running on the worker VM, you'll have to configure the LAN address of the VM as the DNS server and allow the containers to reach the address, like so:</p> Local DNS via flags (containerd)Local DNS via env vars<code>config.ini</code> (Guardian) <pre><code>concourse worker --containerd-dns-server=\"10.0.1.3\" --containerd-allow-host-access=\"true\"\n</code></pre> <pre><code># containerd runtime\nCONCOURSE_CONTAINERD_DNS_SERVER=\"10.0.1.3\"\nCONCOURSE_CONTAINERD_ALLOW_HOST_ACCESS=\"true\"\n# Guardian runtime\nCONCOURSE_GARDEN_DNS_SERVER=\"10.0.1.3\"\nCONCOURSE_GARDEN_ALLOW_HOST_ACCESS=\"true\"\n</code></pre> <pre><code>[server]\n; internal IP of the worker machine\ndns-server=10.0.1.3\n\n; allow containers to reach the above IP\nallow-host-access=true\n</code></pre> <p>Warning</p> <p>Make sure to read A note on allowing host access  and DNS proxy to understand the implications of using <code>allow-host-access</code></p> <p>To validate whether the changes have taken effect, you can  <code>fly intercept</code> into any container and check <code>/etc/resolv.conf</code> once again:</p> <pre><code>$ fly -t ci intercept -j my-pipeline/the-job\nbash-5.0$ cat /etc/resolv.conf\nnameserver 10.1.2.3\nbash-5.0$ nslookup concourse-ci.org\nServer:         10.1.2.3\nAddress:        10.1.2.3#53\n\nNon-authoritative answer:\nName:   concourse-ci.org\nAddress: 185.199.108.153\nName:   concourse-ci.org\nAddress: 185.199.109.153\nName:   concourse-ci.org\nAddress: 185.199.110.153\nName:   concourse-ci.org\nAddress: 185.199.111.153\n</code></pre> <p>If <code>nslookup</code> times out or fails, you may need to open up firewalls or security group configuration so that the worker VM can send UDP/TCP packets to itself.</p>"},{"location":"docs/install/running-worker/#a-note-on-allowing-host-access-and-dns-proxy","title":"A note on allowing host access and DNS proxy","text":"<p>Setting <code>allow-host-access</code> will, well, allow containers to access your host VM's network. If you don't trust your container workloads, you may not want to allow this. With host network access, containers will be able to reach out to any other locally running network processes running on the worker including the garden and baggageclaim servers which would allow them to issue commands and manipulate other containers and volumes on the same worker.</p> <p>Setting <code>dns-proxy-enable</code> will also enable <code>allow-host-access</code> (since the dns proxy will be run on the host, therefore requiring host access be enabled).</p>"},{"location":"docs/install/running-worker/#configuring-peer-to-peer-volume-streaming","title":"Configuring Peer-to-Peer Volume Streaming","text":"<p>Peer-to-Peer (P2P) volume streaming enables the workers to stream volumes directly to each other instead of always streaming volumes through the web node(s). This can reduce the time it takes for individual steps in a job to start and reduce the amount of network traffic used by the Concourse cluster.</p> <p>Experimental Feature</p> <p>This feature is experimental. It is not as robust as the default volume streaming setup which always goes  through web nodes.</p> <p>Pre-Requisites</p> <ul> <li>All worker nodes need to be able to reach each other via IP address. This usually means they are on the same LAN. You   can test this by trying to ping one worker from another worker. If even one worker does not meet this requirement then   you cannot use P2P volume streaming.</li> <li>The baggageclaim port (<code>7788</code> is the default) is open to traffic on all worker nodes. You can verify the port is open   and reaching the baggageclaim API server by hitting the <code>/volumes</code> endpoint.    <pre><code>curl http://&lt;worker-IP-address&gt;:7788/volumes\n</code></pre></li> </ul> <p>To enable P2P volume streaming you need to configure some settings on the web and worker nodes. Configure the worker nodes first. Configure the web node(s) last.</p>"},{"location":"docs/install/running-worker/#p2p-worker-configuration","title":"P2P Worker Configuration","text":"<ul> <li><code>CONCOURSE_BAGGAGECLAIM_BIND_IP=0.0.0.0</code> - Required. The worker needs to listen for traffic over <code>127.0.0.1</code> (to   receive info from the web node) as well as its LAN IP in a P2P setup. Therefore, we need to set the IP baggageclaim   binds to <code>0.0.0.0</code>.</li> <li><code>CONCOURSE_BAGGAGECLAIM_P2P_INTERFACE_NAME_PATTERN=eth0</code> - Optional. Regular expression to match a network interface   for P2P streaming. This is how a worker determines its own LAN IP address, by looking it up via the LAN interface   specified by this flag.       You can determine the name of the LAN interface for any worker by listing all network interfaces and noting which   interface has the LAN IP that you want the worker to use.       To view all available network interfaces on your worker:<ul> <li>On Linux run <code>ip addr list</code></li> <li>On MacOS run <code>ifconfig</code></li> <li>On Windows run <code>ipconfig</code>. Windows network interface names are very different from Unix device names. Example   network interface names for Windows include:    <pre><code>Ethernet 4\nLocal Area Connection* 2\nLocal Area Connection* 12\nWi-Fi 5\nBluetooth Network Connection 2\nLoopback Pseudo-Interface 1\n</code></pre></li> </ul> </li> <li><code>CONCOURSE_BAGGAGECLAIM_P2P_INTERFACE_FAMILY=4</code> - Optional. Tells the worker to use IPv4 or IPv6. Defaults to <code>4</code>   for IPv4. Set to <code>6</code> for IPv6.</li> </ul>"},{"location":"docs/install/running-worker/#p2p-web-configuration","title":"P2P Web Configuration","text":"<p>You need to tell the web node(s) to use P2P volume streaming.</p> <pre><code>CONCOURSE_ENABLE_P2P_VOLUME_STREAMING=true\n</code></pre> <p>Once that flag is set and the web node is restarted, P2P volume streaming will start occurring in your Concourse cluster.</p>"},{"location":"docs/install/upgrading-concourse/","title":"Upgrading Concourse","text":"<p>Be careful to check the \"Breaking Changes\" in the release notes - in particular, you'll want to look for any flags that have changed.</p>"},{"location":"docs/install/upgrading-concourse/#upgrading-the-web-node","title":"Upgrading the Web Node","text":"<p>The web node is upgraded by stopping the Concourse process, swapping out the <code>concourse</code> binary with the new one, and re-starting it.</p> <p>Each <code>web</code> node will automatically run database migrations on start-up and lock via the database to ensure only one of the web nodes runs the migrations. We currently do not guarantee zero-downtime upgrades, as migrations may make changes that confuse the older web nodes. This should resolve as each web node is upgraded, and shouldn't result in any inconsistent state.</p> <p>Typically, Concourse can be upgraded from any version to any other version, though around 3.x and 4.x we made some changes to how migrations are run, and as a result the following upgrade paths must be followed:</p> Current Version Upgrade Path &lt; v3.6.0 v3.6.0 -&gt; v4.0.0 -&gt; latest = v3.6.0 v4.0.0 -&gt; latest <p>We'll try to minimize this kind of thing in the future.</p> <p>Lastly, you will want to overwrite the contents of <code>concourse/fly-assets</code> with the contents from the GitHub release tarball so users can  <code>fly sync</code> to the correct version.</p>"},{"location":"docs/install/upgrading-concourse/#upgrading-the-worker-node","title":"Upgrading the Worker Node","text":"<p>The worker node is upgraded by stopping the Concourse process, swapping out the <code>concourse</code> binary with the new one, and re-starting it.</p>"},{"location":"docs/install/upgrading-concourse/#linux-workers","title":"Linux Workers","text":"<p>The Linux tarball from the GitHub release page contains extra assets that you will want to ensure are also upgraded at the same time. Make sure you overwrite the contents of the following directories:</p> <ul> <li><code>concourse/bin/...</code> - Other binaries like <code>gdn</code>, <code>runc</code>, and <code>containerd</code> are in this directory</li> <li><code>concourse/resource-types/...</code> - The location of the   default resource-types included with each Concourse release</li> </ul>"},{"location":"docs/install/upgrading-concourse/#darwin-and-windows-workers","title":"Darwin and Windows Workers","text":"<p>There are no additional steps for upgrading Darwin and Windows workers.</p>"},{"location":"docs/pipelines/","title":"Pipelines","text":"<p>A pipeline is the result of configuring Jobs and Resources together. When you configure a pipeline, it takes on a life of its own, to continuously detect resource versions and automatically queue new builds for jobs as they have new available inputs.</p> <p>The name of a pipeline has a few restrictions that are outlined here:  <code>identifier</code> schema.</p> <p>Pipelines are configured via <code>fly set-pipeline</code> or the  <code>set_pipeline</code> step as declarative YAML files which conform to the following schema:</p>"},{"location":"docs/pipelines/#pipeline-schema","title":"<code>pipeline</code> schema","text":"jobs: <code>[</code>job<code>]</code> <p>A set of jobs for the pipeline to continuously schedule. At least one job is required for  a pipeline to be valid.</p> resources: <code>[</code>resource<code>]</code> <p>A set of resources for the pipeline to continuously check.</p> resource_types: <code>[</code>resource_type<code>]</code> <p>A set of resource types for resources within the pipeline to use.</p> var_sources: <code>[</code>var_source<code>]</code> <p>A set of Var sources for the pipeline to use.</p> groups: <code>[</code>group<code>]</code> <p>A list of job groups to use for organizing jobs in the web UI.</p> <p>Groups have no functional effect on your pipeline. They are purely for making it easier to grok large pipelines  in the web UI.</p> <p>Note</p> <p>Once you have added groups to your pipeline, all jobs must be in a group.</p> Grouping Jobs <p>The following example will make the \"tests\" group the default view (since it's listed first), separating the later jobs into a \"publish\" group:</p> <pre><code>groups:\n  - name: test\n    jobs:\n      - unit\n      - integration\n  - name: publish\n    jobs:\n      - deploy\n      - shipit\n</code></pre> <p>This would display two tabs at the top of the home page: \"test\" and \"publish\".</p> <p>For a real world example of how groups can be used to simplify navigation and provide logical grouping,  see the groups used at the top of the page in the Concourse pipeline.</p> display: display_config <p>Experimental Feature</p> <p>Display was introduced in Concourse v6.6.0. It is considered an experimental feature.</p> <p>Visual configurations for personalizing your pipeline.</p> Background image <p>The following example will display an image in the background of the pipeline it is configured on.</p> <pre><code>display:\n  background_image: https://avatars1.githubusercontent.com/u/7809479?s=400&amp;v=4\n</code></pre>"},{"location":"docs/pipelines/#group_config-schema","title":"<code>group_config</code> schema","text":"name: <code>identifier</code> <p>A unique name for the group. This should be short and simple as it will be used as the tab name for navigation.</p> jobs: [<code>job.name</code>] <p>A list of jobs that should appear in this group. A job may appear in multiple groups. Neighbours of jobs in the  current group will also appear on the same page in order to give context of the location of the group in  the pipeline.</p> <p>You may also use any valid glob to represent several  jobs, e.g.:</p> <pre><code>groups:\n  - name: develop\n    jobs:\n      - terraform-*\n      - test\n      - deploy-{dev,staging}\n  - name: ship\n    jobs:\n      - deploy-prod\n  - name: all\n    jobs:\n      - \"*\"\n</code></pre> <p>In this example, the <code>develop</code> group will match <code>terraform-apply</code>, <code>terraform-destroy</code>, <code>test</code>, <code>deploy-dev</code>,  <code>deploy-staging</code>. The <code>ship</code> group will only match <code>deploy-prod</code>. The <code>all</code> group will match all jobs in the  pipeline.</p> <p>Note</p> <p>Depending on how it's used, *, {, and } have special meaning in YAML, and may need to be quoted  (as was done in the all job above)</p>"},{"location":"docs/pipelines/#display_config-schema","title":"<code>display_config</code> schema","text":"background_image: <code>string</code> <p>Allows users to specify a custom background image for the pipeline. Must be an http, https, or relative URL.</p> background_filter: <code>string</code> <p>Default <code>opacity(30%) grayscale(100%)</code>. Allows users to specify custom  CSS filters that are applied to the  <code>background_image</code>.</p>"},{"location":"docs/pipelines/setting-pipelines/","title":"Setting Pipelines","text":"<p>Pipelines are configured entirely via the <code>fly</code> CLI or the  <code>set_pipeline</code> step. There is no GUI for configuring pipelines.</p>"},{"location":"docs/pipelines/setting-pipelines/#fly-set-pipeline","title":"<code>fly set-pipeline</code>","text":"<p>To submit a pipeline configuration to Concourse from a file on your local disk you can use the <code>-c</code> or <code>--config</code> flag, like so:</p> <pre><code>fly -t example set-pipeline \\\n    --pipeline my-pipeline \\\n    --config pipeline.yml\n</code></pre> <p>This will present a diff of the changes and ask you to confirm the changes. If you accept then Concourse's pipeline configuration will switch to the pipeline definition in the YAML file specified.</p> <p>The <code>-c</code> or <code>--config</code> flag can also take in the value <code>-</code> to indicate reading from <code>stdin</code>:</p> <pre><code>cat pipeline.yml | fly -t example set-pipeline \\\n    --pipeline my-pipeline \\\n    --config -\n</code></pre> <p>Note that reading from <code>stdin</code> disables the confirmation prompt - the pipeline will be set automatically.</p>"},{"location":"docs/pipelines/setting-pipelines/#providing-static-values-for-vars","title":"Providing static values for vars","text":"<p>The pipeline configuration can contain Vars which may be replaced with static values or loaded at runtime. This allows for credentials to be extracted from a pipeline config, making it safe to check in to a public repository or pass around.</p> <p>For example, if you have a <code>pipeline.yml</code> as follows:</p> <pre><code>resources:\n  - name: private-repo\n    type: git\n    source:\n      uri: git@...\n      branch: master\n      private_key: ((private-repo-key))\n</code></pre> <p>... you could then configure this pipeline like so:</p> <pre><code>fly -t example set-pipeline \\\n    --pipeline my-pipeline \\\n    --config pipeline.yml \\\n    --var \"private-repo-key=$(cat id_rsa)\"\n</code></pre> <p>Or, if you had a <code>vars.yml</code> as follows:</p> <pre><code>private-repo-key: |\n  -----BEGIN RSA PRIVATE KEY-----\n  ...\n  -----END RSA PRIVATE KEY-----\n</code></pre> <p>... you could configure it like so:</p> <pre><code>fly -t example set-pipeline \\\n    --pipeline my-pipeline \\\n    --config pipeline.yml \\\n    --load-vars-from vars.yml\n</code></pre> <p>You can use nested fields in your <code>pipeline.yml</code> as follows:</p> <pre><code>resources:\n  - name: private-repo\n    type: git\n    source:\n      uri: git@((repo.uri))\n      branch: ((repo.branch))\n      private_key: ((\"github.com\".private-repo-key))\n</code></pre> <p>... you could configure it by <code>--load-vars-from</code> with a <code>vars.yml</code> as follows:</p> <pre><code>repo:\n  uri: github.com/...\n  branch: master\ngithub.com:\n  private-repo-key: |\n    -----BEGIN RSA PRIVATE KEY-----\n    ...\n    -----END RSA PRIVATE KEY-----\n</code></pre> <p>... or you could also configure it by passing the vars as flags:</p> <pre><code>fly -t example set-pipeline \\\n    --pipeline my-pipeline \\\n    --config pipeline.yml \\\n    --var \"repo.uri=github.com\" \\\n    --var \"repo.branch=master\" \\\n    --var \"\\\"github.com\\\".private-repo-key=$(cat id_rsa)\"\n</code></pre> <p>When configuring a pipeline, any vars not provided statically will be left to resolve at runtime. To check that all vars are resolvable, you can pass the <code>--check-creds</code> flag:</p> <pre><code>fly -t example set-pipeline \\\n    --pipeline my-pipeline \\\n    --config pipeline.yml \\\n    --load-vars-from vars.yml \\\n    --check-creds\n</code></pre> <p>This will fill in all statically-provided vars and then attempt to resolve all remaining vars server-side. If any fail to resolve, configuring the pipeline will fail.</p>"},{"location":"docs/pipelines/setting-pipelines/#fly-validate-pipeline","title":"<code>fly validate-pipeline</code>","text":"<p>To validate a local pipeline configuration without submitting it to Concourse, run <code>validate-pipeline</code>:</p> <pre><code>fly validate-pipeline --config pipeline.yml\n</code></pre> <p>By default, pipeline errors will cause <code>validate-pipeline</code> to fail, but warnings won't. To fail on both errors and warnings, pass the <code>--strict</code> flag.</p>"},{"location":"docs/pipelines/setting-pipelines/#fly-format-pipeline","title":"<code>fly format-pipeline</code>","text":"<p>To format a pipeline config in a \"canonical\" form (i.e. keys are in normal order, with <code>name</code> first for example), run:</p> <pre><code>fly format-pipeline --config pipeline.yml\n</code></pre> <p>This will print the formatted pipeline config to <code>stdout</code>. To update the file in-place, pass <code>--write/-w</code>.</p>"},{"location":"ecosystem/","title":"Ecosystem","text":"<p>Concourse is utilized by a diverse array of businesses, government agencies, open source projects and non-profit organizations. The applications of Concourse are as varied as its user community, including CI/CD for applications, continuous delivery of infrastructure, release integration, test automation, and numerous other use cases!</p> <p>If you use Concourse, or your organization offers Concourse-related services, we'd appreciate hearing from you. Please submit a pull request adding your organization's name in alphabetical order to one of the lists below, and help us showcase how many people do things continuously with Concourse.</p>"},{"location":"ecosystem/#concourse-as-a-service","title":"Concourse-as-a-Service","text":"<p>The following organizations deliver Concourse as a fully-managed cloud solution, eliminating infrastructure overhead and providing dedicated support.</p> <ul> <li>CentralCI</li> </ul>"},{"location":"ecosystem/#3rd-party-service-providers","title":"3rd Party Service Providers","text":"<p>The following organizations provide various Concourse-related services, including training, consulting, support and managed solutions.</p> <ul> <li>Altoros</li> <li>anynines</li> <li>Cycloid</li> <li>Gstack</li> <li>Pixel Air IO</li> <li>SuperOrbital</li> </ul>"},{"location":"ecosystem/#who-uses-concourse","title":"Who Uses Concourse?","text":"<p>These organizations have either added themselves to this list, or whose use of Concourse is publicly known. There are many additional Concourse users who cannot publicly disclose information about their technology stack (typically financial institutions and security firms).</p> <ol> <li>Altoros</li> <li>anynines</li> <li>Aptomi</li> <li>Armakuni</li> <li>boclips</li> <li>Cerner</li> <li>cloud.gov</li> <li>Cloud Foundry Foundation</li> <li>Comcast</li> <li>Cycloid</li> <li>Electric UI</li> <li>EngineerBetter</li> <li>Express Scripts</li> <li>Fauna</li> <li>Fidelity International</li> <li>Gardener</li> <li>(United Kingdom) Government Digital Services</li> <li>Gstack</li> <li>The Home Depot</li> <li>IBM</li> <li>LeapYear</li> <li>Napoleon Sports &amp; Casino</li> <li>Nasdaq</li> <li>Nokogiri</li> <li>RabbitMQ</li> <li>Resilient Scale</li> <li>SAP</li> <li>Smarsh</li> <li>Springer Nature</li> <li>Stark &amp; Wayne</li> <li>SUSE</li> <li>SuperOrbital</li> <li>Unit 2 Games</li> <li>United States Air Force - Kessel Run</li> <li>Varian</li> <li>Verizon</li> <li>VMware</li> <li>Webfleet Solutions</li> <li>Yahoo!</li> <li>Zipcar</li> </ol>"},{"location":"examples/","title":"Examples","text":"<p>Setting up self-contained Concourse pipelines is an excellent way to experiment before exploring the more comprehensive documentation.</p> <p>Each example presents a pipeline YAML snippet which can be copied to a local file and deployed to your instance via  <code>fly set-pipeline</code>. From there you can experiment and modify parts of the configuration to better understand how everything works. All configuration options are detailed in the Docs.</p> <p>For a practical real-world example, examine Concourse's own pipeline (and its configuration):</p>"},{"location":"examples/git-triggered/","title":"<code>git</code>-triggered job example","text":"<p>The <code>git</code> resource can be used to trigger a job.</p>"},{"location":"examples/git-triggered/#pipeline-configuration","title":"Pipeline Configuration","text":"<pre><code>---\nresources:\n  - name: concourse-docs-git\n    type: git\n    icon: github\n    source:\n      uri: https://github.com/concourse/docs\n\njobs:\n  - name: job\n    public: true\n    build_log_retention:\n      builds: 50\n    plan:\n      - get: concourse-docs-git\n        trigger: true\n      - task: list-files\n        config:\n          inputs:\n            - name: concourse-docs-git\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          run:\n            path: ls\n            args: [ \"-la\", \"./concourse-docs-git\" ]\n</code></pre>"},{"location":"examples/git-triggered/#references","title":"References","text":"<ul> <li>Resources</li> <li>Jobs</li> <li>Steps</li> <li>Tasks</li> </ul>"},{"location":"examples/golang-lib/","title":"Golang library testing example","text":"<p>You can run the tests for a Golang library across any specified versions.</p> <p>This example shows how to have multiple versions of a language, environment, or dependency fetched and integrated in to a Pipeline.</p> <p>For these Docker images, defining them as Resources has two advantages for this use case. First, this enables the pipeline to be triggered when there are new versions of those images available. Second, referencing them in the task's <code>task</code> step **<code>image</code> ** param is helpful as it will ensure consistency between the image versions fetched by the Resource and the image version running in the job.</p>"},{"location":"examples/golang-lib/#pipeline-configuration","title":"Pipeline Configuration","text":"<pre><code>---\nresources:\n  - name: golang-1.20.x-image\n    type: registry-image\n    icon: docker\n    source:\n      repository: golang\n      tag: 1.20-alpine\n\n  - name: golang-1.21.x-image\n    type: registry-image\n    icon: docker\n    source:\n      repository: golang\n      tag: 1.21-alpine\n\n  - name: golang-1.22.x-image\n    type: registry-image\n    icon: docker\n    source:\n      repository: golang\n      tag: 1.22-alpine\n\ntask-config: &amp;task-config\n  platform: linux\n  run:\n    path: /bin/sh\n    args:\n      - -c\n      - |\n        GOPATH=$PWD/go\n\n        go version\n\njobs:\n  - name: golang-1.20\n    public: true\n    build_log_retention:\n      builds: 50\n    plan:\n      - get: golang-1.20.x-image\n        trigger: true\n      - task: run-tests\n        image: golang-1.20.x-image\n        config:\n          &lt;&lt;: *task-config\n\n  - name: golang-1.21\n    public: true\n    build_log_retention:\n      builds: 50\n    plan:\n      - get: golang-1.21.x-image\n        trigger: true\n      - task: run-tests\n        image: golang-1.21.x-image\n        config:\n          &lt;&lt;: *task-config\n\n  - name: golang-1.22\n    public: true\n    build_log_retention:\n      builds: 50\n    plan:\n      - get: golang-1.22.x-image\n        trigger: true\n      - task: run-tests\n        image: golang-1.22.x-image\n        config:\n          &lt;&lt;: *task-config\n</code></pre>"},{"location":"examples/golang-lib/#references","title":"References","text":"<ul> <li>Jobs</li> <li>Steps</li> <li>Tasks</li> </ul>"},{"location":"examples/hello-world/","title":"Hello World pipeline","text":"<p>A single job is the simplest form of pipeline.</p> <p>While this is less of an example pipeline, this is a simple introduction to a critical primitive to form pipelines.</p> <p>Also, due to the fact that there are minimal external factors (Resources) for the system to check and resolve, this is often used to test overall system health.</p>"},{"location":"examples/hello-world/#pipeline-configuration","title":"Pipeline Configuration","text":"<pre><code>---\njobs:\n  - name: job\n    public: true\n    plan:\n      - task: simple-task\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          run:\n            path: echo\n            args: [ \"Hello world!\" ]\n</code></pre>"},{"location":"examples/hello-world/#references","title":"References","text":"<ul> <li>Jobs</li> <li>Steps</li> <li>Tasks</li> </ul>"},{"location":"examples/inputs-outputs/","title":"Task inputs and outputs example","text":"<p>A task can pass an artifacts to another task in the same job.</p> <p>Tasks within a job have the ability to pass artifacts directly inbetween them to allow you to process artifacts in many ways.</p> <p>While you are free to create as many jobs as you'd like for your pipeline, you have to use resources to pass artifacts inbetween them.</p> <p>These constructs give you the ability to design a pipeline that can process artifacts in many different ways via Tasks, and then store those processed artifacts externally via Resources.</p>"},{"location":"examples/inputs-outputs/#pipeline-configuration","title":"Pipeline Configuration","text":"<pre><code>---\njobs:\n  - name: create-and-consume\n    public: true\n    plan:\n      - task: make-a-file\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          run:\n            path: sh\n            args:\n              - -exc\n              - ls -la; echo \"Created a file on $(date)\" &gt; ./files/created_file\n          outputs:\n            - name: files\n      - task: consume-the-file\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          inputs:\n            - name: files\n          run:\n            path: cat\n            args:\n              - ./files/created_file\n</code></pre>"},{"location":"examples/inputs-outputs/#references","title":"References","text":"<ul> <li><code>task-config.outputs</code></li> <li>Jobs</li> <li>Steps</li> <li>Tasks</li> </ul>"},{"location":"examples/java-app/","title":"Java application testing example","text":"<p>You can run the tests for a Java application.</p>"},{"location":"examples/java-app/#pipeline-configuration","title":"Pipeline Configuration","text":"<pre><code>---\nresources:\n  - name: apache-kafka\n    type: git\n    icon: github\n    source:\n      uri: https://github.com/apache/kafka.git\n\njobs:\n  - name: test\n    public: true\n    build_log_retention:\n      builds: 50\n    plan:\n      - get: apache-kafka\n        trigger: true\n      - task: run-tests\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source:\n              repository: gradle\n              tag: jdk17\n          caches:\n            - path: $HOME/.m2/repository\n            - path: $HOME/.gradle/caches/\n            - path: $HOME/.gradle/wrapper/\n          inputs:\n            - name: apache-kafka\n          run:\n            user: root\n            path: /bin/sh\n            args:\n              - -ce\n              - |\n                cd apache-kafka\n\n                ./gradlew clients:test --tests RequestResponseTest\n</code></pre>"},{"location":"examples/java-app/#references","title":"References","text":"<ul> <li>Jobs</li> <li>Steps</li> <li>Tasks</li> </ul>"},{"location":"examples/job-and-task-hooks/","title":"Job & task hooks example","text":"<p>Job hooks like <code>job.on_success</code> and Step hooks like  <code>on_success</code> are available to perform actions based on the success, failure, or abortion of a job.</p>"},{"location":"examples/job-and-task-hooks/#pipeline-configuration","title":"Pipeline Configuration","text":"<pre><code>---\ntask-config: &amp;task-config\n  platform: linux\n  image_resource:\n    type: registry-image\n    source: { repository: busybox }\n\njobs:\n  - name: job\n    public: true\n    plan:\n      - task: successful-task\n        config:\n          &lt;&lt;: *task-config\n          run:\n            path: sh\n            args: [ \"-lc\", \"exit 0\" ]\n        on_success:\n          task: task-success\n          config:\n            &lt;&lt;: *task-config\n            run:\n              path: echo\n              args: [ \"This task succeeded!\" ]\n        on_abort:\n          task: task-aborted\n          config:\n            &lt;&lt;: *task-config\n            run:\n              path: echo\n              args: [ \"This task was aborted!\" ]\n      - task: failing-task\n        config:\n          &lt;&lt;: *task-config\n          run:\n            path: sh\n            args: [ \"-lc\", \"exit 1\" ]\n        on_failure:\n          task: task-failure\n          config:\n            &lt;&lt;: *task-config\n            run:\n              path: echo\n              args: [ \"This task failed!\" ]\n    on_success:\n      task: job-success\n      config:\n        &lt;&lt;: *task-config\n        run:\n          path: echo\n          args: [ \"This job succeeded!\" ]\n    on_failure:\n      task: job-failure\n      config:\n        &lt;&lt;: *task-config\n        run:\n          path: echo\n          args: [ \"This job failed!\" ]\n    on_abort:\n      task: job-aborted\n      config:\n        &lt;&lt;: *task-config\n        run:\n          path: echo\n          args: [ \"This job was aborted!\" ]\n</code></pre>"},{"location":"examples/job-and-task-hooks/#references","title":"References","text":"<ul> <li><code>job.on_success</code></li> <li><code>job.on_failure</code></li> <li><code>job.on_abort</code></li> <li><code>on_success</code></li> <li><code>on_failure</code></li> <li><code>on_abort</code></li> <li>Jobs</li> <li>Steps</li> <li>Tasks</li> </ul>"},{"location":"examples/manually-triggered/","title":"Manually triggered job example","text":"<p>A job can be triggered by a resource. After it's complete, the next job can run automatically or manually.</p>"},{"location":"examples/manually-triggered/#pipeline-configuration","title":"Pipeline Configuration","text":"<pre><code>---\nresources:\n  - name: every-30s\n    type: time\n    icon: clock-outline\n    source:\n      interval: 30s\n\njobs:\n  - name: triggered-first\n    public: true\n    build_log_retention:\n      builds: 20\n    plan:\n      - get: every-30s\n        trigger: true\n      - task: simple-task\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          run:\n            path: echo\n            args: [ \"Hello, world!\" ]\n  - name: not-triggered\n    public: true\n    plan:\n      - get: every-30s\n        passed: [ triggered-first ]\n      - task: simple-task\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          run:\n            path: echo\n            args: [ \"Hello, world!\" ]\n  - name: triggered-second\n    public: true\n    build_log_retention:\n      builds: 20\n    plan:\n      - get: every-30s\n        passed: [ triggered-first ]\n        trigger: true\n      - task: simple-task\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          run:\n            path: echo\n            args: [ \"Hello, world!\" ]\n</code></pre>"},{"location":"examples/manually-triggered/#references","title":"References","text":"<ul> <li>Resources</li> <li>Jobs</li> <li>Steps</li> <li>Tasks</li> </ul>"},{"location":"examples/nodejs-app/","title":"Nodejs application testing example","text":"<p>You can run the tests for a Nodejs application.</p>"},{"location":"examples/nodejs-app/#pipeline-configuration","title":"Pipeline Configuration","text":"<pre><code>---\nresources:\n  - name: repo\n    type: git\n    icon: github\n    source:\n      uri: https://github.com/nodejs/nodejs.org.git\n\n  - name: node-image\n    type: registry-image\n    icon: docker\n    source:\n      repository: node\n      tag: 22-slim\n\njobs:\n  - name: test\n    public: true\n    build_log_retention:\n      builds: 50\n    plan:\n      - get: node-image\n      - get: repo\n        trigger: true\n      - task: test\n        image: node-image\n        config:\n          inputs:\n            - name: repo\n          platform: linux\n          run:\n            path: bash\n            dir: repo\n            args:\n              - -cex\n              - |\n                npm install -g pnpm\n                pnpm install --frozen-lockfile\n                pnpm run test\n</code></pre>"},{"location":"examples/nodejs-app/#references","title":"References","text":"<ul> <li>Jobs</li> <li>Steps</li> <li>Tasks</li> </ul>"},{"location":"examples/php-app/","title":"PHP application testing example","text":"<p>You can run the tests for a PHP application.</p>"},{"location":"examples/php-app/#pipeline-configuration","title":"Pipeline Configuration","text":"<pre><code>---\nresources:\n  - name: laravel-git\n    type: git\n    icon: github\n    source:\n      uri: https://github.com/laravel/laravel.git\n\njobs:\n  - name: test\n    public: true\n    build_log_retention:\n      builds: 50\n    plan:\n      - get: laravel-git\n        trigger: true\n      - task: run-tests\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: composer }\n          inputs:\n            - name: laravel-git\n          run:\n            path: /bin/sh\n            args:\n              - -ce\n              - |\n                cd laravel-git\n\n                composer install\n\n                cp .env.example .env\n                php artisan key:generate\n\n                vendor/bin/phpunit\n</code></pre>"},{"location":"examples/php-app/#references","title":"References","text":"<ul> <li>Jobs</li> <li>Steps</li> <li>Tasks</li> </ul>"},{"location":"examples/pipeline-vars/","title":"Pipeline <code>((vars))</code> example","text":"<p>You can use params in a pipelines configuration file.</p>"},{"location":"examples/pipeline-vars/#pipeline-configuration","title":"Pipeline Configuration","text":"<pre><code>---\njobs:\n  - name: ((first))-job\n    public: true\n    plan:\n      - task: simple-task\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          run:\n            path: echo\n            args: [ \"Hello, ((hello))!\" ]\n  - name: level-((number))-job\n    public: true\n    plan:\n      - task: simple-task\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          run:\n            path: echo\n            args: [ \"Hello, ((hello))!\" ]\n</code></pre>"},{"location":"examples/pipeline-vars/#variables","title":"Variables","text":"<pre><code>---\nfirst: initial\nnumber: \"9000\"\nhello: HAL\n</code></pre>"},{"location":"examples/pipeline-vars/#references","title":"References","text":"<ul> <li>Jobs</li> <li>Steps</li> <li>Tasks</li> </ul>"},{"location":"examples/rails-app/","title":"Rails application testing example","text":"<p>You can run the tests for a Rails that requires a specific version of ruby and relies on a Postgres database.</p>"},{"location":"examples/rails-app/#pipeline-configuration","title":"Pipeline Configuration","text":"<pre><code>---\nresources:\n  - name: rails-contributors-git\n    type: git\n    icon: github\n    source:\n      uri: https://github.com/rails/rails-contributors.git\n\njobs:\n  - name: test\n    public: true\n    build_log_retention:\n      builds: 50\n    plan:\n      - get: rails-contributors-git\n        trigger: true\n      - task: run-tests\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: ruby, tag: 3.4.5 }\n          inputs:\n            - name: rails-contributors-git\n          params:\n            RAILS_ENV: test\n            DATABASE_URL: postgresql://postgres@localhost\n          run:\n            path: /bin/bash\n            args:\n              - -ce\n              - |\n                cd rails-contributors-git\n\n                echo \"=== Setting up Postgres ===\"\n                apt-get update\n                apt-get install -y postgresql libpq-dev cmake nodejs\n                cat &gt; /etc/postgresql/*/main/pg_hba.conf &lt;&lt;-EOF\n                host   all   postgres   localhost   trust\n                EOF\n                service postgresql restart\n\n                echo \"=== Project requires that we clone rails ===\"\n                git clone --mirror https://github.com/rails/rails.git\n\n                echo \"=== Installing Gems ===\"\n                gem install -N bundler\n                bundle install\n\n                echo \"=== Running Tests ===\"\n                bundle exec rails db:setup\n                bundle exec rails test\n</code></pre>"},{"location":"examples/rails-app/#references","title":"References","text":"<ul> <li>Jobs</li> <li>Steps</li> <li>Tasks</li> </ul>"},{"location":"examples/serial-job/","title":"Serial job example","text":"<p>Setting the <code>job.serial</code> flag restricts a job to run one build at a time.</p> <p>By default, jobs are run in parallel. For some use cases this might be ideal (ex. testing all incoming commits from a repository). For other use cases this might be less ideal (ex. deploying an application).</p> <p>You can also set the <code>job.max_in_flight</code> value to 1 to disable parallel job runs.</p>"},{"location":"examples/serial-job/#pipeline-configuration","title":"Pipeline Configuration","text":"<pre><code>---\njobs:\n  # Try to trigger the job multiple times and see what happens\n  - name: serial-job\n    public: true\n    serial: true\n    plan:\n      - task: simple-task\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          run:\n            path: echo\n            args: [ \"Hello, world!\" ]\n</code></pre>"},{"location":"examples/serial-job/#references","title":"References","text":"<ul> <li>Jobs</li> <li>Steps</li> <li>Tasks</li> </ul>"},{"location":"examples/set-pipeline/","title":"Set Pipelines Example","text":"<p>You can set a static set of pipelines from another pipeline on the same team.</p>"},{"location":"examples/set-pipeline/#pipeline-configuration","title":"Pipeline Configuration","text":"<pre><code>---\nresources:\n  - name: concourse-examples\n    type: git\n    icon: github\n    check_every: 30m\n    source:\n      uri: https://github.com/concourse/examples\n\njobs:\n  # update this pipeline before updating child pipelines\n  - name: set-self\n    public: true\n    build_log_retention:\n      builds: 50\n    plan:\n      - get: concourse-examples\n        trigger: true\n      - set_pipeline: self\n        file: concourse-examples/pipelines/set-pipelines.yml\n\n  - name: set-example-pipelines\n    public: true\n    build_log_retention:\n      builds: 50\n    plan:\n      - get: concourse-examples\n        trigger: true\n        passed: [ set-self ]\n      - set_pipeline: job\n        file: concourse-examples/pipelines/hello-world.yml\n      - set_pipeline: separate-task-config\n        file: concourse-examples/pipelines/separate-task-config.yml\n      - set_pipeline: serial-job\n        file: concourse-examples/pipelines/serial-job.yml\n      - set_pipeline: pipeline-vars\n        file: concourse-examples/pipelines/pipeline-vars.yml\n        vars:\n          first: initial\n          number: \"9000\"\n          hello: HAL\n      - set_pipeline: pipeline-vars-file\n        file: concourse-examples/pipelines/pipeline-vars.yml\n        var_files:\n          - concourse-examples/pipelines/vars-file.yml\n      - set_pipeline: instance-groups\n        file: concourse-examples/pipelines/pipeline-vars.yml\n        # instance_vars is currently experimental and requires the feature flag\n        # --enable-pipeline-instances\n        instance_vars:\n          first: initial\n          number: \"9000\"\n          hello: HAL\n      - set_pipeline: instance-groups\n        file: concourse-examples/pipelines/pipeline-vars.yml\n        instance_vars:\n          first: second\n          number: \"3000\"\n          hello: WALLY-E\n      - set_pipeline: task-passing-artifact\n        file: concourse-examples/pipelines/task-passing-artifact.yml\n      - set_pipeline: time-triggered\n        file: concourse-examples/pipelines/time-triggered.yml\n      - set_pipeline: git-triggered\n        file: concourse-examples/pipelines/git-triggered.yml\n      - set_pipeline: manual-trigger\n        file: concourse-examples/pipelines/manually-triggered.yml\n      - set_pipeline: hooks\n        file: concourse-examples/pipelines/job-and-task-hooks.yml\n      - set_pipeline: golang-lib\n        file: concourse-examples/pipelines/golang-lib.yml\n      - set_pipeline: rails\n        file: concourse-examples/pipelines/rails-app-testing.yml\n      - set_pipeline: nodejs\n        file: concourse-examples/pipelines/nodejs-app-testing.yml\n      - set_pipeline: php\n        file: concourse-examples/pipelines/php-larvel-app-testing.yml\n      - set_pipeline: java\n        file: concourse-examples/pipelines/java.yml\n\n  - name: set-rendered-pipelines\n    public: true\n    build_log_retention:\n      builds: 50\n    plan:\n      - get: concourse-examples\n        trigger: true\n        passed: [ set-self ]\n      - task: render-pipelines\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source:\n              repository: taylorsilva/carvel-ytt\n          inputs:\n            - name: concourse-examples\n          outputs:\n            - name: pipeline\n          run:\n            path: sh\n            args:\n              - -cx\n              - |\n                ytt -f ./concourse-examples/pipelines/templates/simple &gt; hello-world-rendered.yml\n                ytt -f ./concourse-examples/pipelines/templates/multiple-files &gt; multi-files-rendered.yml\n                mv *.yml ./pipeline/\n      - set_pipeline: hello-world-rendered\n        file: pipeline/hello-world-rendered.yml\n      - set_pipeline: multi-files-rendered\n        file: pipeline/multi-files-rendered.yml\n</code></pre>"},{"location":"examples/set-pipeline/#references","title":"References","text":"<ul> <li>Jobs</li> <li>Steps</li> <li><code>set-pipeline</code> step</li> </ul>"},{"location":"examples/time-triggered/","title":"<code>time</code>-triggered job example","text":"<p>The <code>time</code> resource can be used to trigger a job.</p>"},{"location":"examples/time-triggered/#pipeline-configuration","title":"Pipeline Configuration","text":"<pre><code>---\nresources:\n  - name: every-30s\n    type: time\n    icon: clock-outline\n    source:\n      interval: 30s\n\njobs:\n  - name: job\n    public: true\n    build_log_retention:\n      builds: 50\n    plan:\n      - get: every-30s\n        trigger: true\n      - task: simple-task\n        config:\n          platform: linux\n          image_resource:\n            type: registry-image\n            source: { repository: busybox }\n          run:\n            path: echo\n            args: [ \"Hello, world!\" ]\n</code></pre>"},{"location":"examples/time-triggered/#references","title":"References","text":"<ul> <li>Resources</li> <li>Jobs</li> <li>Steps</li> <li>Tasks</li> </ul>"},{"location":"project/","title":"Project","text":"<p>Concourse began as a side-project by <code>@vito</code> and <code>@xoebus</code> in 2014. Since then, Concourse has evolved into a dedicated community with contributors from all around the world.</p> <p>Concourse is a project of the Cloud Foundry foundation (CFF), currently lead by Taylor Silva and Derek Richard. The CFF pays for the infrastructure costs of the project. Pixel Air IO, lead by Taylor, is currently the main developer behind Concourse; reviewing and merging Pull Requests, squashing bugs, and stewarding the project and community.</p>"},{"location":"project/#where-is-everything","title":"Where is everything?","text":"<ul> <li>The Concourse repo houses the main codebase, where planning happens, and   where issues are tracked.</li> <li>The Docs repo contains the source for the website you're reading now!</li> <li>GitHub Discussions are used for support, announcements, idea   sharing, and general conversations.</li> <li>The Concourse blog features tutorials and updates from the development perspective.</li> <li>The Concourse Discord server offers a great space to chat with other contributors.</li> <li>The Concourse working group charter is available in the Cloud   Foundry community repo.</li> <li>The working group holds public monthly meetings. Past meetings can be viewed in   this YouTube playlist and   meeting notes   are here.</li> </ul>"},{"location":"project/#why-make-concourse","title":"Why make Concourse?","text":"<p>When working on a substantial project, having a pipeline to reliably test, deploy, and publish the product is essential for rapid iteration.</p> <p>But with every CI system we tried, we found ourselves repeatedly facing the same problems: complex configs buried in many pages of the web UI, uncertainty about who changed what &amp; when, managing dependencies and state on the workers, build contamination, frustrating UX...</p> <p>Our project was expanding, and with every box we checked and for every worker we manually configured, the anxiety of having to rebuild everything if something failed grew increasingly. We began writing software to manage our CI instead of creating the software for the product we intended to build.</p> <p>We created Concourse to be a CI system that provides peace of mind. A CI that's straightforward enough to fully understand and easy to maintain as your project grows; both in the complexity of the product and the size of your team. We aimed to build a CI with robust abstractions and fewer concepts to learn, making it easier to comprehend and allowing Concourse to evolve gracefully.</p>"},{"location":"project/#how-can-i-help","title":"How can I help?","text":"<p>Concourse is a free and Open Source software project that depends on the contributions of sponsors and volunteers worldwide.</p> <p>If you're interested in contributing, head over to GitHub and check out the contributing docs!</p> <p>If you're able to financially contribute to the continued development of Concourse, please reach out to Taylor.</p>"},{"location":"project/#report-a-security-issue","title":"Report a security issue","text":"<p>To report a security issue, please email security@concourse-ci.org.</p> <p>Security advisories will be published as <code>concourse/concourse</code> GitHub Security Advisories.</p>"},{"location":"project/#thanks","title":"Thanks","text":"<p>It's been a long journey and we're grateful to many people for our continued success. We are deeply indebted to all who help sustain this project, but the extraordinary efforts of the following organizations deserve special recognition.</p>"},{"location":"project/#pivotal","title":"Pivotal","text":"<p>Concourse wouldn't be what it is today without Pivotal. This extends beyond the sponsorship, which began in early 2015 - without the experiences we gained and the practices we learned while working on Cloud Foundry and BOSH, we would have neither the technical expertise nor the strong opinions that led to Concourse's creation.</p>"},{"location":"support/","title":"Support","text":""},{"location":"support/#community-support","title":"Community Support","text":"<p>You can ask the community for support either on Discord or GitHub Discussions.</p>"},{"location":"support/#commercial-support","title":"Commercial Support","text":"<p>The maintainers of Concourse provide commercial support for Concourse through Pixel Air. If you're interested in commercial support you can book a call with us.</p>"},{"location":"blog/archive/2025/","title":"2025","text":""},{"location":"blog/archive/2020/","title":"2020","text":""},{"location":"blog/archive/2019/","title":"2019","text":""},{"location":"blog/archive/2018/","title":"2018","text":""},{"location":"blog/archive/2017/","title":"2017","text":""},{"location":"blog/category/tutorials/","title":"tutorials","text":""},{"location":"blog/category/rfcs/","title":"rfcs","text":""},{"location":"blog/category/design/","title":"design","text":""},{"location":"blog/category/product-update/","title":"product-update","text":""},{"location":"blog/category/roadmap/","title":"roadmap","text":""},{"location":"blog/page/2/","title":"Blog","text":""},{"location":"blog/page/3/","title":"Blog","text":""},{"location":"blog/page/4/","title":"Blog","text":""},{"location":"blog/page/5/","title":"Blog","text":""},{"location":"blog/page/6/","title":"Blog","text":""},{"location":"blog/page/7/","title":"Blog","text":""},{"location":"blog/page/8/","title":"Blog","text":""},{"location":"blog/page/9/","title":"Blog","text":""},{"location":"blog/archive/2020/page/2/","title":"2020","text":""},{"location":"blog/archive/2019/page/2/","title":"2019","text":""},{"location":"blog/archive/2018/page/2/","title":"2018","text":""},{"location":"blog/archive/2018/page/3/","title":"2018","text":""},{"location":"blog/archive/2018/page/4/","title":"2018","text":""},{"location":"blog/archive/2018/page/5/","title":"2018","text":""},{"location":"blog/category/product-update/page/2/","title":"product-update","text":""},{"location":"blog/category/product-update/page/3/","title":"product-update","text":""},{"location":"blog/category/product-update/page/4/","title":"product-update","text":""},{"location":"blog/category/product-update/page/5/","title":"product-update","text":""},{"location":"blog/category/product-update/page/6/","title":"product-update","text":""}]}